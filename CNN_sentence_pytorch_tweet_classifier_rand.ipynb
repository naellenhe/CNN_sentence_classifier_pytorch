{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomly initialized word vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = \"-rand\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import cPickle (python2.7)\n",
    "#http://testpy.hatenablog.com/entry/2017/03/17/000626\n",
    "import _pickle as cPickle\n",
    "\n",
    "import numpy as np\n",
    "from collections import defaultdict, OrderedDict\n",
    "\n",
    "import re\n",
    "import sys\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameters\n",
    "num_epochs = 10\n",
    "num_classes = 3\n",
    "batch_size = 50\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load pickle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the pickle file contains [revs, W, W2, word_idx_map, vocab] # W2 random vectors\n",
    "x = cPickle.load(open(\"tweet.p\",\"rb\"), encoding=\"latin1\") # Add encoding=\"latin1\" because got UnicodeDecodeError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset content\n",
    "Get data from twitter (reference: http://tech.wonderpla.net/entry/2017/10/10/110000)\n",
    "- Label 0\n",
    "    - KEYWORD = \"芸能 OR アニメ OR 漫画 OR ドラマ OR ゲーム\"            #エンタメ系のキーワード\n",
    "    - CLASS_LABEL = \"\\__label__0\"\n",
    "\n",
    "- Label 1\n",
    "    - KEYWORD = \"美容 OR サロン OR エステ OR 化粧 OR 保湿\"            #美容系のキーワード\n",
    "    - CLASS_LABEL = \"\\__label__1\"\n",
    "\n",
    "- Label 2\n",
    "    - KEYWORD = \"日常 OR 料理 OR 家事 OR 収納 OR 家具\"            #暮らし系のキーワード\n",
    "    - CLASS_LABEL = \"\\__label__2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### See data sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_words</th>\n",
       "      <th>split</th>\n",
       "      <th>text</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>刃 牙 の 漫画 また 集め たい</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>【 クリア 済 】 友人 が 、 昔 プレイ し た けど 名前 覚え て い ない ゲーム...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     num_words  split                                               text  y\n",
       "155          7      7                                  刃 牙 の 漫画 また 集め たい  0\n",
       "122         41      2  【 クリア 済 】 友人 が 、 昔 プレイ し た けど 名前 覚え て い ない ゲーム...  0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(x[0])\n",
    "\n",
    "# label 0: Entertainment \n",
    "df[df['y'] == 0].sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_words</th>\n",
       "      <th>split</th>\n",
       "      <th>text</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>35</td>\n",
       "      <td>8</td>\n",
       "      <td>美容 女子 の 美容 習慣 【 日 中 の 習慣 】 ランチ に は 野菜 を しっかり 取...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>41</td>\n",
       "      <td>6</td>\n",
       "      <td>★ 美容 ★ 代謝 を 上げる 上質 な 油分 ① ナッツ ② アボガド ③ オリーブ オイ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     num_words  split                                               text  y\n",
       "920         35      8  美容 女子 の 美容 習慣 【 日 中 の 習慣 】 ランチ に は 野菜 を しっかり 取...  1\n",
       "975         41      6  ★ 美容 ★ 代謝 を 上げる 上質 な 油分 ① ナッツ ② アボガド ③ オリーブ オイ...  1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# label 1 : Beauty\n",
    "df[df['y'] == 1].sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_words</th>\n",
       "      <th>split</th>\n",
       "      <th>text</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1406</th>\n",
       "      <td>22</td>\n",
       "      <td>6</td>\n",
       "      <td>【 急募 】 合法 で 未成年 の 私 が 料理 用 に 使う 白 ワイン 50 ml を ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1653</th>\n",
       "      <td>40</td>\n",
       "      <td>8</td>\n",
       "      <td># ミリシタ p と 繋がり たい # ミリ マス p と 繋がり たい 新規 p の デュ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      num_words  split                                               text  y\n",
       "1406         22      6  【 急募 】 合法 で 未成年 の 私 が 料理 用 に 使う 白 ワイン 50 ml を ...  2\n",
       "1653         40      8  # ミリシタ p と 繋がり たい # ミリ マス p と 繋がり たい 新規 p の デュ...  2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# label 2: Life\n",
    "df[df['y'] == 2].sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "revs, W, W2, word_idx_map, vocab = x[0], x[1], x[2], x[3], x[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max sentence length:  100\n"
     ]
    }
   ],
   "source": [
    "# Get the number of the longest sentence\n",
    "max_l = np.max(pd.DataFrame(revs)[\"num_words\"])\n",
    "print(\"max sentence length: \", max_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "revs 2068\n",
      "W 10330\n",
      "W2 10330\n",
      "word_idx_map 10329\n",
      "vocab 10329\n"
     ]
    }
   ],
   "source": [
    "print('revs',len(x[0])) # number of sentence\n",
    "print('W',len(x[1])) # W are pretrained word vectors (unknown words are randomly initialized)\n",
    "print('W2', len(x[2])) # W2 are randomly initialized vectors\n",
    "print('word_idx_map', len(x[3]))\n",
    "print('vocab', len(x[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'y': 0,\n",
       " 'text': 'え 、 サラリーマン し ながら 、 商業 漫画 の 仕事 を し て 、 ツイッター に 定期 的 に 漫画 を あげ て 、 さらに コミケ の 原稿 を 作る ！ ？',\n",
       " 'num_words': 32,\n",
       " 'split': 7}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "revs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using: random vectors\n"
     ]
    }
   ],
   "source": [
    "if word_vectors == \"-rand\":\n",
    "    print(\"using: random vectors\")\n",
    "    U = W2\n",
    "elif word_vectors == \"-word2vec\":\n",
    "    print(\"using: word2vec vectors\")\n",
    "    U = W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10330, 300)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make dataset (check original code)\n",
    "make each sentence an word index map using word_idx_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_idx_from_sent(sent, word_idx_map, max_l=51, k=300, filter_h=5):\n",
    "    \"\"\"\n",
    "    Transforms sentence into a list of indices. Pad with zeroes.\n",
    "    \"\"\"\n",
    "    x = []\n",
    "    pad = filter_h - 1\n",
    "    for i in range(pad):\n",
    "        x.append(0)\n",
    "    words = sent.split()\n",
    "    for word in words:\n",
    "        if word in word_idx_map:\n",
    "            x.append(word_idx_map[word])\n",
    "    while len(x) < max_l + 2*pad:\n",
    "        x.append(0)\n",
    "    return x\n",
    "\n",
    "def make_idx_data_cv(revs, word_idx_map, cv, max_l=51, k=300, filter_h=5):\n",
    "    \"\"\"\n",
    "    Transforms sentences into a 2-d matrix.\n",
    "    \"\"\"\n",
    "    train, test = [], []\n",
    "    for rev in revs:\n",
    "        sent = get_idx_from_sent(rev[\"text\"], word_idx_map, max_l, k, filter_h) # one sentence\n",
    "        sent.append(rev[\"y\"])\n",
    "        if rev[\"split\"]== cv:  # \"split\" is random number of np.random.randint(0,10)\n",
    "            test.append(sent)        \n",
    "        else:  \n",
    "            train.append(sent)   \n",
    "    train = np.array(train, dtype=\"int\")\n",
    "    test = np.array(test, dtype=\"int\")\n",
    "    return [train, test] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "datasets = make_idx_data_cv(revs, word_idx_map, i, max_l, k=300, filter_h=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example of sentence to word index map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'y': 0,\n",
       " 'text': 'え 、 サラリーマン し ながら 、 商業 漫画 の 仕事 を し て 、 ツイッター に 定期 的 に 漫画 を あげ て 、 さらに コミケ の 原稿 を 作る ！ ？',\n",
       " 'num_words': 32,\n",
       " 'split': 7}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "revs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,   27, 4148,   26,    2,   21, 4148,   31,\n",
       "       4147,   25, 4150,   32,    2,   10, 4148,   22,    5,   29,   28,\n",
       "          5, 4147,   32, 4152,   10, 4148,   30,   23,   25,   24,   32,\n",
       "       4154, 4153, 4151,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(datasets[0][0]))\n",
    "datasets[0][1] # sentence => word index map padding with zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data size: (1860, 109)\n",
      "test data size: (208, 109)\n"
     ]
    }
   ],
   "source": [
    "print('train data size:', datasets[0].shape)\n",
    "print('test data size:', datasets[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make dataset (using vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_idx_from_sent_2vec(sent, U, word_idx_map, max_l=51, k=300, filter_h=5):\n",
    "    \"\"\"\n",
    "    Transforms sentence into a list of indices. Pad with zeroes.\n",
    "    \"\"\"\n",
    "    pad = filter_h - 1\n",
    "    x = np.zeros((max_l+2*pad, k))\n",
    "\n",
    "    words = sent.split()\n",
    "    # starting after padding\n",
    "    i = pad\n",
    "    for word in words:\n",
    "        if word in word_idx_map:\n",
    "            x[i] = U[word_idx_map[word]]\n",
    "            i += 1\n",
    "    return x\n",
    "\n",
    "def make_idx_data_cv_2vec(revs, U, word_idx_map, cv, max_l=51, k=300, filter_h=5):\n",
    "    \"\"\"\n",
    "    Transforms sentences into a 2-d matrix.\n",
    "    \"\"\"\n",
    "    train_image, train_label = [], []\n",
    "    test_image, test_label = [], []\n",
    "    test_rev = []\n",
    "    for rev in revs:\n",
    "        sent = get_idx_from_sent_2vec(rev[\"text\"], U, word_idx_map, max_l, k, filter_h) # one sentence\n",
    "        if rev[\"split\"] == cv:  # \"split\" is random number of np.random.randint(0,10)\n",
    "            test_image.append(sent) \n",
    "            test_label.append(rev[\"y\"])\n",
    "            test_rev.append(rev)\n",
    "        else:  \n",
    "            train_image.append(sent)\n",
    "            train_label.append(rev[\"y\"])\n",
    "    train_image = np.array(train_image)\n",
    "    train_label = np.array(train_label)\n",
    "    test_image = np.array(test_image)\n",
    "    test_label = np.array(test_label)\n",
    "    test_rev = np.array(test_rev)\n",
    "    return (train_image, train_label), (test_image, test_label, test_rev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence length(before) 108\n"
     ]
    }
   ],
   "source": [
    "t = \"effective but too tepid biopic\"\n",
    "t_sent_2vec = get_idx_from_sent_2vec(t, U, word_idx_map, max_l, k=300, filter_h=5)\n",
    "print(\"sentence length(before)\", len(t_sent_2vec)) # max_l(51)+2*pad(filter_h-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_sent_2vec[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "datasets_2vec = make_idx_data_cv_2vec(revs, U, word_idx_map, i, max_l, k=300, filter_h=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_image, train_label), (test_image, test_label, test_rev) = datasets_2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example of sentence to vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'y': 0,\n",
       " 'text': 'え 、 サラリーマン し ながら 、 商業 漫画 の 仕事 を し て 、 ツイッター に 定期 的 に 漫画 を あげ て 、 さらに コミケ の 原稿 を 作る ！ ？',\n",
       " 'num_words': 32,\n",
       " 'split': 7}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "revs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(108, 300)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.031848</td>\n",
       "      <td>0.029848</td>\n",
       "      <td>-0.014398</td>\n",
       "      <td>-0.068998</td>\n",
       "      <td>-0.028239</td>\n",
       "      <td>-0.052004</td>\n",
       "      <td>0.051752</td>\n",
       "      <td>0.089686</td>\n",
       "      <td>-0.032347</td>\n",
       "      <td>-0.006774</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.062494</td>\n",
       "      <td>-0.001097</td>\n",
       "      <td>0.057786</td>\n",
       "      <td>0.045410</td>\n",
       "      <td>-0.077737</td>\n",
       "      <td>-0.000512</td>\n",
       "      <td>0.057125</td>\n",
       "      <td>0.062231</td>\n",
       "      <td>-0.084393</td>\n",
       "      <td>-0.054385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.052030</td>\n",
       "      <td>0.047755</td>\n",
       "      <td>-0.006098</td>\n",
       "      <td>0.005459</td>\n",
       "      <td>0.050112</td>\n",
       "      <td>0.064889</td>\n",
       "      <td>-0.019147</td>\n",
       "      <td>-0.055063</td>\n",
       "      <td>0.070911</td>\n",
       "      <td>0.078830</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007838</td>\n",
       "      <td>0.084729</td>\n",
       "      <td>-0.052742</td>\n",
       "      <td>0.047005</td>\n",
       "      <td>0.084278</td>\n",
       "      <td>0.060594</td>\n",
       "      <td>0.087691</td>\n",
       "      <td>-0.086446</td>\n",
       "      <td>0.006907</td>\n",
       "      <td>-0.030155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.071313</td>\n",
       "      <td>-0.005998</td>\n",
       "      <td>0.062598</td>\n",
       "      <td>-0.021418</td>\n",
       "      <td>-0.085882</td>\n",
       "      <td>0.014776</td>\n",
       "      <td>0.096674</td>\n",
       "      <td>-0.036205</td>\n",
       "      <td>-0.094731</td>\n",
       "      <td>-0.081130</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066087</td>\n",
       "      <td>0.097537</td>\n",
       "      <td>-0.028070</td>\n",
       "      <td>-0.091322</td>\n",
       "      <td>-0.041987</td>\n",
       "      <td>0.088065</td>\n",
       "      <td>-0.029542</td>\n",
       "      <td>0.017271</td>\n",
       "      <td>-0.086685</td>\n",
       "      <td>0.004755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.017633</td>\n",
       "      <td>0.062037</td>\n",
       "      <td>-0.084273</td>\n",
       "      <td>-0.078511</td>\n",
       "      <td>-0.041574</td>\n",
       "      <td>0.050543</td>\n",
       "      <td>-0.047856</td>\n",
       "      <td>-0.047555</td>\n",
       "      <td>0.044869</td>\n",
       "      <td>0.067696</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.038059</td>\n",
       "      <td>0.074258</td>\n",
       "      <td>0.080864</td>\n",
       "      <td>0.032623</td>\n",
       "      <td>0.037955</td>\n",
       "      <td>0.005790</td>\n",
       "      <td>0.015685</td>\n",
       "      <td>0.025372</td>\n",
       "      <td>0.071321</td>\n",
       "      <td>-0.042944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.067426</td>\n",
       "      <td>-0.075915</td>\n",
       "      <td>0.069243</td>\n",
       "      <td>0.098445</td>\n",
       "      <td>-0.034026</td>\n",
       "      <td>0.067784</td>\n",
       "      <td>-0.024859</td>\n",
       "      <td>0.020448</td>\n",
       "      <td>-0.025627</td>\n",
       "      <td>0.077285</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039912</td>\n",
       "      <td>0.019995</td>\n",
       "      <td>-0.041253</td>\n",
       "      <td>0.060311</td>\n",
       "      <td>-0.016176</td>\n",
       "      <td>-0.058960</td>\n",
       "      <td>-0.051399</td>\n",
       "      <td>-0.051367</td>\n",
       "      <td>0.033377</td>\n",
       "      <td>-0.099575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.052030</td>\n",
       "      <td>0.047755</td>\n",
       "      <td>-0.006098</td>\n",
       "      <td>0.005459</td>\n",
       "      <td>0.050112</td>\n",
       "      <td>0.064889</td>\n",
       "      <td>-0.019147</td>\n",
       "      <td>-0.055063</td>\n",
       "      <td>0.070911</td>\n",
       "      <td>0.078830</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007838</td>\n",
       "      <td>0.084729</td>\n",
       "      <td>-0.052742</td>\n",
       "      <td>0.047005</td>\n",
       "      <td>0.084278</td>\n",
       "      <td>0.060594</td>\n",
       "      <td>0.087691</td>\n",
       "      <td>-0.086446</td>\n",
       "      <td>0.006907</td>\n",
       "      <td>-0.030155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4  0.031848  0.029848 -0.014398 -0.068998 -0.028239 -0.052004  0.051752   \n",
       "5  0.052030  0.047755 -0.006098  0.005459  0.050112  0.064889 -0.019147   \n",
       "6  0.071313 -0.005998  0.062598 -0.021418 -0.085882  0.014776  0.096674   \n",
       "7  0.017633  0.062037 -0.084273 -0.078511 -0.041574  0.050543 -0.047856   \n",
       "8  0.067426 -0.075915  0.069243  0.098445 -0.034026  0.067784 -0.024859   \n",
       "9  0.052030  0.047755 -0.006098  0.005459  0.050112  0.064889 -0.019147   \n",
       "\n",
       "        7         8         9      ...          290       291       292  \\\n",
       "0  0.000000  0.000000  0.000000    ...     0.000000  0.000000  0.000000   \n",
       "1  0.000000  0.000000  0.000000    ...     0.000000  0.000000  0.000000   \n",
       "2  0.000000  0.000000  0.000000    ...     0.000000  0.000000  0.000000   \n",
       "3  0.000000  0.000000  0.000000    ...     0.000000  0.000000  0.000000   \n",
       "4  0.089686 -0.032347 -0.006774    ...    -0.062494 -0.001097  0.057786   \n",
       "5 -0.055063  0.070911  0.078830    ...    -0.007838  0.084729 -0.052742   \n",
       "6 -0.036205 -0.094731 -0.081130    ...     0.066087  0.097537 -0.028070   \n",
       "7 -0.047555  0.044869  0.067696    ...    -0.038059  0.074258  0.080864   \n",
       "8  0.020448 -0.025627  0.077285    ...    -0.039912  0.019995 -0.041253   \n",
       "9 -0.055063  0.070911  0.078830    ...    -0.007838  0.084729 -0.052742   \n",
       "\n",
       "        293       294       295       296       297       298       299  \n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "2  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "4  0.045410 -0.077737 -0.000512  0.057125  0.062231 -0.084393 -0.054385  \n",
       "5  0.047005  0.084278  0.060594  0.087691 -0.086446  0.006907 -0.030155  \n",
       "6 -0.091322 -0.041987  0.088065 -0.029542  0.017271 -0.086685  0.004755  \n",
       "7  0.032623  0.037955  0.005790  0.015685  0.025372  0.071321 -0.042944  \n",
       "8  0.060311 -0.016176 -0.058960 -0.051399 -0.051367  0.033377 -0.099575  \n",
       "9  0.047005  0.084278  0.060594  0.087691 -0.086446  0.006907 -0.030155  \n",
       "\n",
       "[10 rows x 300 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p2 = pd.DataFrame(train_image[1])\n",
    "print(p2.shape)\n",
    "p2.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make dataset iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1860"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_image = torch.FloatTensor(train_image).reshape(-1, 1, max_l + 2 * (5-1), 300)\n",
    "t_label = torch.LongTensor(train_label)\n",
    "train_dataset = list(zip(t_image, t_label))\n",
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images: torch.Size([50, 1, 108, 300]) \n",
      "labels: torch.Size([50])\n",
      "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])\n",
      "tensor(2)\n"
     ]
    }
   ],
   "source": [
    "for images, labels in train_loader:\n",
    "    print('images:', images.shape, '\\nlabels:', labels.shape)\n",
    "    print(images[1][0])\n",
    "    print(labels[1])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "208"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_image = torch.FloatTensor(test_image).reshape(-1, 1, max_l + 2 * (5-1), 300)\n",
    "c_label = torch.LongTensor(test_label)\n",
    "test_dataset = list(zip(c_image, c_label, test_rev))\n",
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loader\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model parameters (original code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_hs=[3, 4, 5]\n",
    "hidden_units=[100, num_classes]\n",
    "batch_size=50\n",
    "img_w=300\n",
    "img_h = len(datasets[0][0])-1  # sentence length (subtracted 1 for y label)\n",
    "\n",
    "filter_w = img_w    \n",
    "feature_maps = hidden_units[0]\n",
    "filter_shapes = []\n",
    "pool_sizes = []\n",
    "for filter_h in filter_hs:\n",
    "    filter_shapes.append((feature_maps, 1, filter_h, filter_w))\n",
    "    pool_sizes.append((img_h-filter_h+1, img_w-filter_w+1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(100, 1, 3, 300), (100, 1, 4, 300), (100, 1, 5, 300)]\n",
      "one batch train (50, 1, 108, 300)\n",
      "[(106, 1), (105, 1), (104, 1)]\n"
     ]
    }
   ],
   "source": [
    "print(filter_shapes)\n",
    "image_shape = (batch_size, 1, img_h, img_w)\n",
    "print('one batch train', image_shape)\n",
    "print(pool_sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding & Stride\n",
    "- Output size\n",
    "\n",
    "    $ O = \\frac {W-K+2P}{S} + 1 $\n",
    "    - O: output h/w\n",
    "    - W: input h/w\n",
    "    - K: filter size(kernel size)\n",
    "    - P: padding\n",
    "        - $  P = \\frac {K-1}{2} $\n",
    "    - S: stride"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network\n",
    "\n",
    "- Theano:\n",
    "    - conv_layer: LeNetConvPoolLayer\n",
    "    - classifier: MLPDropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model:\n",
    "\n",
    "\n",
    "```\n",
    "Network\n",
    "Input ->\n",
    "Conv -> ReLU -> MaxPool |\n",
    "Conv -> ReLU -> MaxPool | -> concat\n",
    "Conv -> ReLU -> MaxPool |\n",
    "Fully Connected Layer(Logits -> Softmax) -> Labels\n",
    "```\n",
    "\n",
    "```\n",
    "Convolutional layer formula:\n",
    "- Filter 1(Kernel) size K = 3 => (3 x 300)\n",
    "- P(same padding) P = (3-1)/2=1\n",
    "- S(stride) S = 1\n",
    "- in_channels = 1\n",
    "- out_channels (int) – Number of channels produced by the convolution = 100\n",
    "Pooling layer formula:\n",
    "- K\n",
    "```\n",
    "\n",
    "```\n",
    "*Filter dimensions*:\n",
    "Conv1 (W_conv, (100, 1, 3, 300))\n",
    "Conv1 (b_conv, (100,))\n",
    "Conv2 (W_conv, (100, 1, 4, 300))\n",
    "Conv2 (b_conv, (100,))\n",
    "Conv3 (W_conv, (100, 1, 5, 300))\n",
    "Conv3 (b_conv, (100,))\n",
    "\n",
    "*Layer input dimensions*:\n",
    "- Input image(64, 300) \n",
    "\n",
    "----------------------------------------------------------------------\n",
    "|  Conv1  (100, 3, 300)   Conv2  (100, 4, 300)   Conv3  (100, 5, 300) |\n",
    "|  MaxPool (100, 62, 1)   MaxPool (100, 61, 1)   MaxPool (100, 60, 1) |\n",
    "-----------------------------Concat ----------------------------------\n",
    "\n",
    "- Concatenated (100, 1, 1) + (100, 1, 1) + (100, 1, 1) => (300, 1, 1) \n",
    "\n",
    "- Fully Connected Layer(Logits (100, 1) -> Logits (2, 1) -> Softmax) -> Labels\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvPoolLayer(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(ConvPoolLayer, self).__init__()\n",
    "\n",
    "        # Layer 1: conv - relu - conv- relu - pool\n",
    "        self.ngram1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=feature_maps, kernel_size=(filter_hs[0], img_w), stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=pool_sizes[0], stride=None))\n",
    "        self.ngram2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=feature_maps, kernel_size=(filter_hs[1], img_w), stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=pool_sizes[1], stride=None))\n",
    "        self.ngram3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=feature_maps, kernel_size=(filter_hs[2], img_w), stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=pool_sizes[2], stride=None))\n",
    "        \n",
    "        # Fully Connected 1 (readout)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(feature_maps * 3, hidden_units[0]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_units[0], num_classes))\n",
    "\n",
    "        # Initialize all parameters using kaiming normalization\n",
    "        self.init_weights_kaiming()\n",
    "    \n",
    "    def init_weights_kaiming(self):\n",
    "        #Use kaiming normalization to initialize the parameters\n",
    "        for layer in [self.ngram1, self.ngram2, self.ngram3, self.fc]:\n",
    "            for m in layer:\n",
    "                if type(m) == nn.Conv2d or type(m) == nn.Linear:\n",
    "                    m.weight = nn.init.kaiming_normal_(m.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        out1 = self.ngram1(x)\n",
    "        out2 = self.ngram2(x)\n",
    "        out3 = self.ngram3(x)\n",
    "        out = torch.cat((out1, out2, out3), 1)\n",
    "        \n",
    "        out = out.view(out.size(0), -1)\n",
    "    \n",
    "        # Linear function (readout)\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvPoolLayer(\n",
      "  (ngram1): Sequential(\n",
      "    (0): Conv2d(1, 100, kernel_size=(3, 300), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=(106, 1), stride=(106, 1), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (ngram2): Sequential(\n",
      "    (0): Conv2d(1, 100, kernel_size=(4, 300), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=(105, 1), stride=(105, 1), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (ngram3): Sequential(\n",
      "    (0): Conv2d(1, 100, kernel_size=(5, 300), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=(104, 1), stride=(104, 1), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=300, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=100, out_features=3, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = ConvPoolLayer(num_classes)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1, 3, 300])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 4, 300])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 5, 300])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 300])\n",
      "torch.Size([100])\n",
      "torch.Size([3, 100])\n",
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "for p in model.parameters():\n",
    "    print(p.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 50. Loss: 0.31396234035491943.\n",
      "Iteration: 100. Loss: 0.0474594384431839.\n",
      "Iteration: 150. Loss: 0.014495435170829296.\n",
      "Iteration: 200. Loss: 0.00440555065870285.\n",
      "Iteration: 250. Loss: 0.0033106759656220675.\n",
      "Iteration: 300. Loss: 0.007108855061233044.\n",
      "Iteration: 350. Loss: 0.004987960681319237.\n"
     ]
    }
   ],
   "source": [
    "avg_losses = list()\n",
    "iter = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        total_loss = list()\n",
    "        \n",
    "        # Load images as Variable\n",
    "        images = Variable(images) # Now we dont need to resize like images.view(xx)\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        # Clear gradients w.r.t parameters\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass to get output/logits\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # Calculate Loss: Softmax --> cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Getting gradients w.r.t paramters\n",
    "        loss.backward()\n",
    "        \n",
    "        # Track loss to plot the result\n",
    "        total_loss.append(loss.item())\n",
    "        \n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        iter += 1\n",
    "        \n",
    "        if iter % 50 == 0:\n",
    "            # Print Loss\n",
    "            print('Iteration: {}. Loss: {}.'.format(iter, loss.item()))\n",
    "            avg_loss = np.divide(np.sum(total_loss), len(total_loss))\n",
    "            avg_losses.append(avg_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the loss vs iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_axis = np.arange(len(avg_losses))\n",
    "plt.plot(x_axis, avg_losses, label='train')\n",
    "plt.xlabel('iterations (x100)')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model with test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 250 test images: 98.07692307692308 %\n"
     ]
    }
   ],
   "source": [
    "n_test = len(test_loader) * batch_size\n",
    "wrong_predictions = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels, revs in test_loader:\n",
    "        images = Variable(images)\n",
    "        labels = Variable(labels)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        # See which are error predictions\n",
    "        result = (predicted == labels)\n",
    "        err_imgs = images[result == 0] # 0 means wrong prediction\n",
    "        err_labels = labels[result == 0]\n",
    "        err_p = outputs[result == 0]\n",
    "        err_outputs = predicted[result == 0]\n",
    "        err_texts = np.array(revs['text'])[np.array((result == 0).numpy(), dtype=np.bool)]\n",
    "        for img, lbl, p, out, text in zip(err_imgs, err_labels, err_p, err_outputs, err_texts):\n",
    "            wrong_predictions.append((img, lbl, p, out, text))\n",
    "     \n",
    "    print('Test Accuracy of the model on the {} test images: {} %'.format(n_test, 100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True label:  0 \t エンタメ系\n",
      "Predition:  2 \t 暮らし系\n",
      "Possibility: tensor([-0.0631, -8.0196,  3.4800])\n",
      "ガルパ に 登場 する キャラクター たち の 日常 を 描い た ４ コマ 漫画 、 『 もっと ！ ガルパライフ 』 （# ガルパラ ） を 更新 し まし た 第 94 話 「 元気 の 出 ない とき に 」 今 まで の お話 は こちら → # バンドリ # ガ \n",
      "\n",
      "True label:  1 \t 美容系\n",
      "Predition:  2 \t 暮らし系\n",
      "Possibility: tensor([-1.8939, -0.1490,  0.1608])\n",
      "全 地 に 告げよ う 鎮痛 剤 が 飲め ない 人 の 偏頭痛 の 治し 方 ⓵ 目薬 で 目 に 潤い を ⓶ 首筋 に サロン パス を 貼る ⓷ 硬く 分厚い 本 を 枕 に し て ゆっくり と 首 を 左右 に ⓸ 長時間 寝る と 返っ て 悪く なる ので こまめ に 寝る ⓹ 適量 の コーヒー を 飲む god is love . \n",
      "\n",
      "True label:  2 \t 暮らし系\n",
      "Predition:  0 \t エンタメ系\n",
      "Possibility: tensor([ 2.3078, -3.7430, -1.0186])\n",
      "だいたい ３ ０ ０ ０ 円 前後 な の か な ・ ・ ・ カード ゲーム 全然 やっ て ない から プレイマット って どういう 風 に 収納 し たり する の か わかっ て ない けど 折りたたん じゃう の か な ？ それとも 巻物 みたい に クルクル 巻く の か な ・ ・ ・ \n",
      "\n",
      "True label:  2 \t 暮らし系\n",
      "Predition:  1 \t 美容系\n",
      "Possibility: tensor([-6.3816,  4.4567,  0.1300])\n",
      "料理 や 野菜 など に 含ま れ て いる 水分 で は なく 、 水 自体 （ ミネラル ウォーター 等 ） を 1 時間 に コップ 1 杯 飲む と いい らしい です よ 。 この こと を 習慣 化 さ せる と 、 脳 梗塞 が 予防 できる ん だ とか ！ # 美容 # 健康 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "label_names = ['エンタメ系', '美容系', '暮らし系']\n",
    "# unpack img, lbl, out, text\n",
    "for img, lbl, p, out, text in wrong_predictions:\n",
    "    print('True label: ', lbl.item(), '\\t', label_names[lbl.item()])\n",
    "    print('Predition: ', out.item(), '\\t', label_names[out.item()])\n",
    "    print('Possibility:', p)\n",
    "    print(text, '\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model with train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 1900 train images: 99.78494623655914 %\n"
     ]
    }
   ],
   "source": [
    "n_train = len(train_loader) * batch_size\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in train_loader:\n",
    "        images = Variable(images)\n",
    "        labels = Variable(labels)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "    print('Test Accuracy of the model on the {} train images: {} %'.format(n_train, 100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict single inputted text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input the text to predict (change the text below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_to_predict = \"お風呂掃除でいつも落ちなかった溝にある黒カビが家事えもんの塩素系漂白剤＋片栗粉でほぼ真っ白になって感動 家事えもんのテクニック凄い～！\"\n",
    "\n",
    "text_to_predict = \"コスメの最安値が見つけられるアプリ💄💋メイク動画とか 美容情報も載ってるし最高😆🙌📲http://goo.gl/K5Fmea 女子にはほんとに助かる〜💗\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data...\n",
      "data loaded!\n",
      "number of sentences: 2068\n",
      "vocab size: 10329\n",
      "max sentence length: 100\n",
      "loading word2vec vectors...\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "from process_data import build_single_data_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_make_idx_data_cv_2vec(revs, U, word_idx_map, max_l=51, k=300, filter_h=5):\n",
    "    \"\"\"\n",
    "    Transforms sentences into a 2-d matrix.\n",
    "    \"\"\"\n",
    "    test_image, test_label = [], []\n",
    "    test_rev = []\n",
    "    for rev in revs:\n",
    "        sent = get_idx_from_sent_2vec(rev[\"text\"], U, word_idx_map, max_l, k, filter_h) # one sentence\n",
    "        test_image.append(sent) \n",
    "        test_label.append(rev[\"y\"])\n",
    "        test_rev.append(rev)\n",
    "\n",
    "    test_image = np.array(test_image)\n",
    "    test_label = np.array(test_label)\n",
    "    test_rev = np.array(test_rev)\n",
    "    return test_image, test_label, test_rev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1行処理済み\n"
     ]
    }
   ],
   "source": [
    "single_revs, _ = build_single_data_cv(text_to_predict)\n",
    "single_data_2vec = single_make_idx_data_cv_2vec(single_revs, U, word_idx_map, max_l, k=300, filter_h=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 1 美容系\n",
      "Text: コスメ の 最 安値 が 見つけ られる アプリメイク 動画 とか 美容 情報 も 載っ てる し 最高 女子 に は ほんとに 助かる 〜\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    images, labels, revs = single_data_2vec\n",
    "    images = Variable(torch.Tensor(images.reshape(1, 1, -1, 300)))\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    print('Prediction:', predicted.item(), label_names[predicted.item()])\n",
    "    print('Text:', revs[0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
