{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import cPickle (python2.7)\n",
    "#http://testpy.hatenablog.com/entry/2017/03/17/000626\n",
    "import _pickle as cPickle\n",
    "\n",
    "import numpy as np\n",
    "from collections import defaultdict, OrderedDict\n",
    "\n",
    "import re\n",
    "import sys\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameters\n",
    "num_epochs = 10\n",
    "num_classes = 3\n",
    "batch_size = 50\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load pickle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the pickle file contains [revs, W2, word_idx_map, vocab] # W2 random vectors\n",
    "x = cPickle.load(open(\"tweet.p\",\"rb\"), encoding=\"latin1\") # Add encoding=\"latin1\" because got UnicodeDecodeError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset content\n",
    "Get data from twitter (reference: http://tech.wonderpla.net/entry/2017/10/10/110000)\n",
    "- Label 0\n",
    "    - KEYWORD = \"芸能 OR アニメ OR 漫画 OR ドラマ OR ゲーム\"            #エンタメ系のキーワード\n",
    "    - CLASS_LABEL = \"\\__label__0\"\n",
    "\n",
    "- Label 1\n",
    "    - KEYWORD = \"美容 OR サロン OR エステ OR 化粧 OR 保湿\"            #美容系のキーワード\n",
    "    - CLASS_LABEL = \"\\__label__1\"\n",
    "\n",
    "- Label 2\n",
    "    - KEYWORD = \"日常 OR 料理 OR 家事 OR 収納 OR 家具\"            #暮らし系のキーワード\n",
    "    - CLASS_LABEL = \"\\__label__2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### See data sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_words</th>\n",
       "      <th>split</th>\n",
       "      <th>text</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>この まま 芸能 界 入っ ちゃお う か な ぁぁ ww くたばれ レッズ ！</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>はあ ！ ？！！？？！？ この ゲーム の 製作 者 頭 おかしい ん じゃ ない の ！ ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     num_words  split                                               text  y\n",
       "311         14      4           この まま 芸能 界 入っ ちゃお う か な ぁぁ ww くたばれ レッズ ！  0\n",
       "104         16      0  はあ ！ ？！！？？！？ この ゲーム の 製作 者 頭 おかしい ん じゃ ない の ！ ...  0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(x[0])\n",
    "\n",
    "# label 0: Entertainment \n",
    "df[df['y'] == 0].sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_words</th>\n",
       "      <th>split</th>\n",
       "      <th>text</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>おれ に 化粧 さ せ て</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>美容 コラム 、 髪 の ボリューム を 出す 為 に は ？ ー アメブロ を 更新 し ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     num_words  split                                               text  y\n",
       "868          6      7                                      おれ に 化粧 さ せ て  1\n",
       "772         21      7  美容 コラム 、 髪 の ボリューム を 出す 為 に は ？ ー アメブロ を 更新 し ...  1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# label 1 : Beauty\n",
    "df[df['y'] == 1].sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_words</th>\n",
       "      <th>split</th>\n",
       "      <th>text</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1464</th>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>幾たび の 料理 場 を 超え て 思う</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098</th>\n",
       "      <td>33</td>\n",
       "      <td>6</td>\n",
       "      <td>「 やっぱり 料理 くらい でき た 方 が いい の かしら ？ あたし が 料理 の 練...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      num_words  split                                               text  y\n",
       "1464          8      6                               幾たび の 料理 場 を 超え て 思う  2\n",
       "1098         33      6  「 やっぱり 料理 くらい でき た 方 が いい の かしら ？ あたし が 料理 の 練...  2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# label 2: Life\n",
    "df[df['y'] == 2].sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "revs, W2, word_idx_map, vocab = x[0], x[1], x[2], x[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max sentence length:  100\n"
     ]
    }
   ],
   "source": [
    "# Get the number of the longest sentence\n",
    "max_l = np.max(pd.DataFrame(revs)[\"num_words\"])\n",
    "print(\"max sentence length: \", max_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "revs 1488\n",
      "W2 8542\n",
      "word_idx_map 8541\n",
      "vocab 8541\n"
     ]
    }
   ],
   "source": [
    "print('revs',len(x[0])) # number of sentence\n",
    "print('W2', len(x[1])) # W2 are randomly initialized vectors\n",
    "print('word_idx_map', len(x[2]))\n",
    "print('vocab', len(x[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'y': 0,\n",
       " 'text': 'え 、 サラリーマン し ながら 、 商業 漫画 の 仕事 を し て 、 ツイッター に 定期 的 に 漫画 を あげ て 、 さらに コミケ の 原稿 を 作る ！ ？',\n",
       " 'num_words': 32,\n",
       " 'split': 3}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "revs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "U = W2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8542, 300)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make dataset (check original code)\n",
    "make each sentence an word index map using word_idx_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_idx_from_sent(sent, word_idx_map, max_l=51, k=300, filter_h=5):\n",
    "    \"\"\"\n",
    "    Transforms sentence into a list of indices. Pad with zeroes.\n",
    "    \"\"\"\n",
    "    x = []\n",
    "    pad = filter_h - 1\n",
    "    for i in range(pad):\n",
    "        x.append(0)\n",
    "    words = sent.split()\n",
    "    for word in words:\n",
    "        if word in word_idx_map:\n",
    "            x.append(word_idx_map[word])\n",
    "    while len(x) < max_l + 2*pad:\n",
    "        x.append(0)\n",
    "    return x\n",
    "\n",
    "def make_idx_data_cv(revs, word_idx_map, cv, max_l=51, k=300, filter_h=5):\n",
    "    \"\"\"\n",
    "    Transforms sentences into a 2-d matrix.\n",
    "    \"\"\"\n",
    "    train, test = [], []\n",
    "    for rev in revs:\n",
    "        sent = get_idx_from_sent(rev[\"text\"], word_idx_map, max_l, k, filter_h) # one sentence\n",
    "        sent.append(rev[\"y\"])\n",
    "        if rev[\"split\"]== cv:  # \"split\" is random number of np.random.randint(0,10)\n",
    "            test.append(sent)        \n",
    "        else:  \n",
    "            train.append(sent)   \n",
    "    train = np.array(train, dtype=\"int\")\n",
    "    test = np.array(test, dtype=\"int\")\n",
    "    return [train, test] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "datasets = make_idx_data_cv(revs, word_idx_map, i, max_l, k=300, filter_h=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example of sentence to word index map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'y': 0,\n",
       " 'text': 'え 、 サラリーマン し ながら 、 商業 漫画 の 仕事 を し て 、 ツイッター に 定期 的 に 漫画 を あげ て 、 さらに コミケ の 原稿 を 作る ！ ？',\n",
       " 'num_words': 32,\n",
       " 'split': 3}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "revs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0, 36, 31, 33,  1, 43, 31, 47,  6, 46, 34, 39,  1, 25,\n",
       "       31, 44, 13, 38, 49, 13,  6, 39, 45, 25, 31, 35, 48, 46, 41, 39, 37,\n",
       "       42, 40,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(datasets[0][0]))\n",
    "datasets[0][1] # sentence => word index map padding with zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data size: (1358, 109)\n",
      "test data size: (130, 109)\n"
     ]
    }
   ],
   "source": [
    "print('train data size:', datasets[0].shape)\n",
    "print('test data size:', datasets[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make dataset (using vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_idx_from_sent_2vec(sent, U, word_idx_map, max_l=51, k=300, filter_h=5):\n",
    "    \"\"\"\n",
    "    Transforms sentence into a list of indices. Pad with zeroes.\n",
    "    \"\"\"\n",
    "    pad = filter_h - 1\n",
    "    x = np.zeros((max_l+2*pad, k))\n",
    "\n",
    "    words = sent.split()\n",
    "    # starting after padding\n",
    "    i = pad\n",
    "    for word in words:\n",
    "        if word in word_idx_map:\n",
    "            x[i] = U[word_idx_map[word]]\n",
    "            i += 1\n",
    "    return x\n",
    "\n",
    "def make_idx_data_cv_2vec(revs, U, word_idx_map, cv, max_l=51, k=300, filter_h=5):\n",
    "    \"\"\"\n",
    "    Transforms sentences into a 2-d matrix.\n",
    "    \"\"\"\n",
    "    train_image, train_label = [], []\n",
    "    test_image, test_label = [], []\n",
    "    test_rev = []\n",
    "    for rev in revs:\n",
    "        sent = get_idx_from_sent_2vec(rev[\"text\"], U, word_idx_map, max_l, k, filter_h) # one sentence\n",
    "        if rev[\"split\"] == cv:  # \"split\" is random number of np.random.randint(0,10)\n",
    "            test_image.append(sent) \n",
    "            test_label.append(rev[\"y\"])\n",
    "            test_rev.append(rev)\n",
    "        else:  \n",
    "            train_image.append(sent)\n",
    "            train_label.append(rev[\"y\"])\n",
    "    train_image = np.array(train_image)\n",
    "    train_label = np.array(train_label)\n",
    "    test_image = np.array(test_image)\n",
    "    test_label = np.array(test_label)\n",
    "    test_rev = np.array(test_rev)\n",
    "    return (train_image, train_label), (test_image, test_label, test_rev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence length(before) 108\n"
     ]
    }
   ],
   "source": [
    "t = \"effective but too tepid biopic\"\n",
    "t_sent_2vec = get_idx_from_sent_2vec(t, W2, word_idx_map, max_l, k=300, filter_h=5)\n",
    "print(\"sentence length(before)\", len(t_sent_2vec)) # max_l(51)+2*pad(filter_h-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_sent_2vec[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "datasets_2vec = make_idx_data_cv_2vec(revs, W2, word_idx_map, i, max_l, k=300, filter_h=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_image, train_label), (test_image, test_label, test_rev) = datasets_2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example of sentence to vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'y': 0,\n",
       " 'text': 'え 、 サラリーマン し ながら 、 商業 漫画 の 仕事 を し て 、 ツイッター に 定期 的 に 漫画 を あげ て 、 さらに コミケ の 原稿 を 作る ！ ？',\n",
       " 'num_words': 32,\n",
       " 'split': 3}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "revs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(108, 300)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.103267</td>\n",
       "      <td>-0.101774</td>\n",
       "      <td>-0.065072</td>\n",
       "      <td>-0.149400</td>\n",
       "      <td>-0.076861</td>\n",
       "      <td>0.073727</td>\n",
       "      <td>-0.247143</td>\n",
       "      <td>-0.089762</td>\n",
       "      <td>0.066734</td>\n",
       "      <td>-0.076508</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.170033</td>\n",
       "      <td>-0.186460</td>\n",
       "      <td>0.011179</td>\n",
       "      <td>-0.168399</td>\n",
       "      <td>0.128894</td>\n",
       "      <td>0.088277</td>\n",
       "      <td>-0.231706</td>\n",
       "      <td>0.141850</td>\n",
       "      <td>0.117991</td>\n",
       "      <td>-0.089826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.216971</td>\n",
       "      <td>-0.115544</td>\n",
       "      <td>0.075365</td>\n",
       "      <td>0.133743</td>\n",
       "      <td>0.135005</td>\n",
       "      <td>0.037995</td>\n",
       "      <td>0.107325</td>\n",
       "      <td>-0.194571</td>\n",
       "      <td>-0.201864</td>\n",
       "      <td>-0.044679</td>\n",
       "      <td>...</td>\n",
       "      <td>0.227335</td>\n",
       "      <td>-0.244615</td>\n",
       "      <td>-0.132227</td>\n",
       "      <td>-0.195423</td>\n",
       "      <td>-0.163361</td>\n",
       "      <td>0.022915</td>\n",
       "      <td>-0.210211</td>\n",
       "      <td>-0.232730</td>\n",
       "      <td>-0.011759</td>\n",
       "      <td>0.211144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.091834</td>\n",
       "      <td>0.041137</td>\n",
       "      <td>-0.185570</td>\n",
       "      <td>-0.066776</td>\n",
       "      <td>-0.193417</td>\n",
       "      <td>0.247414</td>\n",
       "      <td>-0.108982</td>\n",
       "      <td>0.148620</td>\n",
       "      <td>-0.248893</td>\n",
       "      <td>-0.127763</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.066723</td>\n",
       "      <td>0.157050</td>\n",
       "      <td>0.187216</td>\n",
       "      <td>0.000863</td>\n",
       "      <td>-0.169663</td>\n",
       "      <td>-0.098308</td>\n",
       "      <td>0.186280</td>\n",
       "      <td>-0.099669</td>\n",
       "      <td>0.151222</td>\n",
       "      <td>-0.065158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.075166</td>\n",
       "      <td>-0.101351</td>\n",
       "      <td>-0.122343</td>\n",
       "      <td>-0.025718</td>\n",
       "      <td>0.055772</td>\n",
       "      <td>0.184412</td>\n",
       "      <td>-0.030344</td>\n",
       "      <td>-0.157818</td>\n",
       "      <td>0.093645</td>\n",
       "      <td>-0.144344</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.165488</td>\n",
       "      <td>-0.010441</td>\n",
       "      <td>0.143952</td>\n",
       "      <td>-0.097235</td>\n",
       "      <td>-0.220808</td>\n",
       "      <td>0.193234</td>\n",
       "      <td>0.078970</td>\n",
       "      <td>-0.208000</td>\n",
       "      <td>-0.193980</td>\n",
       "      <td>-0.241248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.016946</td>\n",
       "      <td>0.224562</td>\n",
       "      <td>0.023268</td>\n",
       "      <td>-0.075598</td>\n",
       "      <td>0.030105</td>\n",
       "      <td>-0.206579</td>\n",
       "      <td>0.218902</td>\n",
       "      <td>0.047919</td>\n",
       "      <td>0.061500</td>\n",
       "      <td>0.067161</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.216641</td>\n",
       "      <td>-0.197066</td>\n",
       "      <td>-0.186202</td>\n",
       "      <td>-0.057763</td>\n",
       "      <td>-0.177101</td>\n",
       "      <td>0.026063</td>\n",
       "      <td>-0.249339</td>\n",
       "      <td>0.072304</td>\n",
       "      <td>-0.104868</td>\n",
       "      <td>0.222435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.216971</td>\n",
       "      <td>-0.115544</td>\n",
       "      <td>0.075365</td>\n",
       "      <td>0.133743</td>\n",
       "      <td>0.135005</td>\n",
       "      <td>0.037995</td>\n",
       "      <td>0.107325</td>\n",
       "      <td>-0.194571</td>\n",
       "      <td>-0.201864</td>\n",
       "      <td>-0.044679</td>\n",
       "      <td>...</td>\n",
       "      <td>0.227335</td>\n",
       "      <td>-0.244615</td>\n",
       "      <td>-0.132227</td>\n",
       "      <td>-0.195423</td>\n",
       "      <td>-0.163361</td>\n",
       "      <td>0.022915</td>\n",
       "      <td>-0.210211</td>\n",
       "      <td>-0.232730</td>\n",
       "      <td>-0.011759</td>\n",
       "      <td>0.211144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4  0.103267 -0.101774 -0.065072 -0.149400 -0.076861  0.073727 -0.247143   \n",
       "5 -0.216971 -0.115544  0.075365  0.133743  0.135005  0.037995  0.107325   \n",
       "6 -0.091834  0.041137 -0.185570 -0.066776 -0.193417  0.247414 -0.108982   \n",
       "7  0.075166 -0.101351 -0.122343 -0.025718  0.055772  0.184412 -0.030344   \n",
       "8 -0.016946  0.224562  0.023268 -0.075598  0.030105 -0.206579  0.218902   \n",
       "9 -0.216971 -0.115544  0.075365  0.133743  0.135005  0.037995  0.107325   \n",
       "\n",
       "        7         8         9      ...          290       291       292  \\\n",
       "0  0.000000  0.000000  0.000000    ...     0.000000  0.000000  0.000000   \n",
       "1  0.000000  0.000000  0.000000    ...     0.000000  0.000000  0.000000   \n",
       "2  0.000000  0.000000  0.000000    ...     0.000000  0.000000  0.000000   \n",
       "3  0.000000  0.000000  0.000000    ...     0.000000  0.000000  0.000000   \n",
       "4 -0.089762  0.066734 -0.076508    ...    -0.170033 -0.186460  0.011179   \n",
       "5 -0.194571 -0.201864 -0.044679    ...     0.227335 -0.244615 -0.132227   \n",
       "6  0.148620 -0.248893 -0.127763    ...    -0.066723  0.157050  0.187216   \n",
       "7 -0.157818  0.093645 -0.144344    ...    -0.165488 -0.010441  0.143952   \n",
       "8  0.047919  0.061500  0.067161    ...    -0.216641 -0.197066 -0.186202   \n",
       "9 -0.194571 -0.201864 -0.044679    ...     0.227335 -0.244615 -0.132227   \n",
       "\n",
       "        293       294       295       296       297       298       299  \n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "2  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "4 -0.168399  0.128894  0.088277 -0.231706  0.141850  0.117991 -0.089826  \n",
       "5 -0.195423 -0.163361  0.022915 -0.210211 -0.232730 -0.011759  0.211144  \n",
       "6  0.000863 -0.169663 -0.098308  0.186280 -0.099669  0.151222 -0.065158  \n",
       "7 -0.097235 -0.220808  0.193234  0.078970 -0.208000 -0.193980 -0.241248  \n",
       "8 -0.057763 -0.177101  0.026063 -0.249339  0.072304 -0.104868  0.222435  \n",
       "9 -0.195423 -0.163361  0.022915 -0.210211 -0.232730 -0.011759  0.211144  \n",
       "\n",
       "[10 rows x 300 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p2 = pd.DataFrame(train_image[1])\n",
    "print(p2.shape)\n",
    "p2.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make dataset iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1358"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_image = torch.FloatTensor(train_image).reshape(-1, 1, max_l + 2 * (5-1), 300)\n",
    "t_label = torch.LongTensor(train_label)\n",
    "train_dataset = list(zip(t_image, t_label))\n",
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images: torch.Size([50, 1, 108, 300]) \n",
      "labels: torch.Size([50])\n",
      "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])\n",
      "tensor(0)\n"
     ]
    }
   ],
   "source": [
    "for images, labels in train_loader:\n",
    "    print('images:', images.shape, '\\nlabels:', labels.shape)\n",
    "    print(images[1][0])\n",
    "    print(labels[1])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_image = torch.FloatTensor(test_image).reshape(-1, 1, max_l + 2 * (5-1), 300)\n",
    "c_label = torch.LongTensor(test_label)\n",
    "test_dataset = list(zip(c_image, c_label, test_rev))\n",
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loader\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images: torch.Size([50, 1, 108, 300]) \n",
      "labels: torch.Size([50])\n",
      "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])\n",
      "tensor(0)\n",
      "『 中学 時代 に 自分 が 考え た キャラクター の 服 を 着 て 大阪 の 街 を 歩く 』 とかいう 訳 わから ん 地獄 みたい な 仕事 で 精神 が 壊れ た レポ 漫画 を 描き まし た 。 企画 進行 し て くれ たく う か ( ) さん 、 ありがとう ござい まし た ！ 覚え てろ よ 。\n"
     ]
    }
   ],
   "source": [
    "for images, labels, _ in test_loader:\n",
    "    print('images:', images.shape, '\\nlabels:', labels.shape)\n",
    "    print(images[1][0])\n",
    "    print(labels[1])\n",
    "    print(_['text'][1])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model parameters (original code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_hs=[3, 4, 5]\n",
    "hidden_units=[100, num_classes]\n",
    "batch_size=50\n",
    "img_w=300\n",
    "img_h = len(datasets[0][0])-1  # sentence length (subtracted 1 for y label)\n",
    "\n",
    "filter_w = img_w    \n",
    "feature_maps = hidden_units[0]\n",
    "filter_shapes = []\n",
    "pool_sizes = []\n",
    "for filter_h in filter_hs:\n",
    "    filter_shapes.append((feature_maps, 1, filter_h, filter_w))\n",
    "    pool_sizes.append((img_h-filter_h+1, img_w-filter_w+1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(100, 1, 3, 300), (100, 1, 4, 300), (100, 1, 5, 300)]\n",
      "one batch train (50, 1, 108, 300)\n",
      "[(106, 1), (105, 1), (104, 1)]\n"
     ]
    }
   ],
   "source": [
    "print(filter_shapes)\n",
    "image_shape = (batch_size, 1, img_h, img_w)\n",
    "print('one batch train', image_shape)\n",
    "print(pool_sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding & Stride\n",
    "- Output size\n",
    "\n",
    "    $ O = \\frac {W-K+2P}{S} + 1 $\n",
    "    - O: output h/w\n",
    "    - W: input h/w\n",
    "    - K: filter size(kernel size)\n",
    "    - P: padding\n",
    "        - $  P = \\frac {K-1}{2} $\n",
    "    - S: stride"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network\n",
    "\n",
    "- Theano:\n",
    "    - conv_layer: LeNetConvPoolLayer\n",
    "    - classifier: MLPDropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model:\n",
    "\n",
    "\n",
    "```\n",
    "Network\n",
    "Input ->\n",
    "Conv -> ReLU -> MaxPool |\n",
    "Conv -> ReLU -> MaxPool | -> concat\n",
    "Conv -> ReLU -> MaxPool |\n",
    "Fully Connected Layer(Logits -> Softmax) -> Labels\n",
    "```\n",
    "\n",
    "```\n",
    "Convolutional layer formula:\n",
    "- Filter 1(Kernel) size K = 3 => (3 x 300)\n",
    "- P(same padding) P = (3-1)/2=1\n",
    "- S(stride) S = 1\n",
    "- in_channels = 1\n",
    "- out_channels (int) – Number of channels produced by the convolution = 100\n",
    "Pooling layer formula:\n",
    "- K\n",
    "```\n",
    "\n",
    "```\n",
    "*Filter dimensions*:\n",
    "Conv1 (W_conv, (100, 1, 3, 300))\n",
    "Conv1 (b_conv, (100,))\n",
    "Conv2 (W_conv, (100, 1, 4, 300))\n",
    "Conv2 (b_conv, (100,))\n",
    "Conv3 (W_conv, (100, 1, 5, 300))\n",
    "Conv3 (b_conv, (100,))\n",
    "\n",
    "*Layer input dimensions*:\n",
    "- Input image(64, 300) \n",
    "\n",
    "----------------------------------------------------------------------\n",
    "|  Conv1  (100, 3, 300)   Conv2  (100, 4, 300)   Conv3  (100, 5, 300) |\n",
    "|  MaxPool (100, 62, 1)   MaxPool (100, 61, 1)   MaxPool (100, 60, 1) |\n",
    "-----------------------------Concat ----------------------------------\n",
    "\n",
    "- Concatenated (100, 1, 1) + (100, 1, 1) + (100, 1, 1) => (300, 1, 1) \n",
    "\n",
    "- Fully Connected Layer(Logits (100, 1) -> Logits (2, 1) -> Softmax) -> Labels\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvPoolLayer(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(ConvPoolLayer, self).__init__()\n",
    "\n",
    "        # Layer 1: conv - relu - conv- relu - pool\n",
    "        self.ngram1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=feature_maps, kernel_size=(filter_hs[0], img_w), stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=pool_sizes[0], stride=None))\n",
    "        self.ngram2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=feature_maps, kernel_size=(filter_hs[1], img_w), stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=pool_sizes[1], stride=None))\n",
    "        self.ngram3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=feature_maps, kernel_size=(filter_hs[2], img_w), stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=pool_sizes[2], stride=None))\n",
    "        \n",
    "        # Fully Connected 1 (readout)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(feature_maps * 3, hidden_units[0]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_units[0], num_classes))\n",
    "\n",
    "        # Initialize all parameters using kaiming normalization\n",
    "        self.init_weights_kaiming()\n",
    "    \n",
    "    def init_weights_kaiming(self):\n",
    "        #Use kaiming normalization to initialize the parameters\n",
    "        for layer in [self.ngram1, self.ngram2, self.ngram3, self.fc]:\n",
    "            for m in layer:\n",
    "                if type(m) == nn.Conv2d or type(m) == nn.Linear:\n",
    "                    m.weight = nn.init.kaiming_normal_(m.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        out1 = self.ngram1(x)\n",
    "        out2 = self.ngram2(x)\n",
    "        out3 = self.ngram3(x)\n",
    "        out = torch.cat((out1, out2, out3), 1)\n",
    "        \n",
    "        out = out.view(out.size(0), -1)\n",
    "    \n",
    "        # Linear function (readout)\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvPoolLayer(\n",
      "  (ngram1): Sequential(\n",
      "    (0): Conv2d(1, 100, kernel_size=(3, 300), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=(106, 1), stride=(106, 1), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (ngram2): Sequential(\n",
      "    (0): Conv2d(1, 100, kernel_size=(4, 300), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=(105, 1), stride=(105, 1), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (ngram3): Sequential(\n",
      "    (0): Conv2d(1, 100, kernel_size=(5, 300), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=(104, 1), stride=(104, 1), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=300, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=100, out_features=3, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = ConvPoolLayer(num_classes)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1, 3, 300])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 4, 300])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 5, 300])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 300])\n",
      "torch.Size([100])\n",
      "torch.Size([3, 100])\n",
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "for p in model.parameters():\n",
    "    print(p.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 50. Loss: 0.20847491919994354.\n",
      "Iteration: 100. Loss: 0.011980945244431496.\n",
      "Iteration: 150. Loss: 0.003664374351501465.\n",
      "Iteration: 200. Loss: 0.001171835232526064.\n",
      "Iteration: 250. Loss: 0.0013196211075410247.\n"
     ]
    }
   ],
   "source": [
    "avg_losses = list()\n",
    "iter = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        total_loss = list()\n",
    "        \n",
    "        # Load images as Variable\n",
    "        images = Variable(images) # Now we dont need to resize like images.view(xx)\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        # Clear gradients w.r.t parameters\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass to get output/logits\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # Calculate Loss: Softmax --> cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Getting gradients w.r.t paramters\n",
    "        loss.backward()\n",
    "        \n",
    "        # Track loss to plot the result\n",
    "        total_loss.append(loss.item())\n",
    "        \n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        iter += 1\n",
    "        \n",
    "        if iter % 50 == 0:\n",
    "            # Print Loss\n",
    "            print('Iteration: {}. Loss: {}.'.format(iter, loss.item()))\n",
    "            avg_loss = np.divide(np.sum(total_loss), len(total_loss))\n",
    "            avg_losses.append(avg_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the loss vs iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xt4XPV95/H3V7eRbVnyTb5KIxswAXMxBlnj3CgJhEBCbBIgGCsNNGlp07Jtk3SzpO02XfI8+9DNPpum22wTNsk+SSNjbgk4JMEhgUCa4ItsbIMxBsdgW77I8k2SL7p/9485NmNZ0oxszZzRzOf1PPNo5pzfmfPVsWc+Oud3zu+YuyMiIjKUgrALEBGR7KewEBGRpBQWIiKSlMJCRESSUliIiEhSCgsREUlKYSEiIkkpLEREJCmFhYiIJFUUdgEjZcqUKT579uywyxARGVXWr19/0N0rk7XLmbCYPXs2jY2NYZchIjKqmNnOVNrpMJSIiCSlsBARkaQUFiIikpTCQkREklJYiIhIUgoLERFJSmEhIiJJ5X1YtJ7o5uvPvsEbze1hlyIikrXyPiz63Pm3F37Pv7+U0nUpIiJ5Ke/DYuK4Em65YgY/fnkPxzt7wi5HRCQr5X1YANQvinKss4eVm/aGXYqISFZSWABXRydyyfTx/HD1Ttw97HJERLKOwgIwM+pjUbbsbWNzU2vY5YiIZJ20hoWZ3WRm28xsu5ndP8D8L5jZa2a22cx+ZWY1CfPuNrM3g8fd6awT4NYFsxhbUkjDGnV0i4j0l7awMLNC4JvAzcA84C4zm9ev2ctArbtfCTwO/I9g2UnAV4AYUAd8xcwmpqtWgPGlxSy5aiYrN+2l9WR3OlclIjLqpHPPog7Y7u473L0LWAEsSWzg7s+7+4ng5WqgKnj+YeBZdz/s7keAZ4Gb0lgrAMvqaujo7uPHG5rSvSoRkVElnWExC9id8LopmDaYzwI/H86yZnavmTWaWWNLS8t5lgtXVFUwv6qChjW71NEtIpIgnWFhA0wb8BvYzD4F1AJfG86y7v6Qu9e6e21lZdK7AqakPlbDmweOse7tIyPyfiIiuSCdYdEEVCe8rgLOupDBzG4A/g5Y7O6dw1k2HW6ZP4PxpUUsV0e3iMhp6QyLdcBcM5tjZiXAUmBlYgMzWwB8m3hQHEiYtQq40cwmBh3bNwbT0m5sSRG3XV3Fz17Zz+HjXZlYpYhI1ktbWLh7D3Af8S/5rcCj7r7FzB4ws8VBs68BZcBjZrbRzFYGyx4Gvko8cNYBDwTTMmJZLEpXbx+Pr9+dvLGISB6wXOnIra2t9cbGxhF7vzu+9Tta2jt57ovXUVAwUBeKiMjoZ2br3b02WTtdwT2I+lgNbx86we9+fyjsUkREQqewGMRNl09n4thiXdEtIoLCYlClxYXcUVvNL15rprmtI+xyRERCpbAYwl11UXr7nEfXqaNbRPKbwmIIc6aM430XTeHhtbvo7cuNEwFERM6FwiKJ+liUva0d/HrbgeSNRURylMIiiRvmTaNyfISGNbvCLkVEJDQKiySKCwtYurCa57cdoOnIieQLiIjkIIVFCpbWRTFgxVp1dItIflJYpGDWhDF84F1TWbFuN929fWGXIyKScQqLFNUvinLwWCfPvtYcdikiIhmnsEjRH1w8lVkTxuiKbhHJSwqLFBUWGHfVVfPb7YfY0XIs7HJERDJKYTEMn6ytpqjAeHitTqMVkfyisBiGqeWl3HjZNB5b30RHd2/Y5YiIZIzCYpjqYzUcPdHNz1/dF3YpIiIZo7AYpndfMJk5U8bRsFqHokQkfygshqmgwFhWF6Vx5xFe398WdjkiIhmhsDgHt11TRUlRAcs1XpSI5AmFxTmYNK6Ej14xgx9t2MPxzp6wyxERSTuFxTmqj0U51tnDTzbtDbsUEZG0U1ico2tqJvKuaeM1dLmI5AWFxTkyM+oXRXllTyubm46GXY6ISFopLM7DrQtmMaa4UB3dIpLzFBbnoby0mMXzZ/LUxr20dXSHXY6ISNooLM5T/aIoJ7t7efLlPWGXIiKSNgqL83Rl1QSumFVBw+pduHvY5YiIpIXCYgTUx6Jsa25n/c4jYZciIpIWCosR8LH5MxkfKdJptCKSsxQWI2BcpIiPXz2Ln76yj8PHu8IuR0RkxCksRsiyWJSunj6eWN8UdikiIiNOYTFCLpleTm3NRJav3UVfnzq6RSS3KCxGUP2iKG8dPM5LOw6FXYqIyIhSWIygmy+fwYSxxTSs2Rl2KSIiI0phMYJKiwu545oqfrGlmQNtHWGXIyIyYhQWI+yuuig9fc6jjbvDLkVEZMQoLEbYBZVlvPeiyTy8dje96ugWkRyhsEiD+lgNe46e5IU3DoRdiojIiEhrWJjZTWa2zcy2m9n9A8y/1sw2mFmPmd3eb16vmW0MHivTWedI+9C8aVSOj9CwWld0i0huSFtYmFkh8E3gZmAecJeZzevXbBdwD7B8gLc46e5XBY/F6aozHYoLC7iztprnth2g6ciJsMsRETlv6dyzqAO2u/sOd+8CVgBLEhu4+9vuvhnoS2MdoVhaVw3AI+vU0S0io186w2IWkPhN2RRMS1WpmTWa2Wozu3VkS0u/qolj+cC7prJi3W66e3MuC0Ukz6QzLGyAacM5PSjq7rXAMuCfzezCs1Zgdm8QKI0tLS3nWmfa1MeitLR38svXmsMuRUTkvKQzLJqA6oTXVcDeVBd2973Bzx3Ar4EFA7R5yN1r3b22srLy/KpNg+veNZWZFaUaulxERr10hsU6YK6ZzTGzEmApkNJZTWY20cwiwfMpwHuB19JWaZoUFhh31UX5j+0Heevg8bDLERE5Z2kLC3fvAe4DVgFbgUfdfYuZPWBmiwHMbKGZNQF3AN82sy3B4pcCjWa2CXgeeNDdR11YANy5sJrCAuPhtdq7EJHRy3LlvtG1tbXe2NgYdhkD+twP17N6xyFe+vL1lBYXhl2OiMhpZrY+6B8ekq7gzoD6WA1HTnTzzKv7wy5FROScKCwy4D0XTmb25LEaulxERi2FRQYUFBjLYlHWvX2EN5rbwy5HRGTYFBYZcvs11ZQUFrBcp9GKyCiksMiQSeNKuPmK6TyxoYkTXT1hlyMiMiwKiwyqj9XQ3tHD05v2hV2KiMiwKCwyaOHsicydWqaObhEZdRQWGWRm1MeibGpq5ZWm1rDLERFJmcIiwz5+dRWlxQUsX6u9CxEZPRQWGVYxppjF82fy1Ma9tHV0h12OiEhKFBYhqI/VcKKrl6de3hN2KSIiKVFYhODKqgoun1VOw5pd5MrYXCKS2xQWIYh3dNfw+v52Nuw6EnY5IiJJKSxCsnj+TMoiRTSs1hXdIpL9FBYhGRcp4uMLZvH0K/s4crwr7HJERIaksAjRsliUrp4+ntjQFHYpIiJDUliE6NIZ5VxTM1Ed3SKS9RQWIauPRXnr4HFe+v2hsEsRERmUwiJkH7liBhPGFtOgoctFJIspLEJWWlzI7VdXsWrLfg60d4RdjojIgBQWWeCuWJSePuexRnV0i0h2UlhkgQsry3jPhZNZvmYXvX3q6BaR7KOwyBL1sRr2HD3Ji2+0hF2KiMhZFBZZ4kPzpjGlLKIbI4lIVlJYZImSogLuXFjFc68fYM/Rk2GXIyJyBoVFFlm6MIoDj6zVabQikl0UFlmketJYrru4khXrdtPd2xd2OSIipyksskx9rIYD7Z38amtz2KWIiJymsMgyH7hkKjMrSnVFt4hkFYVFliksMJbWRfnNmwfZeeh42OWIiAAKi6x058JqCguM5eroFpEskVJYmNlfmVm5xX3XzDaY2Y3pLi5fTSsv5YZLp/JYYxOdPb1hlyMikvKexWfcvQ24EagE/gh4MG1VCfWxGg4f7+KZV/eHXYqISMphYcHPjwD/z903JUyTNHjfRVOIThqrjm4RyQqphsV6M/sF8bBYZWbjAV0IkEYFBcayWJS1bx3mzeb2sMsRkTyXalh8FrgfWOjuJ4Bi4oeiJI3uuKaK4kLT3oWIhC7VsHg3sM3dj5rZp4C/B1rTV5YATC6LcPPlM3hiQxMnu9TRLSLhSTUs/g04YWbzgS8BO4EfpK0qOa0+FqW9o4efbN4bdikiksdSDYsed3dgCfANd/8GMD59ZckpdXMmcdHUMh2KEpFQpRoW7Wb2ZeAPgZ+aWSHxfoshmdlNZrbNzLab2f0DzL82uGajx8xu7zfvbjN7M3jcnWKdOcfMqI9F2bT7KK/u0ZE/EQlHqmFxJ9BJ/HqL/cAs4GtDLRAEyjeBm4F5wF1mNq9fs13APcDyfstOAr4CxIA64CtmNjHFWnPOJxZUUVpcoL0LEQlNSmERBEQDUGFmtwAd7p6sz6IO2O7uO9y9C1hB/DBW4vu+7e6bOfs03A8Dz7r7YXc/AjwL3JRKrbmoYmwxH7tyJk9t3EN7R3fY5YhIHkp1uI9PAmuBO4BPAmv6HzYawCxgd8LrpmBaKs5n2ZxUv6iGE129PLlRHd0iknmpHob6O+LXWNzt7p8mvtfwX5MsM9AV3p7i+lJa1szuNbNGM2tsaWlJ8a1Hp/lVFVw2s5yG1TuJn2sgIpI5qYZFgbsfSHh9KIVlm4DqhNdVQKp/Fqe0rLs/5O617l5bWVmZ4luPTvGO7hpe39/Ohl1Hwy5HRPJMqmHxjJmtMrN7zOwe4KfAz5Issw6Ya2ZzzKwEWAqsTHF9q4AbzWxi0LF9YzAtry2+aiZlkSIa1uwMuxQRyTOpdnD/Z+Ah4EpgPvCQu/+XJMv0APcR/5LfCjzq7lvM7AEzWwxgZgvNrIl4X8i3zWxLsOxh4KvEA2cd8EAwLa+VRYq4dcFMnt68j6MnusIuR0TyiOXK8e/a2lpvbGwMu4y0e21vGx/5l9/w9x+9lD9+/wVhlyMio5yZrXf32mTthtyzMLN2M2sb4NFuZm0jV66kat7Mcq6OTmD5ml3q6BaRjBkyLNx9vLuXD/AY7+7lmSpSzlQfq2HHweO8tONQ2KWISJ7QPbhHoY9eOYOKMcW6oltEMkZhMQqVFhdy+zVVrHp1Py3tnWGXIyJ5QGExSi2LRenpcx5t3J28sYjIeVJYjFIXVpbx7gsm8/DaXfT2qaNbRNJLYTGK1S+K0nTkJC++mdtDnYhI+BQWo9iN86YzpayEhtXq6BaR9FJYjGIlRQV8sraa515vZl/rybDLEZEcprAY5e6qi+LAirXq6BaR9FFYjHLVk8Zy7dxKVqzbRU9v/3tIiYiMDIVFDqiPRWlu6+RXrx9I3lhE5BwoLHLABy+ZyvTyUl3RLSJpo7DIAUWFBSytq+bFN1rYdehE2OWISA5SWOSIpQujFBYYy9dq70JERp7CIkdMryjl+kum8ljjbjp7esMuR0RyjMIih9QvquHQ8S5WbWkOuxQRyTEKixzy/oumUD1pDA2rdY9uERlZCoscUlBgLKurYc1bh9l+oD3sckQkhygscswdtVUUF5pOoxWREaWwyDFTyiLcdPkMnljfxMkudXSLyMhQWOSg+liUto4ent68N+xSRCRHKCxyUGzOJC6sHKdDUSIyYhQWOcjMqI/VsHH3UV7d0xp2OSKSAxQWOeq2q6uIFBXoim4RGREKixxVMbaYj82fyVMv7+FYZ0/Y5YjIKKewyGH1sSjHu3p58uU9YZciIqOcwiKHXVU9gXkzymlYswt3D7scERnFFBY5zMyoXxRl6742Xt59NOxyRGQUU1jkuCVXzWJcSSENq9XRLSLnTmGR48oiRdy6YBZPb97L0RNdYZcjIqOUwiIP1Mdq6Ozp44kN6ugWkXOjsMgD82aWsyA6gYY1O9XRLSLnRGGRJ+pjNexoOc7qHYfDLkVERiGFRZ645coZlJcW6YpuETknCos8UVpcyG3XVPHMq/s4eKwz7HJEZJRRWOSR+liU7l7nscamsEsRkVFGYZFHLpo6nticSSxfu5O+PnV0i0jqFBZ5pn5RDbsPn+Q32w+GXYqIjCJpDQszu8nMtpnZdjO7f4D5ETN7JJi/xsxmB9Nnm9lJM9sYPL6VzjrzyYcvm8bkcSU0rN4ZdikiMoqkLSzMrBD4JnAzMA+4y8zm9Wv2WeCIu18EfB34p4R5v3f3q4LHn6WrznwTKSrkjtpqfvX6Afa1ngy7HBEZJdK5Z1EHbHf3He7eBawAlvRrswT4fvD8ceB6M7M01iTAsroovX3OI+t2h12KiIwS6QyLWUDit1FTMG3ANu7eA7QCk4N5c8zsZTN7wczeP9AKzOxeM2s0s8aWlpaRrT6HRSeP5dqLK1mxdjc9vX1hlyMio0A6w2KgPYT+p+AM1mYfEHX3BcAXgOVmVn5WQ/eH3L3W3WsrKyvPu+B8Uh+Lsr+tg+dePxB2KSIyCqQzLJqA6oTXVcDewdqYWRFQARx29053PwTg7uuB3wMXp7HWvHP9JVOZVh6hYY2u6BaR5NIZFuuAuWY2x8xKgKXAyn5tVgJ3B89vB55zdzezyqCDHDO7AJgL7EhjrXmnqLCApQujvPhmC7sOnQi7HBHJcmkLi6AP4j5gFbAVeNTdt5jZA2a2OGj2XWCymW0nfrjp1Om11wKbzWwT8Y7vP3N3jYA3wpbWVWPAw+u0dyEiQ7NcGbK6trbWGxsbwy5j1PmTHzSyYecRXvry9ZQU6RpNkXxjZuvdvTZZO3075Ln6WJRDx7tYtWV/2KWISBZTWOS5a+dWUjVxDA1rdEW3iAxOYZHnCgqMZbEoq3ccZvuBY2GXIyJZSmEh3HFNNcWFxnKdRisig1BYCJXjI3z4suk8vn43Hd29YZcjIllIYSFA/B7dbR09PL15X9iliEgWUlgIAIsumMQFlePU0S0iA1JYCABmRn2shpd3HWXL3tawyxGRLKOwkNNuu3oWkaICdXSLyFkUFnLahLEl3HLlTJ58eQ/HOnvCLkdEsojCQs5QvyjK8a5entq4J+xSRCSLKCzkDAuqJ3DpjHJ+uHoXuTJumIicP4WFnCHe0R1l6742Nu4+GnY5IpIlFBZyllsXzGJcSaE6ukXkNIWFnKUsUsTiq2bxk817aT3RHXY5IpIFFBYyoPpYlI7uPn70clPYpYhIFlBYyIAun1XB/OoJNKxRR7eIKCxkCPWxKNsPHGPtW7qjrUi+U1jIoD525UzGlxbRoI5ukbynsJBBjSkp5Larq/j5q/s4eKwz7HJEJEQKCxlSfSxKd6/z+Hp1dIvkM4WFDGnutPHUzZnE8jW76OtTR7dIvlJYSFL1sSi7Dp/gP7YfDLsUEQmJwkKSuuny6UwaV6IbI4nkMYWFJBUpKuSO2ip+ufUA+1s7wi5HREKgsJCULKuL0tvnPLJud9iliEgIFBaSkprJ43j/3CmsWLeLnt6+sMsRkQxTWEjK6mM17Gvt4PltLWGXIiIZprCQlF1/6VSmlUfU0S2ShxQWkrLiwgLuXBjlhTdaeLO5XQMMiuSRorALkNFl6cJq/s/z2/nQ118kUlTAtPJSppeXMq2ilGnjI0yvKGVaeenp6VPLI5QWF4ZdtoicJ4WFDMvMCWP40Z+/h7VvHeZAeyf7WzvY39bBK01Hebatg47uszu/J4wtjgdKeSnTyiMJ4VJ6OlwmjyuhoMBC+I1EJBUKCxm2K6smcGXVhLOmuzttJ3vY39ZBc1s8RJpbO2hu72B/ayfNbR1s3ddGy7FO+h/BKiowpo6PnBUiZ4RLeSllEf2XFQmDPnkyYsyMirHFVIwt5l3Txw/arqe3j5ZjnTS3xfdMmhPDpa2D7S3H+O32g7R39py1bFmkKB4gQahMqwgOg5VH4oe+KkqZUhahuFDdcSIjSWEhGVdUWMCMijHMqBgD1YO3O975zl5Kc9s7eyengmXNW4dpbuugp98Ah2YwpSxyZoicOgyWEC4VY4ox06EvkVQoLCRrjYsUcWFlGRdWlg3apq/POXS8q9/eSSfNQV9K05GTrN95hCMnus9aNlJU0G8PJfJO53wwXR30InEKCxnVCgqMyvERKsdHuHxWxaDtOrp7aWnvZH9bR79DX/Fg2dx0lF+0dtDZc3YH/cSxxWec4TWtPJKwh6IOeskPCgvJC6XFhVRPGkv1pLGDtnF3Wk92x/tSTnXOJ/SlNLd18tq+Ng4m6aBPDJHpFRGmjS+lfEwxkaICIkWFRIoL3nleVKCQkVEhrWFhZjcB3wAKge+4+4P95keAHwDXAIeAO9397WDel4HPAr3AX7r7qnTWKmJmTBhbwoSxJUN20Hf39nHwWGLn/Dvhsr+tgzea2/nNmwc5NkAH/UCKC+10cESKCogUJzwfIFzir5O1P3u50jOWi88vKVRYSWrSFhZmVgh8E/gQ0ASsM7OV7v5aQrPPAkfc/SIzWwr8E3Cnmc0DlgKXATOBX5rZxe7em656RVJVnNhBP4RjnT3xMGnt4FhnD509fcGjl87uhOc9fcHr3nfadPeenn+ss4dDxwabf/6DOpYUFpwVQiUjFloKq1yRzj2LOmC7u+8AMLMVwBIgMSyWAP8YPH8c+FeLn56yBFjh7p3AW2a2PXi/l9JYr8iIKosUUZakg/58uTtdvX1nB86g4XOuYdWV0bA6FSCnhpQ5fdTPz/hx1nw/Pd/PfN3vsOFZ7zvUsv3mM+j8QWoZYF3n/HuctXz8yfyqCTz+ufeQTukMi1lA4s0PmoDYYG3cvcfMWoHJwfTV/Zadlb5SRUYns1OHsAqhNPPrT0dYdXT3nvnlbmf8OH268zuvh57/zvI2SPvEVfVr0+9NBlt28Pc+c69pyHX1f89h/B4zJgy9lzsS0hkWA+1b9h95brA2qSyLmd0L3AsQjUaHW5+InKeww0oyJ52XuTZx5iVXVcDewdqYWRFQARxOcVnc/SF3r3X32srKyhEsXUREEqUzLNYBc81sjpmVEO+wXtmvzUrg7uD57cBzHj94txJYamYRM5sDzAXWprFWEREZQtoOQwV9EPcBq4ifOvs9d99iZg8Aje6+Evgu8O9BB/Zh4oFC0O5R4p3hPcBf6EwoEZHwWK7cwKa2ttYbGxvDLkNEZFQxs/XuXpusnYbmFBGRpBQWIiKSlMJCRESSUliIiEhSOdPBbWYtwM7zeIspwMERKmckqa7hUV3Do7qGJxfrqnH3pBeq5UxYnC8za0zljIBMU13Do7qGR3UNTz7XpcNQIiKSlMJCRESSUli846GwCxiE6hoe1TU8qmt48rYu9VmIiEhS2rMQEZGk8ioszOwmM9tmZtvN7P4B5kfM7JFg/hozm50ldd1jZi1mtjF4/HGG6vqemR0ws1cHmW9m9i9B3ZvN7Oosqes6M2tN2F7/kKG6qs3seTPbamZbzOyvBmiT8W2WYl0Z32ZmVmpma81sU1DXfxugTcY/kynWFcpnMlh3oZm9bGZPDzAvfdvL3fPiQXzk298DFwAlwCZgXr82fw58K3i+FHgkS+q6B/jXELbZtcDVwKuDzP8I8HPiN6taBKzJkrquA54OYXvNAK4Ono8H3hjg3zLj2yzFujK+zYJtUBY8LwbWAIv6tQnjM5lKXaF8JoN1fwFYPtC/Vzq3Vz7tWZy+J7i7dwGn7gmeaAnw/eD548D11v++iOHUFQp3f5H40PGDWQL8wONWAxPMbEYW1BUKd9/n7huC5+3AVs6+HXDGt1mKdWVcsA2OBS+Lg0f/TtSMfyZTrCsUZlYFfBT4ziBN0ra98iksBroneP8PzBn3BAdO3RM87LoAbgsOWzxuZtUDzA9DqrWH4d3BYYSfm9llmV55sPu/gPhfpYlC3WZD1AUhbLPgkMpG4ADwrLsPur0y+JlMpS4I5zP5z8CXgL5B5qdte+VTWJzPPcHTKZV1/gSY7e5XAr/knb8cwhbG9krFBuJDGMwH/jfwZCZXbmZlwBPAX7t7W//ZAyySkW2WpK5Qtpm797r7VcRvnVxnZpf3axLK9kqhrox/Js3sFuCAu68fqtkA00Zke+VTWJzPPcFDrcvdD7l7Z/Dy/wLXpLmmVKV0r/RMc/e2U4cR3P1nQLGZTcnEus2smPgXcoO7/2iAJqFss2R1hbnNgnUeBX4N3NRvVhifyaR1hfSZfC+w2MzeJn64+oNm9sN+bdK2vfIpLM7nnuCh1tXvmPZi4secs8FK4NPBGT6LgFZ33xd2UWY2/dRxWjOrI/7//FAG1mvEbxW81d3/1yDNMr7NUqkrjG1mZpVmNiF4Pga4AXi9X7OMfyZTqSuMz6S7f9ndq9x9NvHviefc/VP9mqVte6XtHtzZxs/jnuBZUNdfmtli4vcjP0z8TIy0M7OHiZ8lM8XMmoCvEO/sw92/BfyM+Nk924ETwB9lSV23A58zsx7gJLA0A6EP8b/8/hB4JTjeDfC3QDShtjC2WSp1hbHNZgDfN7NC4uH0qLs/HfZnMsW6QvlMDiRT20tXcIuISFL5dBhKRETOkcJCRESSUliIiEhSCgsREUlKYSEiIkkpLEREJCmFhYx6Zva74OdsM1s2wu/9twOtK13M7FZLMjy4md0RDJ3dZ2a1/eZ9ORieepuZfThh+oDD4JvZCjObO/K/ieQaXWchOcPMrgP+xt1vGcYyhe7eO8T8Y+5eNhL1pVjP74DF7n5wiDaXEh9I7tvEf9/GYPo84GHiIxnPJD5m0cXBYm8AHyI+HMQ64C53f83M/gD4lLv/SZp+JckR2rOQUc/MTg0n/SDwfovfjObzwcihXzOzdcHooH8atL/O4jcDWg68Ekx70szWB3+x3xtMexAYE7xfQ+K6guE6vmZmr5rZK2Z2Z8J7/9riI5G+bmYNCcNoPGhmrwW1/M8Bfo+Lgc5TQWFmT5nZp4Pnf3qqBnff6u7bBtgUS4AV7t7p7m8Rv0q8jqGHwf8NcIPFxxESGZT+g0guuZ+EPYvgS7/V3ReaWQT4rZn9ImhbB1wefKkCfMbdDwdjAa0zsyfc/X4zuy8YfbS/TwBXAfOBKcEyLwbzFgCXER8g8LfAe83sNeDjwCXu7qfGHurnvcRHfz3l3qDmt4AvEr9Z0lBmAasTXicOf95/WPQYgLv3BUNDzAeGGs1U8pz2LCSX3Uh80L6NxO/fMBk4dXx+bUJQQHysn03Ev2yrE9oN5n3Aw8FQ1s3AC8DChPducvc+YCMwG2gDOoDvmNkniI98QqKfAAABwElEQVQL1d8MoOXUi+B9/wF4HviiuycbPXSw4amTDVt9gPhhK5FBac9CcpkB/8ndV50xMd63cbzf6xuAd7v7CTP7NVCawnsPpjPheS9QFAwYWQdcT3xwt/uAD/Zb7iTxIaUTXUF89NdUvsyHGv58qGHRS4N1iwxKexaSS9qJ32P6lFXER1IthnifgJmNG2C5CuBIEBSXcObhnu5Ty/fzInBn0C9SSfy+4GsHK8ziNx6qCO4V8dfED2H1txW4KGGZOuBm4oe1/sbM5gz2/oGVwFIziwRt5wY1JRsG/2JgS5L3ljynsJBcshnosfitQT9P/D7FrwEbzOxV4mcPDbQ3/QxQZGabga9y5nH/h4DNpzqXE/w4WN8m4DngS+6+f4jaxgNPB+t4Afj8AG1eBBYEnecR4jfV+Yy77yXeZ/G9YN7HLT40+7uBn5rZKgB33wI8GvzOzwB/ERwm6yG+J7OKeCA9GrTFzKYBJ7PhPiSS3XTqrEgWMbNvAD9x919maH2fB9rc/buZWJ+MXtqzEMku/x0Ym8H1HSV77ukuWUx7FiIikpT2LEREJCmFhYiIJKWwEBGRpBQWIiKSlMJCRESS+v8bRF8dFZiY1wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_axis = np.arange(len(avg_losses))\n",
    "plt.plot(x_axis, avg_losses, label='train')\n",
    "plt.xlabel('iterations (x100)')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model with test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 150 test images: 96.15384615384616 %\n"
     ]
    }
   ],
   "source": [
    "n_test = len(test_loader) * batch_size\n",
    "wrong_predictions = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels, revs in test_loader:\n",
    "        images = Variable(images)\n",
    "        labels = Variable(labels)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        # See which are error predictions\n",
    "        result = (predicted == labels)\n",
    "        err_imgs = images[result == 0] # 0 means wrong prediction\n",
    "        err_labels = labels[result == 0]\n",
    "        err_p = outputs[result == 0]\n",
    "        err_outputs = predicted[result == 0]\n",
    "        err_texts = np.array(revs['text'])[np.array((result == 0).numpy(), dtype=np.bool)]\n",
    "        for img, lbl, p, out, text in zip(err_imgs, err_labels, err_p, err_outputs, err_texts):\n",
    "            wrong_predictions.append((img, lbl, p, out, text))\n",
    "     \n",
    "    print('Test Accuracy of the model on the {} test images: {} %'.format(n_test, 100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True label:  2 \t 暮らし系\n",
      "Predition:  0 \t エンタメ系\n",
      "Possibility: tensor([ 4.2707, -2.3034, -2.4540])\n",
      "だいたい ３ ０ ０ ０ 円 前後 な の か な ・ ・ ・ カード ゲーム 全然 やっ て ない から プレイマット って どういう 風 に 収納 し たり する の か わかっ て ない けど 折りたたん じゃう の か な ？ それとも 巻物 みたい に クルクル 巻く の か な ・ ・ ・ \n",
      "\n",
      "True label:  2 \t 暮らし系\n",
      "Predition:  1 \t 美容系\n",
      "Possibility: tensor([-4.8788,  3.0732,  1.6130])\n",
      "今日 美容 師 さん と 料理 の 話 に なっ て 、 クック パッド とか に 載っ てる レシピ 、 その 通り に 作る と 確か に 美味しい もの できる けど 、 もっと 男 飯 ！ みたい な レシピ の 方 が 絶対 美味い ん だ よ な ガハハ ( 山賊 ) ていう 話し た 。 なんか 米 ！ 肉 ！ マヨネーズ ！ てんこ盛り ！ みたい な やつ \n",
      "\n",
      "True label:  2 \t 暮らし系\n",
      "Predition:  0 \t エンタメ系\n",
      "Possibility: tensor([ 2.1038, -0.8646, -1.2426])\n",
      "中塚 智実 レシピ 付き フォト ブック クリスイーツ （ 単行本 （ ソフト カバー ）～ 中塚 智実 ～ 集英社 ） \n",
      "\n",
      "True label:  2 \t 暮らし系\n",
      "Predition:  1 \t 美容系\n",
      "Possibility: tensor([-0.2197,  0.1062,  0.0450])\n",
      "見 たい ！ ！ ！ やっぱ 、 ディズニー グッズ を どう 収納 し てる の か 気 に なる (*'▽'*) カチューシャ とか 、 ポップコーン ケース とか 。(*'▽'*) \n",
      "\n",
      "True label:  2 \t 暮らし系\n",
      "Predition:  0 \t エンタメ系\n",
      "Possibility: tensor([ 0.4545,  0.1390,  0.0613])\n",
      "【 山口 県 周 南市 】 家具 ・ 家電 付き ワンルーム マンション が 1 泊 から 泊まれる ホテル に 。 「 アーバンタイムス 徳山 」 が 結構 お買い得 という 噂 。 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "label_names = ['エンタメ系', '美容系', '暮らし系']\n",
    "# unpack img, lbl, out, text\n",
    "for img, lbl, p, out, text in wrong_predictions:\n",
    "    print('True label: ', lbl.item(), '\\t', label_names[lbl.item()])\n",
    "    print('Predition: ', out.item(), '\\t', label_names[out.item()])\n",
    "    print('Possibility:', p)\n",
    "    print(text, '\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model with train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 1400 train images: 100.0 %\n"
     ]
    }
   ],
   "source": [
    "n_train = len(train_loader) * batch_size\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in train_loader:\n",
    "        images = Variable(images)\n",
    "        labels = Variable(labels)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "    print('Test Accuracy of the model on the {} train images: {} %'.format(n_train, 100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict single inputted text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input the text to predict (change the text below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_to_predict = \"お風呂掃除でいつも落ちなかった溝にある黒カビが家事えもんの塩素系漂白剤＋片栗粉でほぼ真っ白になって感動 家事えもんのテクニック凄い～！\"\n",
    "\n",
    "text_to_predict = \"コスメの最安値が見つけられるアプリ💄💋メイク動画とか 美容情報も載ってるし最高😆🙌📲http://goo.gl/K5Fmea 女子にはほんとに助かる〜💗\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data...\n",
      "data loaded!\n",
      "number of sentences: 1772\n",
      "vocab size: 9467\n",
      "max sentence length: 100\n",
      "loading word2vec vectors...\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "from process_data import build_single_data_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_make_idx_data_cv_2vec(revs, U, word_idx_map, max_l=51, k=300, filter_h=5):\n",
    "    \"\"\"\n",
    "    Transforms sentences into a 2-d matrix.\n",
    "    \"\"\"\n",
    "    test_image, test_label = [], []\n",
    "    test_rev = []\n",
    "    for rev in revs:\n",
    "        sent = get_idx_from_sent_2vec(rev[\"text\"], U, word_idx_map, max_l, k, filter_h) # one sentence\n",
    "        test_image.append(sent) \n",
    "        test_label.append(rev[\"y\"])\n",
    "        test_rev.append(rev)\n",
    "\n",
    "    test_image = np.array(test_image)\n",
    "    test_label = np.array(test_label)\n",
    "    test_rev = np.array(test_rev)\n",
    "    return test_image, test_label, test_rev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1行処理済み\n"
     ]
    }
   ],
   "source": [
    "single_revs, _ = build_single_data_cv(text_to_predict)\n",
    "single_data_2vec = single_make_idx_data_cv_2vec(single_revs, W2, word_idx_map, max_l, k=300, filter_h=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 1 美容系\n",
      "Text: コスメ の 最 安値 が 見つけ られる アプリメイク 動画 とか 美容 情報 も 載っ てる し 最高 女子 に は ほんとに 助かる 〜\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    images, labels, revs = single_data_2vec\n",
    "    images = Variable(torch.Tensor(images.reshape(1, 1, -1, 300)))\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    print('Prediction:', predicted.item(), label_names[predicted.item()])\n",
    "    print('Text:', revs[0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
