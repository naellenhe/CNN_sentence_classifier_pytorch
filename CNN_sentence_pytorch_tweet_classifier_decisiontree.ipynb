{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys, re\n",
    "import pandas as pd\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocabulary dictionary : word_idx_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_data_cv(data_folder, cv=10):\n",
    "    \"\"\"\n",
    "    Loads data and split into 10 folds.\n",
    "    \"\"\"\n",
    "    revs = []\n",
    "    label_0_file, label_1_file, label_2_file = data_folder #[\"__label__0.txt\",\"__label__1.txt\", \"__label__2.txt\"]    \n",
    "    word_idx_map = dict()\n",
    "    word_idx = 1\n",
    "    for label, file in enumerate(data_folder): \n",
    "        with codecs.open(file, \"rb\", \"utf-8\", \"ignore\") as f:\n",
    "            for line in f:       \n",
    "                rev = []\n",
    "                rev.append(line.strip())\n",
    "                orig_rev = \" \".join(rev).lower()\n",
    "\n",
    "                words = set(orig_rev.split())\n",
    "                for word in words:\n",
    "                    if word not in word_idx_map:\n",
    "                        word_idx_map[word] = word_idx\n",
    "                        word_idx += 1\n",
    "\n",
    "                datum  = {\"y\": label, \n",
    "                          \"text\": orig_rev,                             \n",
    "                          \"num_words\": len(orig_rev.split()),\n",
    "                          \"split\": np.random.randint(0, cv)}\n",
    "                revs.append(datum)\n",
    "    return revs, word_idx_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data...\n",
      "Data loaded\n"
     ]
    }
   ],
   "source": [
    "data_folder = [\"__label__0.txt\",\"__label__1.txt\", \"__label__2.txt\"]    \n",
    "\n",
    "print(\"loading data...\")      \n",
    "revs, word_idx_map = build_data_cv(data_folder, cv=10)\n",
    "print(\"Data loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset content\n",
    "Get data from twitter (reference: http://tech.wonderpla.net/entry/2017/10/10/110000)\n",
    "- Label 0\n",
    "    - KEYWORD = \"èŠ¸èƒ½ OR ã‚¢ãƒ‹ãƒ¡ OR æ¼«ç”» OR ãƒ‰ãƒ©ãƒ OR ã‚²ãƒ¼ãƒ \"            #ã‚¨ãƒ³ã‚¿ãƒ¡ç³»ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰\n",
    "    - CLASS_LABEL = \"\\__label__0\"\n",
    "\n",
    "- Label 1\n",
    "    - KEYWORD = \"ç¾å®¹ OR ã‚µãƒ­ãƒ³ OR ã‚¨ã‚¹ãƒ† OR åŒ–ç²§ OR ä¿æ¹¿\"            #ç¾å®¹ç³»ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰\n",
    "    - CLASS_LABEL = \"\\__label__1\"\n",
    "\n",
    "- Label 2\n",
    "    - KEYWORD = \"æ—¥å¸¸ OR æ–™ç† OR å®¶äº‹ OR åç´ OR å®¶å…·\"            #æš®ã‚‰ã—ç³»ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰\n",
    "    - CLASS_LABEL = \"\\__label__2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = ['ã‚¨ãƒ³ã‚¿ãƒ¡ç³»', 'ç¾å®¹ç³»', 'æš®ã‚‰ã—ç³»']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### See data sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_words</th>\n",
       "      <th>split</th>\n",
       "      <th>text</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>anthem ã¦ã„ã† ã‚²ãƒ¼ãƒ  warframe ã¨ ã‚¿ã‚¤ã‚¿ãƒ³ãƒ•ã‚©ãƒ¼ãƒ« ã‚’ è¶³ã— ã¦ 2 ã§ ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>ãƒŠãƒ¬ãƒ¼ã‚¿ãƒ¼ ã‚’ ç„¡è¦– ã™ã‚‹ ã‚²ãƒ¼ãƒ  ã§ã™ ã€‚ ã»ã‚“ã¾ ãƒ„ãƒœ # icey</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     num_words  split                                               text  y\n",
       "682         24      6  anthem ã¦ã„ã† ã‚²ãƒ¼ãƒ  warframe ã¨ ã‚¿ã‚¤ã‚¿ãƒ³ãƒ•ã‚©ãƒ¼ãƒ« ã‚’ è¶³ã— ã¦ 2 ã§ ...  0\n",
       "387         11      5               ãƒŠãƒ¬ãƒ¼ã‚¿ãƒ¼ ã‚’ ç„¡è¦– ã™ã‚‹ ã‚²ãƒ¼ãƒ  ã§ã™ ã€‚ ã»ã‚“ã¾ ãƒ„ãƒœ # icey  0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(revs)\n",
    "\n",
    "# label 0: Entertainment \n",
    "df[df['y'] == 0].sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_words</th>\n",
       "      <th>split</th>\n",
       "      <th>text</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>790</th>\n",
       "      <td>55</td>\n",
       "      <td>7</td>\n",
       "      <td>æœˆ ã« ä¸€ åº¦ ã® ç¾å®¹ é™¢ ã¯ ã€ å‰é«ª ã® ã‚«ãƒƒãƒˆ ã¨ ã€ ã‚«ãƒ©ãƒ¼ ã¨ ã€ ã‚¨ã‚¯ã‚¹ãƒ† é ¼...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017</th>\n",
       "      <td>68</td>\n",
       "      <td>8</td>\n",
       "      <td>ãƒ€ã‚¤ã‚¨ãƒƒãƒˆ åŠ¹æœ ãŒ ã‚ã‚‹ ã¨ã—ã¦ æµè¡Œ ã® ãƒ¨ã‚¬ ã‚„ å¤ªæ¥µæ‹³ ã€‚ ã“ã‚Œã‚‰ ã® åŸºæœ¬ ã¯ è…¹...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      num_words  split                                               text  y\n",
       "790          55      7  æœˆ ã« ä¸€ åº¦ ã® ç¾å®¹ é™¢ ã¯ ã€ å‰é«ª ã® ã‚«ãƒƒãƒˆ ã¨ ã€ ã‚«ãƒ©ãƒ¼ ã¨ ã€ ã‚¨ã‚¯ã‚¹ãƒ† é ¼...  1\n",
       "1017         68      8  ãƒ€ã‚¤ã‚¨ãƒƒãƒˆ åŠ¹æœ ãŒ ã‚ã‚‹ ã¨ã—ã¦ æµè¡Œ ã® ãƒ¨ã‚¬ ã‚„ å¤ªæ¥µæ‹³ ã€‚ ã“ã‚Œã‚‰ ã® åŸºæœ¬ ã¯ è…¹...  1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# label 1 : Beauty\n",
    "df[df['y'] == 1].sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_words</th>\n",
       "      <th>split</th>\n",
       "      <th>text</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1520</th>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>å’Œç‰› æ°´ç”° ã€Œ 2 äºº ã§ é£¯ ã„ã£ ãŸã‚‰ é€£ã‚Œ ã® æ–™ç† ãŒ å…ˆ ã« å‡º ãŸ ã€ 17 åˆ†...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1619</th>\n",
       "      <td>78</td>\n",
       "      <td>9</td>\n",
       "      <td>è™å¾… ã• ã‚Œ ã¦ æ­»ã‚“ ã  å­ä¾› ã« ã¯ åŒæƒ… ã§ãã‚‹ ã®ã« æ—¥å¸¸ çš„ ã« è™å¾… ã• ã‚Œ ç¶š...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      num_words  split                                               text  y\n",
       "1520         31      0  å’Œç‰› æ°´ç”° ã€Œ 2 äºº ã§ é£¯ ã„ã£ ãŸã‚‰ é€£ã‚Œ ã® æ–™ç† ãŒ å…ˆ ã« å‡º ãŸ ã€ 17 åˆ†...  2\n",
       "1619         78      9  è™å¾… ã• ã‚Œ ã¦ æ­»ã‚“ ã  å­ä¾› ã« ã¯ åŒæƒ… ã§ãã‚‹ ã®ã« æ—¥å¸¸ çš„ ã« è™å¾… ã• ã‚Œ ç¶š...  2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# label 2: Life\n",
    "df[df['y'] == 2].sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "revs 2068\n",
      "word_idx_map 10329\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(word_idx_map)\n",
    "print('revs',len(revs)) # number of sentence\n",
    "print('word_idx_map', vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'y': 0,\n",
       " 'text': 'ãˆ ã€ ã‚µãƒ©ãƒªãƒ¼ãƒãƒ³ ã— ãªãŒã‚‰ ã€ å•†æ¥­ æ¼«ç”» ã® ä»•äº‹ ã‚’ ã— ã¦ ã€ ãƒ„ã‚¤ãƒƒã‚¿ãƒ¼ ã« å®šæœŸ çš„ ã« æ¼«ç”» ã‚’ ã‚ã’ ã¦ ã€ ã•ã‚‰ã« ã‚³ãƒŸã‚± ã® åŸç¨¿ ã‚’ ä½œã‚‹ ï¼ ï¼Ÿ',\n",
       " 'num_words': 32,\n",
       " 'split': 2}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "revs[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make BOW vectors\n",
    "make each sentence an BOW vector using word_idx_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_bow_from_sent(revs, word_idx_map, cv, vocab_size):\n",
    "    \"\"\"\n",
    "    Transforms sentences into a 2-d matrix.\n",
    "    \"\"\"\n",
    "    train, test = [], []\n",
    "    for rev in revs:\n",
    "        sent = rev[\"text\"]\n",
    "        bow_vec = np.zeros(vocab_size + 1)\n",
    "        bow_vec[0] = rev['y'] # Add true label at the beginning\n",
    "        words = sent.split()\n",
    "        for word in words:\n",
    "            bow_vec[word_idx_map[word]] += 1\n",
    "\n",
    "        if rev[\"split\"]== cv:  # \"split\" is random number of np.random.randint(0,10)\n",
    "            test.append(bow_vec)        \n",
    "        else:  \n",
    "            train.append(bow_vec)   \n",
    "    train = np.array(train, dtype=\"int\")\n",
    "    test = np.array(test, dtype=\"int\")\n",
    "    return [train, test] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = 0\n",
    "datasets = make_bow_from_sent(revs, word_idx_map, cv, vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example of sentence to BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'y': 0,\n",
       " 'text': 'ã‹ã£ã“ã„ã„ ã€ ã‚ãã‚ã ã™ã‚‹ æ¼«ç”» ã‚‚ æ°— ã« ãªã£ ã¦ã‚‹ ã‘ã© ãªã‹ãªã‹ èª­ã‚ ã¦ ãªã„ ã‚“ ã  ã‚ˆ ã­ã‡ ã€ æº€å–« è¡Œã“ ã† ã‹ ãª ã¨ æ€ã£ ã¦ ã‚‚ å®¶ ã§ ã‚´ãƒ­ã‚´ãƒ­ ã£ã¨ ã— ã¡ã‚ƒã†',\n",
       " 'num_words': 35,\n",
       " 'split': 4}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "revs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier(random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image = datasets[0][:, 1:]\n",
    "train_label = datasets[0][:, 0]\n",
    "test_image = datasets[1][:, 1:]\n",
    "test_label = datasets[1][:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data size: (1874, 10329)\n",
      "train data size: (1874,)\n",
      "test data size: (194, 10329)\n",
      "train data size: (194,)\n"
     ]
    }
   ],
   "source": [
    "print('train data size:', train_image.shape)\n",
    "print('train data size:', train_label.shape)\n",
    "print('test data size:', test_image.shape)\n",
    "print('train data size:', test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=0,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(train_image, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.994845360825\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy:', clf.score(test_image, test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.996798292423\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy:', clf.score(train_image, train_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict single inputted text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input the text to predict (change the text below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_to_predict = \"ãŠé¢¨å‘‚æƒé™¤ã§ã„ã¤ã‚‚è½ã¡ãªã‹ã£ãŸæºã«ã‚ã‚‹é»’ã‚«ãƒ“ãŒå®¶äº‹ãˆã‚‚ã‚“ã®å¡©ç´ ç³»æ¼‚ç™½å‰¤ï¼‹ç‰‡æ —ç²‰ã§ã»ã¼çœŸã£ç™½ã«ãªã£ã¦æ„Ÿå‹• å®¶äº‹ãˆã‚‚ã‚“ã®ãƒ†ã‚¯ãƒ‹ãƒƒã‚¯å‡„ã„ï½ï¼\"\n",
    "\n",
    "text_to_predict = \"ã‚³ã‚¹ãƒ¡ã®æœ€å®‰å€¤ãŒè¦‹ã¤ã‘ã‚‰ã‚Œã‚‹ã‚¢ãƒ—ãƒªğŸ’„ğŸ’‹ãƒ¡ã‚¤ã‚¯å‹•ç”»ã¨ã‹ ç¾å®¹æƒ…å ±ã‚‚è¼‰ã£ã¦ã‚‹ã—æœ€é«˜ğŸ˜†ğŸ™ŒğŸ“²http://goo.gl/K5Fmea å¥³å­ã«ã¯ã»ã‚“ã¨ã«åŠ©ã‹ã‚‹ã€œğŸ’—\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from get_data_from_twitter import process_single_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_bow_from_single_sent(sent, word_idx_map, vocab_size):\n",
    "    \"\"\"\n",
    "    Transforms sentences into a 2-d matrix.\n",
    "    \"\"\"\n",
    "    test = []\n",
    "    bow_vec = np.zeros(vocab_size + 1)\n",
    "    bow_vec[0] = 0 # Add dummy true label at the beginning\n",
    "    words = sent.split()\n",
    "    for word in words:\n",
    "        if word in word_idx_map:\n",
    "            bow_vec[word_idx_map[word]] += 1\n",
    "\n",
    "    test.append(bow_vec)\n",
    "    test = np.array(test, dtype=\"int\")\n",
    "    return test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1è¡Œå‡¦ç†æ¸ˆã¿\n"
     ]
    }
   ],
   "source": [
    "processed_sent = process_single_txt(text_to_predict)\n",
    "single_bow = make_bow_from_single_sent(processed_sent, word_idx_map, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: 1 ç¾å®¹ç³»\n"
     ]
    }
   ],
   "source": [
    "predected = clf.predict(single_bow[:, 1:]).item()\n",
    "print('Predicted:', predected, label_names[predected])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
