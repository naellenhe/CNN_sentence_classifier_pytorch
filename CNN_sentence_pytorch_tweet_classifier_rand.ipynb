{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomly initialized word vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = \"-rand\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import cPickle (python2.7)\n",
    "#http://testpy.hatenablog.com/entry/2017/03/17/000626\n",
    "import _pickle as cPickle\n",
    "\n",
    "import numpy as np\n",
    "from collections import defaultdict, OrderedDict\n",
    "\n",
    "import re\n",
    "import sys\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameters\n",
    "num_epochs = 10\n",
    "num_classes = 3\n",
    "batch_size = 50\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load pickle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the pickle file contains [revs, W, W2, word_idx_map, vocab] # W2 random vectors\n",
    "x = cPickle.load(open(\"tweet.p\",\"rb\"), encoding=\"latin1\") # Add encoding=\"latin1\" because got UnicodeDecodeError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset content\n",
    "Get data from twitter (reference: http://tech.wonderpla.net/entry/2017/10/10/110000)\n",
    "- Label 0\n",
    "    - KEYWORD = \"芸能 OR アニメ OR 漫画 OR ドラマ OR ゲーム\"            #エンタメ系のキーワード\n",
    "    - CLASS_LABEL = \"\\__label__0\"\n",
    "\n",
    "- Label 1\n",
    "    - KEYWORD = \"美容 OR サロン OR エステ OR 化粧 OR 保湿\"            #美容系のキーワード\n",
    "    - CLASS_LABEL = \"\\__label__1\"\n",
    "\n",
    "- Label 2\n",
    "    - KEYWORD = \"日常 OR 料理 OR 家事 OR 収納 OR 家具\"            #暮らし系のキーワード\n",
    "    - CLASS_LABEL = \"\\__label__2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### See data sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_words</th>\n",
       "      <th>split</th>\n",
       "      <th>text</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>33</td>\n",
       "      <td>5</td>\n",
       "      <td>某 違法 サイト が 潰れ て から 数 ヶ月 、 各 漫画 家 や 漫画 原作 者 さん ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>若手 俳優 たち が サバイバル ゲーム に 挑戦 7 月 期 ドラマ ゼロ # ntv #...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     num_words  split                                               text  y\n",
       "182         33      5  某 違法 サイト が 潰れ て から 数 ヶ月 、 各 漫画 家 や 漫画 原作 者 さん ...  0\n",
       "469         18      4  若手 俳優 たち が サバイバル ゲーム に 挑戦 7 月 期 ドラマ ゼロ # ntv #...  0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(x[0])\n",
    "\n",
    "# label 0: Entertainment \n",
    "df[df['y'] == 0].sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_words</th>\n",
       "      <th>split</th>\n",
       "      <th>text</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>21</td>\n",
       "      <td>8</td>\n",
       "      <td>美容 室 いく の ワクワク し すぎ て 早く 目 が 覚め た けど お腹 壊し た か...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>62</td>\n",
       "      <td>5</td>\n",
       "      <td>わたし 「 襟足 刈り上げ で 、 サイド から 繋げ て 4 mm に し たい ん です...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     num_words  split                                               text  y\n",
       "827         21      8  美容 室 いく の ワクワク し すぎ て 早く 目 が 覚め た けど お腹 壊し た か...  1\n",
       "873         62      5  わたし 「 襟足 刈り上げ で 、 サイド から 繋げ て 4 mm に し たい ん です...  1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# label 1 : Beauty\n",
    "df[df['y'] == 1].sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_words</th>\n",
       "      <th>split</th>\n",
       "      <th>text</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1182</th>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>じゃがいも って 料理 の 幅広く て いい です よ ね 。 蒸かし た じゃがいも に ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1224</th>\n",
       "      <td>67</td>\n",
       "      <td>7</td>\n",
       "      <td>○ 『 配送 ・ 配達 専門 ！ 重たい モノ 通販 』 金庫 , 家具 , タンス , テ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      num_words  split                                               text  y\n",
       "1182         49      1  じゃがいも って 料理 の 幅広く て いい です よ ね 。 蒸かし た じゃがいも に ...  2\n",
       "1224         67      7  ○ 『 配送 ・ 配達 専門 ！ 重たい モノ 通販 』 金庫 , 家具 , タンス , テ...  2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# label 2: Life\n",
    "df[df['y'] == 2].sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "revs, W, W2, word_idx_map, vocab = x[0], x[1], x[2], x[3], x[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max sentence length:  100\n"
     ]
    }
   ],
   "source": [
    "# Get the number of the longest sentence\n",
    "max_l = np.max(pd.DataFrame(revs)[\"num_words\"])\n",
    "print(\"max sentence length: \", max_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "revs 1772\n",
      "W 9468\n",
      "W2 9468\n",
      "word_idx_map 9467\n",
      "vocab 9467\n"
     ]
    }
   ],
   "source": [
    "print('revs',len(x[0])) # number of sentence\n",
    "print('W',len(x[1])) # W are pretrained word vectors (unknown words are randomly initialized)\n",
    "print('W2', len(x[2])) # W2 are randomly initialized vectors\n",
    "print('word_idx_map', len(x[3]))\n",
    "print('vocab', len(x[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'y': 0,\n",
       " 'text': 'え 、 サラリーマン し ながら 、 商業 漫画 の 仕事 を し て 、 ツイッター に 定期 的 に 漫画 を あげ て 、 さらに コミケ の 原稿 を 作る ！ ？',\n",
       " 'num_words': 32,\n",
       " 'split': 2}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "revs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using: random vectors\n"
     ]
    }
   ],
   "source": [
    "if word_vectors == \"-rand\":\n",
    "    print(\"using: random vectors\")\n",
    "    U = W2\n",
    "elif word_vectors == \"-word2vec\":\n",
    "    print(\"using: word2vec vectors\")\n",
    "    U = W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9468, 300)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make dataset (check original code)\n",
    "make each sentence an word index map using word_idx_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_idx_from_sent(sent, word_idx_map, max_l=51, k=300, filter_h=5):\n",
    "    \"\"\"\n",
    "    Transforms sentence into a list of indices. Pad with zeroes.\n",
    "    \"\"\"\n",
    "    x = []\n",
    "    pad = filter_h - 1\n",
    "    for i in range(pad):\n",
    "        x.append(0)\n",
    "    words = sent.split()\n",
    "    for word in words:\n",
    "        if word in word_idx_map:\n",
    "            x.append(word_idx_map[word])\n",
    "    while len(x) < max_l + 2*pad:\n",
    "        x.append(0)\n",
    "    return x\n",
    "\n",
    "def make_idx_data_cv(revs, word_idx_map, cv, max_l=51, k=300, filter_h=5):\n",
    "    \"\"\"\n",
    "    Transforms sentences into a 2-d matrix.\n",
    "    \"\"\"\n",
    "    train, test = [], []\n",
    "    for rev in revs:\n",
    "        sent = get_idx_from_sent(rev[\"text\"], word_idx_map, max_l, k, filter_h) # one sentence\n",
    "        sent.append(rev[\"y\"])\n",
    "        if rev[\"split\"]== cv:  # \"split\" is random number of np.random.randint(0,10)\n",
    "            test.append(sent)        \n",
    "        else:  \n",
    "            train.append(sent)   \n",
    "    train = np.array(train, dtype=\"int\")\n",
    "    test = np.array(test, dtype=\"int\")\n",
    "    return [train, test] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "datasets = make_idx_data_cv(revs, word_idx_map, i, max_l, k=300, filter_h=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example of sentence to word index map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'y': 0,\n",
       " 'text': 'え 、 サラリーマン し ながら 、 商業 漫画 の 仕事 を し て 、 ツイッター に 定期 的 に 漫画 を あげ て 、 さらに コミケ の 原稿 を 作る ！ ？',\n",
       " 'num_words': 32,\n",
       " 'split': 2}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "revs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,   23, 3829,   22,   15,   28, 3829,   30,\n",
       "       3833,   21, 3845,   29,   15,    2, 3829,   31,    7,   24,   25,\n",
       "          7, 3833,   29, 3842,    2, 3829,   32,   26,   21,   27,   29,\n",
       "       3841, 3843, 3844,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(datasets[0][0]))\n",
    "datasets[0][1] # sentence => word index map padding with zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data size: (1620, 109)\n",
      "test data size: (152, 109)\n"
     ]
    }
   ],
   "source": [
    "print('train data size:', datasets[0].shape)\n",
    "print('test data size:', datasets[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make dataset (using vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_idx_from_sent_2vec(sent, U, word_idx_map, max_l=51, k=300, filter_h=5):\n",
    "    \"\"\"\n",
    "    Transforms sentence into a list of indices. Pad with zeroes.\n",
    "    \"\"\"\n",
    "    pad = filter_h - 1\n",
    "    x = np.zeros((max_l+2*pad, k))\n",
    "\n",
    "    words = sent.split()\n",
    "    # starting after padding\n",
    "    i = pad\n",
    "    for word in words:\n",
    "        if word in word_idx_map:\n",
    "            x[i] = U[word_idx_map[word]]\n",
    "            i += 1\n",
    "    return x\n",
    "\n",
    "def make_idx_data_cv_2vec(revs, U, word_idx_map, cv, max_l=51, k=300, filter_h=5):\n",
    "    \"\"\"\n",
    "    Transforms sentences into a 2-d matrix.\n",
    "    \"\"\"\n",
    "    train_image, train_label = [], []\n",
    "    test_image, test_label = [], []\n",
    "    test_rev = []\n",
    "    for rev in revs:\n",
    "        sent = get_idx_from_sent_2vec(rev[\"text\"], U, word_idx_map, max_l, k, filter_h) # one sentence\n",
    "        if rev[\"split\"] == cv:  # \"split\" is random number of np.random.randint(0,10)\n",
    "            test_image.append(sent) \n",
    "            test_label.append(rev[\"y\"])\n",
    "            test_rev.append(rev)\n",
    "        else:  \n",
    "            train_image.append(sent)\n",
    "            train_label.append(rev[\"y\"])\n",
    "    train_image = np.array(train_image)\n",
    "    train_label = np.array(train_label)\n",
    "    test_image = np.array(test_image)\n",
    "    test_label = np.array(test_label)\n",
    "    test_rev = np.array(test_rev)\n",
    "    return (train_image, train_label), (test_image, test_label, test_rev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence length(before) 108\n"
     ]
    }
   ],
   "source": [
    "t = \"effective but too tepid biopic\"\n",
    "t_sent_2vec = get_idx_from_sent_2vec(t, U, word_idx_map, max_l, k=300, filter_h=5)\n",
    "print(\"sentence length(before)\", len(t_sent_2vec)) # max_l(51)+2*pad(filter_h-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_sent_2vec[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "datasets_2vec = make_idx_data_cv_2vec(revs, U, word_idx_map, i, max_l, k=300, filter_h=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_image, train_label), (test_image, test_label, test_rev) = datasets_2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example of sentence to vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'y': 0,\n",
       " 'text': 'え 、 サラリーマン し ながら 、 商業 漫画 の 仕事 を し て 、 ツイッター に 定期 的 に 漫画 を あげ て 、 さらに コミケ の 原稿 を 作る ！ ？',\n",
       " 'num_words': 32,\n",
       " 'split': 2}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "revs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(108, 300)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.064392</td>\n",
       "      <td>-0.002581</td>\n",
       "      <td>0.013883</td>\n",
       "      <td>-0.037063</td>\n",
       "      <td>0.026673</td>\n",
       "      <td>-0.065513</td>\n",
       "      <td>0.011645</td>\n",
       "      <td>0.018522</td>\n",
       "      <td>0.022069</td>\n",
       "      <td>0.005872</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039722</td>\n",
       "      <td>-0.021070</td>\n",
       "      <td>0.018943</td>\n",
       "      <td>-0.086531</td>\n",
       "      <td>0.065545</td>\n",
       "      <td>0.101533</td>\n",
       "      <td>-0.056950</td>\n",
       "      <td>0.082155</td>\n",
       "      <td>0.038191</td>\n",
       "      <td>-0.041275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.014293</td>\n",
       "      <td>-0.068069</td>\n",
       "      <td>0.062165</td>\n",
       "      <td>-0.017260</td>\n",
       "      <td>0.013693</td>\n",
       "      <td>-0.026318</td>\n",
       "      <td>0.056138</td>\n",
       "      <td>-0.005120</td>\n",
       "      <td>-0.100470</td>\n",
       "      <td>-0.045287</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025515</td>\n",
       "      <td>0.050534</td>\n",
       "      <td>0.062637</td>\n",
       "      <td>0.016193</td>\n",
       "      <td>-0.028408</td>\n",
       "      <td>0.039458</td>\n",
       "      <td>0.031125</td>\n",
       "      <td>0.091147</td>\n",
       "      <td>-0.046704</td>\n",
       "      <td>0.094780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.072139</td>\n",
       "      <td>0.064816</td>\n",
       "      <td>-0.090644</td>\n",
       "      <td>-0.043941</td>\n",
       "      <td>0.010022</td>\n",
       "      <td>-0.067790</td>\n",
       "      <td>0.033524</td>\n",
       "      <td>-0.021529</td>\n",
       "      <td>-0.059422</td>\n",
       "      <td>0.099765</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012819</td>\n",
       "      <td>0.003835</td>\n",
       "      <td>0.090722</td>\n",
       "      <td>0.098881</td>\n",
       "      <td>-0.033249</td>\n",
       "      <td>0.074877</td>\n",
       "      <td>-0.043950</td>\n",
       "      <td>-0.021405</td>\n",
       "      <td>0.045619</td>\n",
       "      <td>-0.099146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.086468</td>\n",
       "      <td>-0.003798</td>\n",
       "      <td>0.039399</td>\n",
       "      <td>-0.038809</td>\n",
       "      <td>0.014513</td>\n",
       "      <td>-0.007378</td>\n",
       "      <td>-0.098877</td>\n",
       "      <td>0.089061</td>\n",
       "      <td>0.018667</td>\n",
       "      <td>-0.017337</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.097156</td>\n",
       "      <td>0.026778</td>\n",
       "      <td>0.019081</td>\n",
       "      <td>-0.030279</td>\n",
       "      <td>-0.025137</td>\n",
       "      <td>-0.029905</td>\n",
       "      <td>-0.099507</td>\n",
       "      <td>-0.015676</td>\n",
       "      <td>0.027498</td>\n",
       "      <td>0.027933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.063229</td>\n",
       "      <td>-0.086116</td>\n",
       "      <td>0.086172</td>\n",
       "      <td>-0.028849</td>\n",
       "      <td>-0.077457</td>\n",
       "      <td>-0.097333</td>\n",
       "      <td>0.091468</td>\n",
       "      <td>-0.048911</td>\n",
       "      <td>0.003279</td>\n",
       "      <td>0.068182</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.045849</td>\n",
       "      <td>0.095730</td>\n",
       "      <td>-0.062649</td>\n",
       "      <td>-0.053380</td>\n",
       "      <td>-0.027305</td>\n",
       "      <td>-0.039676</td>\n",
       "      <td>-0.006028</td>\n",
       "      <td>0.093363</td>\n",
       "      <td>-0.089076</td>\n",
       "      <td>0.091493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.014293</td>\n",
       "      <td>-0.068069</td>\n",
       "      <td>0.062165</td>\n",
       "      <td>-0.017260</td>\n",
       "      <td>0.013693</td>\n",
       "      <td>-0.026318</td>\n",
       "      <td>0.056138</td>\n",
       "      <td>-0.005120</td>\n",
       "      <td>-0.100470</td>\n",
       "      <td>-0.045287</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025515</td>\n",
       "      <td>0.050534</td>\n",
       "      <td>0.062637</td>\n",
       "      <td>0.016193</td>\n",
       "      <td>-0.028408</td>\n",
       "      <td>0.039458</td>\n",
       "      <td>0.031125</td>\n",
       "      <td>0.091147</td>\n",
       "      <td>-0.046704</td>\n",
       "      <td>0.094780</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4 -0.064392 -0.002581  0.013883 -0.037063  0.026673 -0.065513  0.011645   \n",
       "5  0.014293 -0.068069  0.062165 -0.017260  0.013693 -0.026318  0.056138   \n",
       "6  0.072139  0.064816 -0.090644 -0.043941  0.010022 -0.067790  0.033524   \n",
       "7  0.086468 -0.003798  0.039399 -0.038809  0.014513 -0.007378 -0.098877   \n",
       "8 -0.063229 -0.086116  0.086172 -0.028849 -0.077457 -0.097333  0.091468   \n",
       "9  0.014293 -0.068069  0.062165 -0.017260  0.013693 -0.026318  0.056138   \n",
       "\n",
       "        7         8         9      ...          290       291       292  \\\n",
       "0  0.000000  0.000000  0.000000    ...     0.000000  0.000000  0.000000   \n",
       "1  0.000000  0.000000  0.000000    ...     0.000000  0.000000  0.000000   \n",
       "2  0.000000  0.000000  0.000000    ...     0.000000  0.000000  0.000000   \n",
       "3  0.000000  0.000000  0.000000    ...     0.000000  0.000000  0.000000   \n",
       "4  0.018522  0.022069  0.005872    ...    -0.039722 -0.021070  0.018943   \n",
       "5 -0.005120 -0.100470 -0.045287    ...    -0.025515  0.050534  0.062637   \n",
       "6 -0.021529 -0.059422  0.099765    ...    -0.012819  0.003835  0.090722   \n",
       "7  0.089061  0.018667 -0.017337    ...    -0.097156  0.026778  0.019081   \n",
       "8 -0.048911  0.003279  0.068182    ...    -0.045849  0.095730 -0.062649   \n",
       "9 -0.005120 -0.100470 -0.045287    ...    -0.025515  0.050534  0.062637   \n",
       "\n",
       "        293       294       295       296       297       298       299  \n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "2  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "4 -0.086531  0.065545  0.101533 -0.056950  0.082155  0.038191 -0.041275  \n",
       "5  0.016193 -0.028408  0.039458  0.031125  0.091147 -0.046704  0.094780  \n",
       "6  0.098881 -0.033249  0.074877 -0.043950 -0.021405  0.045619 -0.099146  \n",
       "7 -0.030279 -0.025137 -0.029905 -0.099507 -0.015676  0.027498  0.027933  \n",
       "8 -0.053380 -0.027305 -0.039676 -0.006028  0.093363 -0.089076  0.091493  \n",
       "9  0.016193 -0.028408  0.039458  0.031125  0.091147 -0.046704  0.094780  \n",
       "\n",
       "[10 rows x 300 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p2 = pd.DataFrame(train_image[1])\n",
    "print(p2.shape)\n",
    "p2.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make dataset iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1620"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_image = torch.FloatTensor(train_image).reshape(-1, 1, max_l + 2 * (5-1), 300)\n",
    "t_label = torch.LongTensor(train_label)\n",
    "train_dataset = list(zip(t_image, t_label))\n",
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images: torch.Size([50, 1, 108, 300]) \n",
      "labels: torch.Size([50])\n",
      "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])\n",
      "tensor(1)\n"
     ]
    }
   ],
   "source": [
    "for images, labels in train_loader:\n",
    "    print('images:', images.shape, '\\nlabels:', labels.shape)\n",
    "    print(images[1][0])\n",
    "    print(labels[1])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "152"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_image = torch.FloatTensor(test_image).reshape(-1, 1, max_l + 2 * (5-1), 300)\n",
    "c_label = torch.LongTensor(test_label)\n",
    "test_dataset = list(zip(c_image, c_label, test_rev))\n",
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loader\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model parameters (original code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_hs=[3, 4, 5]\n",
    "hidden_units=[100, num_classes]\n",
    "batch_size=50\n",
    "img_w=300\n",
    "img_h = len(datasets[0][0])-1  # sentence length (subtracted 1 for y label)\n",
    "\n",
    "filter_w = img_w    \n",
    "feature_maps = hidden_units[0]\n",
    "filter_shapes = []\n",
    "pool_sizes = []\n",
    "for filter_h in filter_hs:\n",
    "    filter_shapes.append((feature_maps, 1, filter_h, filter_w))\n",
    "    pool_sizes.append((img_h-filter_h+1, img_w-filter_w+1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(100, 1, 3, 300), (100, 1, 4, 300), (100, 1, 5, 300)]\n",
      "one batch train (50, 1, 108, 300)\n",
      "[(106, 1), (105, 1), (104, 1)]\n"
     ]
    }
   ],
   "source": [
    "print(filter_shapes)\n",
    "image_shape = (batch_size, 1, img_h, img_w)\n",
    "print('one batch train', image_shape)\n",
    "print(pool_sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding & Stride\n",
    "- Output size\n",
    "\n",
    "    $ O = \\frac {W-K+2P}{S} + 1 $\n",
    "    - O: output h/w\n",
    "    - W: input h/w\n",
    "    - K: filter size(kernel size)\n",
    "    - P: padding\n",
    "        - $  P = \\frac {K-1}{2} $\n",
    "    - S: stride"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network\n",
    "\n",
    "- Theano:\n",
    "    - conv_layer: LeNetConvPoolLayer\n",
    "    - classifier: MLPDropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model:\n",
    "\n",
    "\n",
    "```\n",
    "Network\n",
    "Input ->\n",
    "Conv -> ReLU -> MaxPool |\n",
    "Conv -> ReLU -> MaxPool | -> concat\n",
    "Conv -> ReLU -> MaxPool |\n",
    "Fully Connected Layer(Logits -> Softmax) -> Labels\n",
    "```\n",
    "\n",
    "```\n",
    "Convolutional layer formula:\n",
    "- Filter 1(Kernel) size K = 3 => (3 x 300)\n",
    "- P(same padding) P = (3-1)/2=1\n",
    "- S(stride) S = 1\n",
    "- in_channels = 1\n",
    "- out_channels (int) – Number of channels produced by the convolution = 100\n",
    "Pooling layer formula:\n",
    "- K\n",
    "```\n",
    "\n",
    "```\n",
    "*Filter dimensions*:\n",
    "Conv1 (W_conv, (100, 1, 3, 300))\n",
    "Conv1 (b_conv, (100,))\n",
    "Conv2 (W_conv, (100, 1, 4, 300))\n",
    "Conv2 (b_conv, (100,))\n",
    "Conv3 (W_conv, (100, 1, 5, 300))\n",
    "Conv3 (b_conv, (100,))\n",
    "\n",
    "*Layer input dimensions*:\n",
    "- Input image(64, 300) \n",
    "\n",
    "----------------------------------------------------------------------\n",
    "|  Conv1  (100, 3, 300)   Conv2  (100, 4, 300)   Conv3  (100, 5, 300) |\n",
    "|  MaxPool (100, 62, 1)   MaxPool (100, 61, 1)   MaxPool (100, 60, 1) |\n",
    "-----------------------------Concat ----------------------------------\n",
    "\n",
    "- Concatenated (100, 1, 1) + (100, 1, 1) + (100, 1, 1) => (300, 1, 1) \n",
    "\n",
    "- Fully Connected Layer(Logits (100, 1) -> Logits (2, 1) -> Softmax) -> Labels\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvPoolLayer(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(ConvPoolLayer, self).__init__()\n",
    "\n",
    "        # Layer 1: conv - relu - conv- relu - pool\n",
    "        self.ngram1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=feature_maps, kernel_size=(filter_hs[0], img_w), stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=pool_sizes[0], stride=None))\n",
    "        self.ngram2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=feature_maps, kernel_size=(filter_hs[1], img_w), stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=pool_sizes[1], stride=None))\n",
    "        self.ngram3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=feature_maps, kernel_size=(filter_hs[2], img_w), stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=pool_sizes[2], stride=None))\n",
    "        \n",
    "        # Fully Connected 1 (readout)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(feature_maps * 3, hidden_units[0]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_units[0], num_classes))\n",
    "\n",
    "        # Initialize all parameters using kaiming normalization\n",
    "        self.init_weights_kaiming()\n",
    "    \n",
    "    def init_weights_kaiming(self):\n",
    "        #Use kaiming normalization to initialize the parameters\n",
    "        for layer in [self.ngram1, self.ngram2, self.ngram3, self.fc]:\n",
    "            for m in layer:\n",
    "                if type(m) == nn.Conv2d or type(m) == nn.Linear:\n",
    "                    m.weight = nn.init.kaiming_normal_(m.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        out1 = self.ngram1(x)\n",
    "        out2 = self.ngram2(x)\n",
    "        out3 = self.ngram3(x)\n",
    "        out = torch.cat((out1, out2, out3), 1)\n",
    "        \n",
    "        out = out.view(out.size(0), -1)\n",
    "    \n",
    "        # Linear function (readout)\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvPoolLayer(\n",
      "  (ngram1): Sequential(\n",
      "    (0): Conv2d(1, 100, kernel_size=(3, 300), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=(106, 1), stride=(106, 1), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (ngram2): Sequential(\n",
      "    (0): Conv2d(1, 100, kernel_size=(4, 300), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=(105, 1), stride=(105, 1), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (ngram3): Sequential(\n",
      "    (0): Conv2d(1, 100, kernel_size=(5, 300), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=(104, 1), stride=(104, 1), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=300, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=100, out_features=3, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = ConvPoolLayer(num_classes)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1, 3, 300])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 4, 300])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 5, 300])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 300])\n",
      "torch.Size([100])\n",
      "torch.Size([3, 100])\n",
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "for p in model.parameters():\n",
    "    print(p.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 50. Loss: 0.3587445020675659.\n",
      "Iteration: 100. Loss: 0.01839945837855339.\n",
      "Iteration: 150. Loss: 0.0051238276064395905.\n",
      "Iteration: 200. Loss: 0.0032628111075609922.\n",
      "Iteration: 250. Loss: 0.0015370656037703156.\n",
      "Iteration: 300. Loss: 0.0010711323702707887.\n"
     ]
    }
   ],
   "source": [
    "avg_losses = list()\n",
    "iter = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        total_loss = list()\n",
    "        \n",
    "        # Load images as Variable\n",
    "        images = Variable(images) # Now we dont need to resize like images.view(xx)\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        # Clear gradients w.r.t parameters\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass to get output/logits\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # Calculate Loss: Softmax --> cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Getting gradients w.r.t paramters\n",
    "        loss.backward()\n",
    "        \n",
    "        # Track loss to plot the result\n",
    "        total_loss.append(loss.item())\n",
    "        \n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        iter += 1\n",
    "        \n",
    "        if iter % 50 == 0:\n",
    "            # Print Loss\n",
    "            print('Iteration: {}. Loss: {}.'.format(iter, loss.item()))\n",
    "            avg_loss = np.divide(np.sum(total_loss), len(total_loss))\n",
    "            avg_losses.append(avg_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the loss vs iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_axis = np.arange(len(avg_losses))\n",
    "plt.plot(x_axis, avg_losses, label='train')\n",
    "plt.xlabel('iterations (x100)')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model with test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 200 test images: 99.34210526315789 %\n"
     ]
    }
   ],
   "source": [
    "n_test = len(test_loader) * batch_size\n",
    "wrong_predictions = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels, revs in test_loader:\n",
    "        images = Variable(images)\n",
    "        labels = Variable(labels)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        # See which are error predictions\n",
    "        result = (predicted == labels)\n",
    "        err_imgs = images[result == 0] # 0 means wrong prediction\n",
    "        err_labels = labels[result == 0]\n",
    "        err_p = outputs[result == 0]\n",
    "        err_outputs = predicted[result == 0]\n",
    "        err_texts = np.array(revs['text'])[np.array((result == 0).numpy(), dtype=np.bool)]\n",
    "        for img, lbl, p, out, text in zip(err_imgs, err_labels, err_p, err_outputs, err_texts):\n",
    "            wrong_predictions.append((img, lbl, p, out, text))\n",
    "     \n",
    "    print('Test Accuracy of the model on the {} test images: {} %'.format(n_test, 100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True label:  2 \t 暮らし系\n",
      "Predition:  0 \t エンタメ系\n",
      "Possibility: tensor([ 4.6164, -1.9947, -0.9974])\n",
      "だいたい ３ ０ ０ ０ 円 前後 な の か な ・ ・ ・ カード ゲーム 全然 やっ て ない から プレイマット って どういう 風 に 収納 し たり する の か わかっ て ない けど 折りたたん じゃう の か な ？ それとも 巻物 みたい に クルクル 巻く の か な ・ ・ ・ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "label_names = ['エンタメ系', '美容系', '暮らし系']\n",
    "# unpack img, lbl, out, text\n",
    "for img, lbl, p, out, text in wrong_predictions:\n",
    "    print('True label: ', lbl.item(), '\\t', label_names[lbl.item()])\n",
    "    print('Predition: ', out.item(), '\\t', label_names[out.item()])\n",
    "    print('Possibility:', p)\n",
    "    print(text, '\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model with train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = len(train_loader) * batch_size\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in train_loader:\n",
    "        images = Variable(images)\n",
    "        labels = Variable(labels)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "    print('Test Accuracy of the model on the {} train images: {} %'.format(n_train, 100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict single inputted text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input the text to predict (change the text below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_to_predict = \"お風呂掃除でいつも落ちなかった溝にある黒カビが家事えもんの塩素系漂白剤＋片栗粉でほぼ真っ白になって感動 家事えもんのテクニック凄い～！\"\n",
    "\n",
    "text_to_predict = \"コスメの最安値が見つけられるアプリ💄💋メイク動画とか 美容情報も載ってるし最高😆🙌📲http://goo.gl/K5Fmea 女子にはほんとに助かる〜💗\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "from process_data import build_single_data_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_make_idx_data_cv_2vec(revs, U, word_idx_map, max_l=51, k=300, filter_h=5):\n",
    "    \"\"\"\n",
    "    Transforms sentences into a 2-d matrix.\n",
    "    \"\"\"\n",
    "    test_image, test_label = [], []\n",
    "    test_rev = []\n",
    "    for rev in revs:\n",
    "        sent = get_idx_from_sent_2vec(rev[\"text\"], U, word_idx_map, max_l, k, filter_h) # one sentence\n",
    "        test_image.append(sent) \n",
    "        test_label.append(rev[\"y\"])\n",
    "        test_rev.append(rev)\n",
    "\n",
    "    test_image = np.array(test_image)\n",
    "    test_label = np.array(test_label)\n",
    "    test_rev = np.array(test_rev)\n",
    "    return test_image, test_label, test_rev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_revs, _ = build_single_data_cv(text_to_predict)\n",
    "single_data_2vec = single_make_idx_data_cv_2vec(single_revs, U, word_idx_map, max_l, k=300, filter_h=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    images, labels, revs = single_data_2vec\n",
    "    images = Variable(torch.Tensor(images.reshape(1, 1, -1, 300)))\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    print('Prediction:', predicted.item(), label_names[predicted.item()])\n",
    "    print('Text:', revs[0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
