{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialized word vector with pretrain japanese word2vec \n",
    "\n",
    "https://github.com/Kyubyong/wordvectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = \"-word2vec\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import cPickle (python2.7)\n",
    "#http://testpy.hatenablog.com/entry/2017/03/17/000626\n",
    "import _pickle as cPickle\n",
    "\n",
    "import numpy as np\n",
    "from collections import defaultdict, OrderedDict\n",
    "\n",
    "import re\n",
    "import sys\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameters\n",
    "num_epochs = 10\n",
    "num_classes = 3\n",
    "batch_size = 50\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load pickle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the pickle file contains [revs, W, W2, word_idx_map, vocab] # W2 random vectors\n",
    "x = cPickle.load(open(\"tweet.p\",\"rb\"), encoding=\"latin1\") # Add encoding=\"latin1\" because got UnicodeDecodeError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset content\n",
    "Get data from twitter (reference: http://tech.wonderpla.net/entry/2017/10/10/110000)\n",
    "- Label 0\n",
    "    - KEYWORD = \"芸能 OR アニメ OR 漫画 OR ドラマ OR ゲーム\"            #エンタメ系のキーワード\n",
    "    - CLASS_LABEL = \"\\__label__0\"\n",
    "\n",
    "- Label 1\n",
    "    - KEYWORD = \"美容 OR サロン OR エステ OR 化粧 OR 保湿\"            #美容系のキーワード\n",
    "    - CLASS_LABEL = \"\\__label__1\"\n",
    "\n",
    "- Label 2\n",
    "    - KEYWORD = \"日常 OR 料理 OR 家事 OR 収納 OR 家具\"            #暮らし系のキーワード\n",
    "    - CLASS_LABEL = \"\\__label__2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### See data sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_words</th>\n",
       "      <th>split</th>\n",
       "      <th>text</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>news 加藤 シゲ アキ ： 主演 ドラマ の 追加 キャスト に 間宮 祥 太朗 、 梅...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>自分 、 勇者 な んで モンスター を 倒し て 、 1 秒間 に 『 207 , 105...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     num_words  split                                               text  y\n",
       "468         23      3  news 加藤 シゲ アキ ： 主演 ドラマ の 追加 キャスト に 間宮 祥 太朗 、 梅...  0\n",
       "165         40      0  自分 、 勇者 な んで モンスター を 倒し て 、 1 秒間 に 『 207 , 105...  0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(x[0])\n",
    "\n",
    "# label 0: Entertainment \n",
    "df[df['y'] == 0].sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_words</th>\n",
       "      <th>split</th>\n",
       "      <th>text</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>922</th>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>【 安く て 質 の 良い サロン 】 お 探し の 方 、 是非 ホームページ 覗い て ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>ちゃんと 起き て 着替え て 化粧 し て 出かけ た から とても えらい ( えらい ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     num_words  split                                               text  y\n",
       "922         53      0  【 安く て 質 の 良い サロン 】 お 探し の 方 、 是非 ホームページ 覗い て ...  1\n",
       "703         18      0  ちゃんと 起き て 着替え て 化粧 し て 出かけ た から とても えらい ( えらい ...  1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# label 1 : Beauty\n",
    "df[df['y'] == 1].sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_words</th>\n",
       "      <th>split</th>\n",
       "      <th>text</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1481</th>\n",
       "      <td>61</td>\n",
       "      <td>4</td>\n",
       "      <td># リンドリ おそらく 霧島 さん は 悪い 意味 で 「 手加減 が でき ない 」 な ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1501</th>\n",
       "      <td>47</td>\n",
       "      <td>9</td>\n",
       "      <td>めぐ 料理 上手 に 写真 上手 か ！ ！ なんか レシピ 本 に 使え そう な 写真 ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      num_words  split                                               text  y\n",
       "1481         61      4  # リンドリ おそらく 霧島 さん は 悪い 意味 で 「 手加減 が でき ない 」 な ...  2\n",
       "1501         47      9  めぐ 料理 上手 に 写真 上手 か ！ ！ なんか レシピ 本 に 使え そう な 写真 ...  2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# label 2: Life\n",
    "df[df['y'] == 2].sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "revs, W, W2, word_idx_map, vocab = x[0], x[1], x[2], x[3], x[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max sentence length:  100\n"
     ]
    }
   ],
   "source": [
    "# Get the number of the longest sentence\n",
    "max_l = np.max(pd.DataFrame(revs)[\"num_words\"])\n",
    "print(\"max sentence length: \", max_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "revs 2068\n",
      "W 10330\n",
      "W2 10330\n",
      "word_idx_map 10329\n",
      "vocab 10329\n"
     ]
    }
   ],
   "source": [
    "print('revs',len(x[0])) # number of sentence\n",
    "print('W', len(x[1])) # W are pretrained word vectors (unknown words are randomly initialized)\n",
    "print('W2', len(x[2])) # W2 are randomly initialized vectors\n",
    "print('word_idx_map', len(x[3]))\n",
    "print('vocab', len(x[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'y': 0,\n",
       " 'text': 'え 、 サラリーマン し ながら 、 商業 漫画 の 仕事 を し て 、 ツイッター に 定期 的 に 漫画 を あげ て 、 さらに コミケ の 原稿 を 作る ！ ？',\n",
       " 'num_words': 32,\n",
       " 'split': 7}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "revs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using: word2vec vectors\n"
     ]
    }
   ],
   "source": [
    "if word_vectors==\"-rand\":\n",
    "    print(\"using: random vectors\")\n",
    "    U = W2\n",
    "elif word_vectors==\"-word2vec\":\n",
    "    print(\"using: word2vec vectors\")\n",
    "    U = W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10330, 300)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make dataset (check original code)\n",
    "make each sentence an word index map using word_idx_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_idx_from_sent(sent, word_idx_map, max_l=51, k=300, filter_h=5):\n",
    "    \"\"\"\n",
    "    Transforms sentence into a list of indices. Pad with zeroes.\n",
    "    \"\"\"\n",
    "    x = []\n",
    "    pad = filter_h - 1\n",
    "    for i in range(pad):\n",
    "        x.append(0)\n",
    "    words = sent.split()\n",
    "    for word in words:\n",
    "        if word in word_idx_map:\n",
    "            x.append(word_idx_map[word])\n",
    "    while len(x) < max_l + 2*pad:\n",
    "        x.append(0)\n",
    "    return x\n",
    "\n",
    "def make_idx_data_cv(revs, word_idx_map, cv, max_l=51, k=300, filter_h=5):\n",
    "    \"\"\"\n",
    "    Transforms sentences into a 2-d matrix.\n",
    "    \"\"\"\n",
    "    train, test = [], []\n",
    "    for rev in revs:\n",
    "        sent = get_idx_from_sent(rev[\"text\"], word_idx_map, max_l, k, filter_h) # one sentence\n",
    "        sent.append(rev[\"y\"])\n",
    "        if rev[\"split\"]== cv:  # \"split\" is random number of np.random.randint(0,10)\n",
    "            test.append(sent)        \n",
    "        else:  \n",
    "            train.append(sent)   \n",
    "    train = np.array(train, dtype=\"int\")\n",
    "    test = np.array(test, dtype=\"int\")\n",
    "    return [train, test] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "datasets = make_idx_data_cv(revs, word_idx_map, i, max_l, k=300, filter_h=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example of sentence to word index map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'y': 0,\n",
       " 'text': 'え 、 サラリーマン し ながら 、 商業 漫画 の 仕事 を し て 、 ツイッター に 定期 的 に 漫画 を あげ て 、 さらに コミケ の 原稿 を 作る ！ ？',\n",
       " 'num_words': 32,\n",
       " 'split': 7}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "revs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,   27, 4148,   26,    2,   21, 4148,   31,\n",
       "       4147,   25, 4150,   32,    2,   10, 4148,   22,    5,   29,   28,\n",
       "          5, 4147,   32, 4152,   10, 4148,   30,   23,   25,   24,   32,\n",
       "       4154, 4153, 4151,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(datasets[0][0]))\n",
    "datasets[0][1] # sentence => word index map padding with zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data size: (1860, 109)\n",
      "test data size: (208, 109)\n"
     ]
    }
   ],
   "source": [
    "print('train data size:', datasets[0].shape)\n",
    "print('test data size:', datasets[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make dataset (using vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_idx_from_sent_2vec(sent, U, word_idx_map, max_l=51, k=300, filter_h=5):\n",
    "    \"\"\"\n",
    "    Transforms sentence into a list of indices. Pad with zeroes.\n",
    "    \"\"\"\n",
    "    pad = filter_h - 1\n",
    "    x = np.zeros((max_l+2*pad, k))\n",
    "\n",
    "    words = sent.split()\n",
    "    # starting after padding\n",
    "    i = pad\n",
    "    for word in words:\n",
    "        if word in word_idx_map:\n",
    "            x[i] = U[word_idx_map[word]]\n",
    "            i += 1\n",
    "    return x\n",
    "\n",
    "def make_idx_data_cv_2vec(revs, U, word_idx_map, cv, max_l=51, k=300, filter_h=5):\n",
    "    \"\"\"\n",
    "    Transforms sentences into a 2-d matrix.\n",
    "    \"\"\"\n",
    "    train_image, train_label = [], []\n",
    "    test_image, test_label = [], []\n",
    "    test_rev = []\n",
    "    for rev in revs:\n",
    "        sent = get_idx_from_sent_2vec(rev[\"text\"], U, word_idx_map, max_l, k, filter_h) # one sentence\n",
    "        if rev[\"split\"] == cv:  # \"split\" is random number of np.random.randint(0,10)\n",
    "            test_image.append(sent) \n",
    "            test_label.append(rev[\"y\"])\n",
    "            test_rev.append(rev)\n",
    "        else:  \n",
    "            train_image.append(sent)\n",
    "            train_label.append(rev[\"y\"])\n",
    "    train_image = np.array(train_image)\n",
    "    train_label = np.array(train_label)\n",
    "    test_image = np.array(test_image)\n",
    "    test_label = np.array(test_label)\n",
    "    test_rev = np.array(test_rev)\n",
    "    return (train_image, train_label), (test_image, test_label, test_rev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence length(before) 108\n"
     ]
    }
   ],
   "source": [
    "t = \"effective but too tepid biopic\"\n",
    "t_sent_2vec = get_idx_from_sent_2vec(t, U, word_idx_map, max_l, k=300, filter_h=5)\n",
    "print(\"sentence length(before)\", len(t_sent_2vec)) # max_l(51)+2*pad(filter_h-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_sent_2vec[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "datasets_2vec = make_idx_data_cv_2vec(revs, U, word_idx_map, i, max_l, k=300, filter_h=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_image, train_label), (test_image, test_label, test_rev) = datasets_2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example of sentence to vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'y': 0,\n",
       " 'text': 'え 、 サラリーマン し ながら 、 商業 漫画 の 仕事 を し て 、 ツイッター に 定期 的 に 漫画 を あげ て 、 さらに コミケ の 原稿 を 作る ！ ？',\n",
       " 'num_words': 32,\n",
       " 'split': 7}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "revs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(108, 300)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.014600</td>\n",
       "      <td>0.031418</td>\n",
       "      <td>0.090312</td>\n",
       "      <td>-0.000052</td>\n",
       "      <td>-0.013168</td>\n",
       "      <td>-0.069336</td>\n",
       "      <td>0.095244</td>\n",
       "      <td>-0.012322</td>\n",
       "      <td>-0.057443</td>\n",
       "      <td>-0.061566</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.053096</td>\n",
       "      <td>-0.027628</td>\n",
       "      <td>-0.046655</td>\n",
       "      <td>0.011596</td>\n",
       "      <td>0.024088</td>\n",
       "      <td>0.015511</td>\n",
       "      <td>-0.029644</td>\n",
       "      <td>0.006272</td>\n",
       "      <td>-0.025874</td>\n",
       "      <td>-0.076605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.054434</td>\n",
       "      <td>0.006617</td>\n",
       "      <td>0.077553</td>\n",
       "      <td>-0.057432</td>\n",
       "      <td>-0.061614</td>\n",
       "      <td>0.038032</td>\n",
       "      <td>-0.022674</td>\n",
       "      <td>0.102550</td>\n",
       "      <td>0.085985</td>\n",
       "      <td>0.045336</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006924</td>\n",
       "      <td>0.046076</td>\n",
       "      <td>0.025392</td>\n",
       "      <td>-0.070382</td>\n",
       "      <td>-0.069138</td>\n",
       "      <td>0.039778</td>\n",
       "      <td>0.039866</td>\n",
       "      <td>0.093973</td>\n",
       "      <td>0.088324</td>\n",
       "      <td>-0.098473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.015008</td>\n",
       "      <td>0.014014</td>\n",
       "      <td>0.043544</td>\n",
       "      <td>-0.039249</td>\n",
       "      <td>0.007010</td>\n",
       "      <td>0.022439</td>\n",
       "      <td>0.013127</td>\n",
       "      <td>-0.034857</td>\n",
       "      <td>0.049377</td>\n",
       "      <td>-0.051198</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071647</td>\n",
       "      <td>0.033772</td>\n",
       "      <td>0.089638</td>\n",
       "      <td>0.014955</td>\n",
       "      <td>0.064228</td>\n",
       "      <td>0.010969</td>\n",
       "      <td>-0.009657</td>\n",
       "      <td>-0.045884</td>\n",
       "      <td>0.019352</td>\n",
       "      <td>0.165582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.119047</td>\n",
       "      <td>0.027210</td>\n",
       "      <td>0.002545</td>\n",
       "      <td>0.006658</td>\n",
       "      <td>-0.011127</td>\n",
       "      <td>0.037048</td>\n",
       "      <td>0.062418</td>\n",
       "      <td>-0.032071</td>\n",
       "      <td>-0.007870</td>\n",
       "      <td>-0.047811</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006505</td>\n",
       "      <td>0.060982</td>\n",
       "      <td>-0.125483</td>\n",
       "      <td>0.103325</td>\n",
       "      <td>0.026611</td>\n",
       "      <td>0.054767</td>\n",
       "      <td>-0.005485</td>\n",
       "      <td>-0.085803</td>\n",
       "      <td>0.017624</td>\n",
       "      <td>-0.100847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.021471</td>\n",
       "      <td>0.029862</td>\n",
       "      <td>-0.038230</td>\n",
       "      <td>-0.037036</td>\n",
       "      <td>-0.000850</td>\n",
       "      <td>0.018548</td>\n",
       "      <td>0.075258</td>\n",
       "      <td>0.027883</td>\n",
       "      <td>0.055498</td>\n",
       "      <td>0.012769</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007132</td>\n",
       "      <td>0.028085</td>\n",
       "      <td>-0.053919</td>\n",
       "      <td>0.025820</td>\n",
       "      <td>0.005494</td>\n",
       "      <td>0.030930</td>\n",
       "      <td>0.052201</td>\n",
       "      <td>0.046751</td>\n",
       "      <td>0.104778</td>\n",
       "      <td>0.004859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.054434</td>\n",
       "      <td>0.006617</td>\n",
       "      <td>0.077553</td>\n",
       "      <td>-0.057432</td>\n",
       "      <td>-0.061614</td>\n",
       "      <td>0.038032</td>\n",
       "      <td>-0.022674</td>\n",
       "      <td>0.102550</td>\n",
       "      <td>0.085985</td>\n",
       "      <td>0.045336</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006924</td>\n",
       "      <td>0.046076</td>\n",
       "      <td>0.025392</td>\n",
       "      <td>-0.070382</td>\n",
       "      <td>-0.069138</td>\n",
       "      <td>0.039778</td>\n",
       "      <td>0.039866</td>\n",
       "      <td>0.093973</td>\n",
       "      <td>0.088324</td>\n",
       "      <td>-0.098473</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4 -0.014600  0.031418  0.090312 -0.000052 -0.013168 -0.069336  0.095244   \n",
       "5  0.054434  0.006617  0.077553 -0.057432 -0.061614  0.038032 -0.022674   \n",
       "6 -0.015008  0.014014  0.043544 -0.039249  0.007010  0.022439  0.013127   \n",
       "7 -0.119047  0.027210  0.002545  0.006658 -0.011127  0.037048  0.062418   \n",
       "8 -0.021471  0.029862 -0.038230 -0.037036 -0.000850  0.018548  0.075258   \n",
       "9  0.054434  0.006617  0.077553 -0.057432 -0.061614  0.038032 -0.022674   \n",
       "\n",
       "        7         8         9      ...          290       291       292  \\\n",
       "0  0.000000  0.000000  0.000000    ...     0.000000  0.000000  0.000000   \n",
       "1  0.000000  0.000000  0.000000    ...     0.000000  0.000000  0.000000   \n",
       "2  0.000000  0.000000  0.000000    ...     0.000000  0.000000  0.000000   \n",
       "3  0.000000  0.000000  0.000000    ...     0.000000  0.000000  0.000000   \n",
       "4 -0.012322 -0.057443 -0.061566    ...    -0.053096 -0.027628 -0.046655   \n",
       "5  0.102550  0.085985  0.045336    ...     0.006924  0.046076  0.025392   \n",
       "6 -0.034857  0.049377 -0.051198    ...     0.071647  0.033772  0.089638   \n",
       "7 -0.032071 -0.007870 -0.047811    ...     0.006505  0.060982 -0.125483   \n",
       "8  0.027883  0.055498  0.012769    ...     0.007132  0.028085 -0.053919   \n",
       "9  0.102550  0.085985  0.045336    ...     0.006924  0.046076  0.025392   \n",
       "\n",
       "        293       294       295       296       297       298       299  \n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "2  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "4  0.011596  0.024088  0.015511 -0.029644  0.006272 -0.025874 -0.076605  \n",
       "5 -0.070382 -0.069138  0.039778  0.039866  0.093973  0.088324 -0.098473  \n",
       "6  0.014955  0.064228  0.010969 -0.009657 -0.045884  0.019352  0.165582  \n",
       "7  0.103325  0.026611  0.054767 -0.005485 -0.085803  0.017624 -0.100847  \n",
       "8  0.025820  0.005494  0.030930  0.052201  0.046751  0.104778  0.004859  \n",
       "9 -0.070382 -0.069138  0.039778  0.039866  0.093973  0.088324 -0.098473  \n",
       "\n",
       "[10 rows x 300 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p2 = pd.DataFrame(train_image[1])\n",
    "print(p2.shape)\n",
    "p2.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make dataset iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1860"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_image = torch.FloatTensor(train_image).reshape(-1, 1, max_l + 2 * (5-1), 300)\n",
    "t_label = torch.LongTensor(train_label)\n",
    "train_dataset = list(zip(t_image, t_label))\n",
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images: torch.Size([50, 1, 108, 300]) \n",
      "labels: torch.Size([50])\n",
      "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])\n",
      "tensor(1)\n"
     ]
    }
   ],
   "source": [
    "for images, labels in train_loader:\n",
    "    print('images:', images.shape, '\\nlabels:', labels.shape)\n",
    "    print(images[1][0])\n",
    "    print(labels[1])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "208"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_image = torch.FloatTensor(test_image).reshape(-1, 1, max_l + 2 * (5-1), 300)\n",
    "c_label = torch.LongTensor(test_label)\n",
    "test_dataset = list(zip(c_image, c_label, test_rev))\n",
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loader\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model parameters (original code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_hs=[3, 4, 5]\n",
    "hidden_units=[100, num_classes]\n",
    "batch_size=50\n",
    "img_w=300\n",
    "img_h = len(datasets[0][0])-1  # sentence length (subtracted 1 for y label)\n",
    "\n",
    "filter_w = img_w    \n",
    "feature_maps = hidden_units[0]\n",
    "filter_shapes = []\n",
    "pool_sizes = []\n",
    "for filter_h in filter_hs:\n",
    "    filter_shapes.append((feature_maps, 1, filter_h, filter_w))\n",
    "    pool_sizes.append((img_h-filter_h+1, img_w-filter_w+1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(100, 1, 3, 300), (100, 1, 4, 300), (100, 1, 5, 300)]\n",
      "one batch train (50, 1, 108, 300)\n",
      "[(106, 1), (105, 1), (104, 1)]\n"
     ]
    }
   ],
   "source": [
    "print(filter_shapes)\n",
    "image_shape = (batch_size, 1, img_h, img_w)\n",
    "print('one batch train', image_shape)\n",
    "print(pool_sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding & Stride\n",
    "- Output size\n",
    "\n",
    "    $ O = \\frac {W-K+2P}{S} + 1 $\n",
    "    - O: output h/w\n",
    "    - W: input h/w\n",
    "    - K: filter size(kernel size)\n",
    "    - P: padding\n",
    "        - $  P = \\frac {K-1}{2} $\n",
    "    - S: stride"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network\n",
    "\n",
    "- Theano:\n",
    "    - conv_layer: LeNetConvPoolLayer\n",
    "    - classifier: MLPDropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model:\n",
    "\n",
    "\n",
    "```\n",
    "Network\n",
    "Input ->\n",
    "Conv -> ReLU -> MaxPool |\n",
    "Conv -> ReLU -> MaxPool | -> concat\n",
    "Conv -> ReLU -> MaxPool |\n",
    "Fully Connected Layer(Logits -> Softmax) -> Labels\n",
    "```\n",
    "\n",
    "```\n",
    "Convolutional layer formula:\n",
    "- Filter 1(Kernel) size K = 3 => (3 x 300)\n",
    "- P(same padding) P = (3-1)/2=1\n",
    "- S(stride) S = 1\n",
    "- in_channels = 1\n",
    "- out_channels (int) – Number of channels produced by the convolution = 100\n",
    "Pooling layer formula:\n",
    "- K\n",
    "```\n",
    "\n",
    "```\n",
    "*Filter dimensions*:\n",
    "Conv1 (W_conv, (100, 1, 3, 300))\n",
    "Conv1 (b_conv, (100,))\n",
    "Conv2 (W_conv, (100, 1, 4, 300))\n",
    "Conv2 (b_conv, (100,))\n",
    "Conv3 (W_conv, (100, 1, 5, 300))\n",
    "Conv3 (b_conv, (100,))\n",
    "\n",
    "*Layer input dimensions*:\n",
    "- Input image(64, 300) \n",
    "\n",
    "----------------------------------------------------------------------\n",
    "|  Conv1  (100, 3, 300)   Conv2  (100, 4, 300)   Conv3  (100, 5, 300) |\n",
    "|  MaxPool (100, 62, 1)   MaxPool (100, 61, 1)   MaxPool (100, 60, 1) |\n",
    "-----------------------------Concat ----------------------------------\n",
    "\n",
    "- Concatenated (100, 1, 1) + (100, 1, 1) + (100, 1, 1) => (300, 1, 1) \n",
    "\n",
    "- Fully Connected Layer(Logits (100, 1) -> Logits (2, 1) -> Softmax) -> Labels\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvPoolLayer(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(ConvPoolLayer, self).__init__()\n",
    "\n",
    "        # Layer 1: conv - relu - conv- relu - pool\n",
    "        self.ngram1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=feature_maps, kernel_size=(filter_hs[0], img_w), stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=pool_sizes[0], stride=None))\n",
    "        self.ngram2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=feature_maps, kernel_size=(filter_hs[1], img_w), stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=pool_sizes[1], stride=None))\n",
    "        self.ngram3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=feature_maps, kernel_size=(filter_hs[2], img_w), stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=pool_sizes[2], stride=None))\n",
    "        \n",
    "        # Fully Connected 1 (readout)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(feature_maps * 3, hidden_units[0]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_units[0], num_classes))\n",
    "\n",
    "        # Initialize all parameters using kaiming normalization\n",
    "        self.init_weights_kaiming()\n",
    "    \n",
    "    def init_weights_kaiming(self):\n",
    "        #Use kaiming normalization to initialize the parameters\n",
    "        for layer in [self.ngram1, self.ngram2, self.ngram3, self.fc]:\n",
    "            for m in layer:\n",
    "                if type(m) == nn.Conv2d or type(m) == nn.Linear:\n",
    "                    m.weight = nn.init.kaiming_normal_(m.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        out1 = self.ngram1(x)\n",
    "        out2 = self.ngram2(x)\n",
    "        out3 = self.ngram3(x)\n",
    "        out = torch.cat((out1, out2, out3), 1)\n",
    "        \n",
    "        out = out.view(out.size(0), -1)\n",
    "    \n",
    "        # Linear function (readout)\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvPoolLayer(\n",
      "  (ngram1): Sequential(\n",
      "    (0): Conv2d(1, 100, kernel_size=(3, 300), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=(106, 1), stride=(106, 1), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (ngram2): Sequential(\n",
      "    (0): Conv2d(1, 100, kernel_size=(4, 300), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=(105, 1), stride=(105, 1), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (ngram3): Sequential(\n",
      "    (0): Conv2d(1, 100, kernel_size=(5, 300), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=(104, 1), stride=(104, 1), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=300, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=100, out_features=3, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = ConvPoolLayer(num_classes)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1, 3, 300])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 4, 300])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 5, 300])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 300])\n",
      "torch.Size([100])\n",
      "torch.Size([3, 100])\n",
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "for p in model.parameters():\n",
    "    print(p.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 50. Loss: 0.31215181946754456.\n",
      "Iteration: 100. Loss: 0.05699552595615387.\n",
      "Iteration: 150. Loss: 0.03479385003447533.\n",
      "Iteration: 200. Loss: 0.005086824763566256.\n",
      "Iteration: 250. Loss: 0.0024610927794128656.\n",
      "Iteration: 300. Loss: 0.002773027401417494.\n",
      "Iteration: 350. Loss: 0.003598378971219063.\n"
     ]
    }
   ],
   "source": [
    "avg_losses = list()\n",
    "iter = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        total_loss = list()\n",
    "        \n",
    "        # Load images as Variable\n",
    "        images = Variable(images) # Now we dont need to resize like images.view(xx)\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        # Clear gradients w.r.t parameters\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass to get output/logits\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # Calculate Loss: Softmax --> cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Getting gradients w.r.t paramters\n",
    "        loss.backward()\n",
    "        \n",
    "        # Track loss to plot the result\n",
    "        total_loss.append(loss.item())\n",
    "        \n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        iter += 1\n",
    "        \n",
    "        if iter % 50 == 0:\n",
    "            # Print Loss\n",
    "            print('Iteration: {}. Loss: {}.'.format(iter, loss.item()))\n",
    "            avg_loss = np.divide(np.sum(total_loss), len(total_loss))\n",
    "            avg_losses.append(avg_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the loss vs iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_axis = np.arange(len(avg_losses))\n",
    "plt.plot(x_axis, avg_losses, label='train')\n",
    "plt.xlabel('iterations (x100)')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model with test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 250 test images: 98.5576923076923 %\n"
     ]
    }
   ],
   "source": [
    "n_test = len(test_loader) * batch_size\n",
    "wrong_predictions = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels, revs in test_loader:\n",
    "        images = Variable(images)\n",
    "        labels = Variable(labels)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        # See which are error predictions\n",
    "        result = (predicted == labels)\n",
    "        err_imgs = images[result == 0] # 0 means wrong prediction\n",
    "        err_labels = labels[result == 0]\n",
    "        err_p = outputs[result == 0]\n",
    "        err_outputs = predicted[result == 0]\n",
    "        err_texts = np.array(revs['text'])[np.array((result == 0).numpy(), dtype=np.bool)]\n",
    "        for img, lbl, p, out, text in zip(err_imgs, err_labels, err_p, err_outputs, err_texts):\n",
    "            wrong_predictions.append((img, lbl, p, out, text))\n",
    "     \n",
    "    print('Test Accuracy of the model on the {} test images: {} %'.format(n_test, 100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True label:  2 \t 暮らし系\n",
      "Predition:  0 \t エンタメ系\n",
      "Possibility: tensor([ 4.0586, -4.8071, -1.5552])\n",
      "だいたい ３ ０ ０ ０ 円 前後 な の か な ・ ・ ・ カード ゲーム 全然 やっ て ない から プレイマット って どういう 風 に 収納 し たり する の か わかっ て ない けど 折りたたん じゃう の か な ？ それとも 巻物 みたい に クルクル 巻く の か な ・ ・ ・ \n",
      "\n",
      "True label:  2 \t 暮らし系\n",
      "Predition:  1 \t 美容系\n",
      "Possibility: tensor([-6.3041,  6.8313,  1.5241])\n",
      "料理 や 野菜 など に 含ま れ て いる 水分 で は なく 、 水 自体 （ ミネラル ウォーター 等 ） を 1 時間 に コップ 1 杯 飲む と いい らしい です よ 。 この こと を 習慣 化 さ せる と 、 脳 梗塞 が 予防 できる ん だ とか ！ # 美容 # 健康 \n",
      "\n",
      "True label:  2 \t 暮らし系\n",
      "Predition:  0 \t エンタメ系\n",
      "Possibility: tensor([ 3.0384, -7.4430,  2.6322])\n",
      "ガルパ に 登場 する キャラクター たち の 日常 を 描い た ４ コマ 漫画 、 『 もっと ！ ガルパライフ 』 （# ガルパラ ） を 更新 し まし た 第 94 話 「 元気 の 出 ない とき に 」 今 まで の お話 は こちら → # バンドリ # ガ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "label_names = ['エンタメ系', '美容系', '暮らし系']\n",
    "# unpack img, lbl, out, text\n",
    "for img, lbl, p, out, text in wrong_predictions:\n",
    "    print('True label: ', lbl.item(), '\\t', label_names[lbl.item()])\n",
    "    print('Predition: ', out.item(), '\\t', label_names[out.item()])\n",
    "    print('Possibility:', p)\n",
    "    print(text, '\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model with train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 1900 train images: 99.40860215053763 %\n"
     ]
    }
   ],
   "source": [
    "n_train = len(train_loader) * batch_size\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in train_loader:\n",
    "        images = Variable(images)\n",
    "        labels = Variable(labels)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "    print('Test Accuracy of the model on the {} train images: {} %'.format(n_train, 100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict single inputted text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input the text to predict (change the text below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_to_predict = \"お風呂掃除でいつも落ちなかった溝にある黒カビが家事えもんの塩素系漂白剤＋片栗粉でほぼ真っ白になって感動 家事えもんのテクニック凄い～！\"\n",
    "\n",
    "text_to_predict = \"コスメの最安値が見つけられるアプリ💄💋メイク動画とか 美容情報も載ってるし最高😆🙌📲http://goo.gl/K5Fmea 女子にはほんとに助かる〜💗\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data...\n",
      "data loaded!\n",
      "number of sentences: 2068\n",
      "vocab size: 10329\n",
      "max sentence length: 100\n",
      "loading word2vec vectors...\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "from process_data import build_single_data_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_make_idx_data_cv_2vec(revs, U, word_idx_map, max_l=51, k=300, filter_h=5):\n",
    "    \"\"\"\n",
    "    Transforms sentences into a 2-d matrix.\n",
    "    \"\"\"\n",
    "    test_image, test_label = [], []\n",
    "    test_rev = []\n",
    "    for rev in revs:\n",
    "        sent = get_idx_from_sent_2vec(rev[\"text\"], U, word_idx_map, max_l, k, filter_h) # one sentence\n",
    "        test_image.append(sent) \n",
    "        test_label.append(rev[\"y\"])\n",
    "        test_rev.append(rev)\n",
    "\n",
    "    test_image = np.array(test_image)\n",
    "    test_label = np.array(test_label)\n",
    "    test_rev = np.array(test_rev)\n",
    "    return test_image, test_label, test_rev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1行処理済み\n"
     ]
    }
   ],
   "source": [
    "single_revs, _ = build_single_data_cv(text_to_predict)\n",
    "single_data_2vec = single_make_idx_data_cv_2vec(single_revs, U, word_idx_map, max_l, k=300, filter_h=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 1 美容系\n",
      "Text: コスメ の 最 安値 が 見つけ られる アプリメイク 動画 とか 美容 情報 も 載っ てる し 最高 女子 に は ほんとに 助かる 〜\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    images, labels, revs = single_data_2vec\n",
    "    images = Variable(torch.Tensor(images.reshape(1, 1, -1, 300)))\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    print('Prediction:', predicted.item(), label_names[predicted.item()])\n",
    "    print('Text:', revs[0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
