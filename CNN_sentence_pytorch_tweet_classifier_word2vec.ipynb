{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialized word vector with pretrain japanese word2vec \n",
    "\n",
    "https://github.com/Kyubyong/wordvectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = \"-word2vec\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import cPickle (python2.7)\n",
    "#http://testpy.hatenablog.com/entry/2017/03/17/000626\n",
    "import _pickle as cPickle\n",
    "\n",
    "import numpy as np\n",
    "from collections import defaultdict, OrderedDict\n",
    "\n",
    "import re\n",
    "import sys\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameters\n",
    "num_epochs = 10\n",
    "num_classes = 3\n",
    "batch_size = 50\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load pickle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the pickle file contains [revs, W, W2, word_idx_map, vocab] # W2 random vectors\n",
    "x = cPickle.load(open(\"gensim_tweet.p\",\"rb\"), encoding=\"latin1\") # Add encoding=\"latin1\" because got UnicodeDecodeError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset content\n",
    "Get data from twitter (reference: http://tech.wonderpla.net/entry/2017/10/10/110000)\n",
    "- Label 0\n",
    "    - KEYWORD = \"芸能 OR アニメ OR 漫画 OR ドラマ OR ゲーム\"            #エンタメ系のキーワード\n",
    "    - CLASS_LABEL = \"\\__label__0\"\n",
    "\n",
    "- Label 1\n",
    "    - KEYWORD = \"美容 OR サロン OR エステ OR 化粧 OR 保湿\"            #美容系のキーワード\n",
    "    - CLASS_LABEL = \"\\__label__1\"\n",
    "\n",
    "- Label 2\n",
    "    - KEYWORD = \"日常 OR 料理 OR 家事 OR 収納 OR 家具\"            #暮らし系のキーワード\n",
    "    - CLASS_LABEL = \"\\__label__2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### See data sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_words</th>\n",
       "      <th>split</th>\n",
       "      <th>text</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>某 違法 サイト が 潰れ て から 数 ヶ月 、 各 漫画 家 や 漫画 原作 者 さん ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>44</td>\n",
       "      <td>5</td>\n",
       "      <td>ルージュ さん おはよう ござい ます ！ かき ふら い さん の 名義 で これ まで ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    num_words  split                                               text  y\n",
       "59         33      2  某 違法 サイト が 潰れ て から 数 ヶ月 、 各 漫画 家 や 漫画 原作 者 さん ...  0\n",
       "82         44      5  ルージュ さん おはよう ござい ます ！ かき ふら い さん の 名義 で これ まで ...  0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(x[0])\n",
    "\n",
    "# label 0: Entertainment \n",
    "df[df['y'] == 0].sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_words</th>\n",
       "      <th>split</th>\n",
       "      <th>text</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1048</th>\n",
       "      <td>72</td>\n",
       "      <td>7</td>\n",
       "      <td>シル キー 2 ウェイ ファンデーション ( spf 20 / pa ++) 透明 感 の ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1069</th>\n",
       "      <td>62</td>\n",
       "      <td>4</td>\n",
       "      <td>ホームページ で は 美容 ・ 健康 ・ ブライダル の お 得 な 情報 を 掲載 し て...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      num_words  split                                               text  y\n",
       "1048         72      7  シル キー 2 ウェイ ファンデーション ( spf 20 / pa ++) 透明 感 の ...  1\n",
       "1069         62      4  ホームページ で は 美容 ・ 健康 ・ ブライダル の お 得 な 情報 を 掲載 し て...  1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# label 1 : Beauty\n",
    "df[df['y'] == 1].sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_words</th>\n",
       "      <th>split</th>\n",
       "      <th>text</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1432</th>\n",
       "      <td>52</td>\n",
       "      <td>4</td>\n",
       "      <td>修羅場 家 の 日常 : 結婚式 に 出席 し た 時 、 トイレ に 中座 し て た 友...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1742</th>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>日常 生活 に は 支障 ない ん だ けど な 〜 〜 〜 作業 が 辛い</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      num_words  split                                               text  y\n",
       "1432         52      4  修羅場 家 の 日常 : 結婚式 に 出席 し た 時 、 トイレ に 中座 し て た 友...  2\n",
       "1742         16      7             日常 生活 に は 支障 ない ん だ けど な 〜 〜 〜 作業 が 辛い  2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# label 2: Life\n",
    "df[df['y'] == 2].sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "revs, W, W2, word_idx_map, vocab = x[0], x[1], x[2], x[3], x[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max sentence length:  100\n"
     ]
    }
   ],
   "source": [
    "# Get the number of the longest sentence\n",
    "max_l = np.max(pd.DataFrame(revs)[\"num_words\"])\n",
    "print(\"max sentence length: \", max_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "revs 2068\n",
      "W 10330\n",
      "W2 10330\n",
      "word_idx_map 10329\n",
      "vocab 10329\n"
     ]
    }
   ],
   "source": [
    "print('revs',len(x[0])) # number of sentence\n",
    "print('W', len(x[1])) # W are pretrained word vectors (unknown words are randomly initialized)\n",
    "print('W2', len(x[2])) # W2 are randomly initialized vectors\n",
    "print('word_idx_map', len(x[3]))\n",
    "print('vocab', len(x[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'y': 0,\n",
       " 'text': 'え 、 サラリーマン し ながら 、 商業 漫画 の 仕事 を し て 、 ツイッター に 定期 的 に 漫画 を あげ て 、 さらに コミケ の 原稿 を 作る ！ ？',\n",
       " 'num_words': 32,\n",
       " 'split': 1}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "revs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using: word2vec vectors\n"
     ]
    }
   ],
   "source": [
    "if word_vectors==\"-rand\":\n",
    "    print(\"using: random vectors\")\n",
    "    U = W2\n",
    "elif word_vectors==\"-word2vec\":\n",
    "    print(\"using: word2vec vectors\")\n",
    "    U = W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10330, 300)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make dataset (check original code)\n",
    "make each sentence an word index map using word_idx_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_idx_from_sent(sent, word_idx_map, max_l=51, k=300, filter_h=5):\n",
    "    \"\"\"\n",
    "    Transforms sentence into a list of indices. Pad with zeroes.\n",
    "    \"\"\"\n",
    "    x = []\n",
    "    pad = filter_h - 1\n",
    "    for i in range(pad):\n",
    "        x.append(0)\n",
    "    words = sent.split()\n",
    "    for word in words:\n",
    "        if word in word_idx_map:\n",
    "            x.append(word_idx_map[word])\n",
    "    while len(x) < max_l + 2*pad:\n",
    "        x.append(0)\n",
    "    return x\n",
    "\n",
    "def make_idx_data_cv(revs, word_idx_map, cv, max_l=51, k=300, filter_h=5):\n",
    "    \"\"\"\n",
    "    Transforms sentences into a 2-d matrix.\n",
    "    \"\"\"\n",
    "    train, test = [], []\n",
    "    for rev in revs:\n",
    "        sent = get_idx_from_sent(rev[\"text\"], word_idx_map, max_l, k, filter_h) # one sentence\n",
    "        sent.append(rev[\"y\"])\n",
    "        if rev[\"split\"]== cv:  # \"split\" is random number of np.random.randint(0,10)\n",
    "            test.append(sent)        \n",
    "        else:  \n",
    "            train.append(sent)   \n",
    "    train = np.array(train, dtype=\"int\")\n",
    "    test = np.array(test, dtype=\"int\")\n",
    "    return [train, test] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "datasets = make_idx_data_cv(revs, word_idx_map, i, max_l, k=300, filter_h=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example of sentence to word index map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'y': 0,\n",
       " 'text': 'え 、 サラリーマン し ながら 、 商業 漫画 の 仕事 を し て 、 ツイッター に 定期 的 に 漫画 を あげ て 、 さらに コミケ の 原稿 を 作る ！ ？',\n",
       " 'num_words': 32,\n",
       " 'split': 1}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "revs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0, 49, 31, 40, 22, 33, 31, 36,  1, 39, 46, 44, 22,  8,\n",
       "       31, 45, 16, 47, 35, 16,  1, 44, 43,  8, 31, 41, 37, 39, 42, 44, 34,\n",
       "       38, 48,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(datasets[0][0]))\n",
    "datasets[0][1] # sentence => word index map padding with zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data size: (1853, 109)\n",
      "test data size: (215, 109)\n"
     ]
    }
   ],
   "source": [
    "print('train data size:', datasets[0].shape)\n",
    "print('test data size:', datasets[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make dataset (using vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_idx_from_sent_2vec(sent, U, word_idx_map, max_l=51, k=300, filter_h=5):\n",
    "    \"\"\"\n",
    "    Transforms sentence into a list of indices. Pad with zeroes.\n",
    "    \"\"\"\n",
    "    pad = filter_h - 1\n",
    "    x = np.zeros((max_l+2*pad, k))\n",
    "\n",
    "    words = sent.split()\n",
    "    # starting after padding\n",
    "    i = pad\n",
    "    for word in words:\n",
    "        if word in word_idx_map:\n",
    "            x[i] = U[word_idx_map[word]]\n",
    "            i += 1\n",
    "    return x\n",
    "\n",
    "def make_idx_data_cv_2vec(revs, U, word_idx_map, cv, max_l=51, k=300, filter_h=5):\n",
    "    \"\"\"\n",
    "    Transforms sentences into a 2-d matrix.\n",
    "    \"\"\"\n",
    "    train_image, train_label = [], []\n",
    "    test_image, test_label = [], []\n",
    "    test_rev = []\n",
    "    for rev in revs:\n",
    "        sent = get_idx_from_sent_2vec(rev[\"text\"], U, word_idx_map, max_l, k, filter_h) # one sentence\n",
    "        if rev[\"split\"] == cv:  # \"split\" is random number of np.random.randint(0,10)\n",
    "            test_image.append(sent) \n",
    "            test_label.append(rev[\"y\"])\n",
    "            test_rev.append(rev)\n",
    "        else:  \n",
    "            train_image.append(sent)\n",
    "            train_label.append(rev[\"y\"])\n",
    "    train_image = np.array(train_image)\n",
    "    train_label = np.array(train_label)\n",
    "    test_image = np.array(test_image)\n",
    "    test_label = np.array(test_label)\n",
    "    test_rev = np.array(test_rev)\n",
    "    return (train_image, train_label), (test_image, test_label, test_rev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence length(before) 108\n"
     ]
    }
   ],
   "source": [
    "t = \"effective but too tepid biopic\"\n",
    "t_sent_2vec = get_idx_from_sent_2vec(t, U, word_idx_map, max_l, k=300, filter_h=5)\n",
    "print(\"sentence length(before)\", len(t_sent_2vec)) # max_l(51)+2*pad(filter_h-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_sent_2vec[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "datasets_2vec = make_idx_data_cv_2vec(revs, U, word_idx_map, i, max_l, k=300, filter_h=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_image, train_label), (test_image, test_label, test_rev) = datasets_2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example of sentence to vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'y': 0,\n",
       " 'text': 'え 、 サラリーマン し ながら 、 商業 漫画 の 仕事 を し て 、 ツイッター に 定期 的 に 漫画 を あげ て 、 さらに コミケ の 原稿 を 作る ！ ？',\n",
       " 'num_words': 32,\n",
       " 'split': 1}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "revs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(108, 300)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.047938</td>\n",
       "      <td>-0.012884</td>\n",
       "      <td>-0.056857</td>\n",
       "      <td>-0.012662</td>\n",
       "      <td>-0.017988</td>\n",
       "      <td>0.017350</td>\n",
       "      <td>0.047852</td>\n",
       "      <td>-0.029005</td>\n",
       "      <td>-0.001137</td>\n",
       "      <td>0.026639</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.045853</td>\n",
       "      <td>0.016910</td>\n",
       "      <td>-0.039848</td>\n",
       "      <td>-0.064570</td>\n",
       "      <td>-0.058615</td>\n",
       "      <td>0.009916</td>\n",
       "      <td>-0.014220</td>\n",
       "      <td>0.107975</td>\n",
       "      <td>0.116522</td>\n",
       "      <td>0.110864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.071014</td>\n",
       "      <td>-0.010093</td>\n",
       "      <td>-0.048892</td>\n",
       "      <td>0.049935</td>\n",
       "      <td>0.004244</td>\n",
       "      <td>0.059785</td>\n",
       "      <td>0.005612</td>\n",
       "      <td>-0.127936</td>\n",
       "      <td>-0.039739</td>\n",
       "      <td>0.004968</td>\n",
       "      <td>...</td>\n",
       "      <td>0.103655</td>\n",
       "      <td>-0.051866</td>\n",
       "      <td>0.087268</td>\n",
       "      <td>0.056497</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>-0.005126</td>\n",
       "      <td>0.130839</td>\n",
       "      <td>-0.009686</td>\n",
       "      <td>0.003536</td>\n",
       "      <td>0.077469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.110441</td>\n",
       "      <td>-0.025591</td>\n",
       "      <td>-0.066245</td>\n",
       "      <td>0.078289</td>\n",
       "      <td>-0.043802</td>\n",
       "      <td>-0.002915</td>\n",
       "      <td>-0.022811</td>\n",
       "      <td>-0.006989</td>\n",
       "      <td>-0.010652</td>\n",
       "      <td>0.029903</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025297</td>\n",
       "      <td>-0.042852</td>\n",
       "      <td>-0.079471</td>\n",
       "      <td>-0.085797</td>\n",
       "      <td>-0.026410</td>\n",
       "      <td>0.000728</td>\n",
       "      <td>-0.072049</td>\n",
       "      <td>-0.070150</td>\n",
       "      <td>0.079390</td>\n",
       "      <td>-0.112369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.048331</td>\n",
       "      <td>0.033419</td>\n",
       "      <td>-0.031500</td>\n",
       "      <td>-0.071572</td>\n",
       "      <td>0.066776</td>\n",
       "      <td>-0.022589</td>\n",
       "      <td>-0.016808</td>\n",
       "      <td>0.019989</td>\n",
       "      <td>-0.108131</td>\n",
       "      <td>-0.035041</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.081411</td>\n",
       "      <td>0.009484</td>\n",
       "      <td>-0.001005</td>\n",
       "      <td>0.088263</td>\n",
       "      <td>-0.018893</td>\n",
       "      <td>0.041408</td>\n",
       "      <td>-0.079723</td>\n",
       "      <td>-0.078454</td>\n",
       "      <td>-0.043328</td>\n",
       "      <td>-0.036232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.128078</td>\n",
       "      <td>0.067364</td>\n",
       "      <td>0.004988</td>\n",
       "      <td>0.013444</td>\n",
       "      <td>-0.015906</td>\n",
       "      <td>-0.113039</td>\n",
       "      <td>-0.053078</td>\n",
       "      <td>0.010158</td>\n",
       "      <td>-0.043217</td>\n",
       "      <td>-0.024071</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.120665</td>\n",
       "      <td>0.040173</td>\n",
       "      <td>0.007844</td>\n",
       "      <td>-0.046066</td>\n",
       "      <td>-0.053584</td>\n",
       "      <td>0.060227</td>\n",
       "      <td>-0.129146</td>\n",
       "      <td>-0.029178</td>\n",
       "      <td>0.015250</td>\n",
       "      <td>0.054799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.071014</td>\n",
       "      <td>-0.010093</td>\n",
       "      <td>-0.048892</td>\n",
       "      <td>0.049935</td>\n",
       "      <td>0.004244</td>\n",
       "      <td>0.059785</td>\n",
       "      <td>0.005612</td>\n",
       "      <td>-0.127936</td>\n",
       "      <td>-0.039739</td>\n",
       "      <td>0.004968</td>\n",
       "      <td>...</td>\n",
       "      <td>0.103655</td>\n",
       "      <td>-0.051866</td>\n",
       "      <td>0.087268</td>\n",
       "      <td>0.056497</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>-0.005126</td>\n",
       "      <td>0.130839</td>\n",
       "      <td>-0.009686</td>\n",
       "      <td>0.003536</td>\n",
       "      <td>0.077469</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4  0.047938 -0.012884 -0.056857 -0.012662 -0.017988  0.017350  0.047852   \n",
       "5 -0.071014 -0.010093 -0.048892  0.049935  0.004244  0.059785  0.005612   \n",
       "6 -0.110441 -0.025591 -0.066245  0.078289 -0.043802 -0.002915 -0.022811   \n",
       "7  0.048331  0.033419 -0.031500 -0.071572  0.066776 -0.022589 -0.016808   \n",
       "8 -0.128078  0.067364  0.004988  0.013444 -0.015906 -0.113039 -0.053078   \n",
       "9 -0.071014 -0.010093 -0.048892  0.049935  0.004244  0.059785  0.005612   \n",
       "\n",
       "        7         8         9      ...          290       291       292  \\\n",
       "0  0.000000  0.000000  0.000000    ...     0.000000  0.000000  0.000000   \n",
       "1  0.000000  0.000000  0.000000    ...     0.000000  0.000000  0.000000   \n",
       "2  0.000000  0.000000  0.000000    ...     0.000000  0.000000  0.000000   \n",
       "3  0.000000  0.000000  0.000000    ...     0.000000  0.000000  0.000000   \n",
       "4 -0.029005 -0.001137  0.026639    ...    -0.045853  0.016910 -0.039848   \n",
       "5 -0.127936 -0.039739  0.004968    ...     0.103655 -0.051866  0.087268   \n",
       "6 -0.006989 -0.010652  0.029903    ...    -0.025297 -0.042852 -0.079471   \n",
       "7  0.019989 -0.108131 -0.035041    ...    -0.081411  0.009484 -0.001005   \n",
       "8  0.010158 -0.043217 -0.024071    ...    -0.120665  0.040173  0.007844   \n",
       "9 -0.127936 -0.039739  0.004968    ...     0.103655 -0.051866  0.087268   \n",
       "\n",
       "        293       294       295       296       297       298       299  \n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "2  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "4 -0.064570 -0.058615  0.009916 -0.014220  0.107975  0.116522  0.110864  \n",
       "5  0.056497  0.000689 -0.005126  0.130839 -0.009686  0.003536  0.077469  \n",
       "6 -0.085797 -0.026410  0.000728 -0.072049 -0.070150  0.079390 -0.112369  \n",
       "7  0.088263 -0.018893  0.041408 -0.079723 -0.078454 -0.043328 -0.036232  \n",
       "8 -0.046066 -0.053584  0.060227 -0.129146 -0.029178  0.015250  0.054799  \n",
       "9  0.056497  0.000689 -0.005126  0.130839 -0.009686  0.003536  0.077469  \n",
       "\n",
       "[10 rows x 300 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p2 = pd.DataFrame(train_image[1])\n",
    "print(p2.shape)\n",
    "p2.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make dataset iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1853"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_image = torch.FloatTensor(train_image).reshape(-1, 1, max_l + 2 * (5-1), 300)\n",
    "t_label = torch.LongTensor(train_label)\n",
    "train_dataset = list(zip(t_image, t_label))\n",
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images: torch.Size([50, 1, 108, 300]) \n",
      "labels: torch.Size([50])\n",
      "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])\n",
      "tensor(0)\n"
     ]
    }
   ],
   "source": [
    "for images, labels in train_loader:\n",
    "    print('images:', images.shape, '\\nlabels:', labels.shape)\n",
    "    print(images[1][0])\n",
    "    print(labels[1])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "215"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_image = torch.FloatTensor(test_image).reshape(-1, 1, max_l + 2 * (5-1), 300)\n",
    "c_label = torch.LongTensor(test_label)\n",
    "test_dataset = list(zip(c_image, c_label, test_rev))\n",
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loader\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model parameters (original code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_hs=[3, 4, 5]\n",
    "hidden_units=[100, num_classes]\n",
    "batch_size=50\n",
    "img_w=300\n",
    "img_h = len(datasets[0][0])-1  # sentence length (subtracted 1 for y label)\n",
    "\n",
    "filter_w = img_w    \n",
    "feature_maps = hidden_units[0]\n",
    "filter_shapes = []\n",
    "pool_sizes = []\n",
    "for filter_h in filter_hs:\n",
    "    filter_shapes.append((feature_maps, 1, filter_h, filter_w))\n",
    "    pool_sizes.append((img_h-filter_h+1, img_w-filter_w+1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(100, 1, 3, 300), (100, 1, 4, 300), (100, 1, 5, 300)]\n",
      "one batch train (50, 1, 108, 300)\n",
      "[(106, 1), (105, 1), (104, 1)]\n"
     ]
    }
   ],
   "source": [
    "print(filter_shapes)\n",
    "image_shape = (batch_size, 1, img_h, img_w)\n",
    "print('one batch train', image_shape)\n",
    "print(pool_sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding & Stride\n",
    "- Output size\n",
    "\n",
    "    $ O = \\frac {W-K+2P}{S} + 1 $\n",
    "    - O: output h/w\n",
    "    - W: input h/w\n",
    "    - K: filter size(kernel size)\n",
    "    - P: padding\n",
    "        - $  P = \\frac {K-1}{2} $\n",
    "    - S: stride"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network\n",
    "\n",
    "- Theano:\n",
    "    - conv_layer: LeNetConvPoolLayer\n",
    "    - classifier: MLPDropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model:\n",
    "\n",
    "\n",
    "```\n",
    "Network\n",
    "Input ->\n",
    "Conv -> ReLU -> MaxPool |\n",
    "Conv -> ReLU -> MaxPool | -> concat\n",
    "Conv -> ReLU -> MaxPool |\n",
    "Fully Connected Layer(Logits -> Softmax) -> Labels\n",
    "```\n",
    "\n",
    "```\n",
    "Convolutional layer formula:\n",
    "- Filter 1(Kernel) size K = 3 => (3 x 300)\n",
    "- P(same padding) P = (3-1)/2=1\n",
    "- S(stride) S = 1\n",
    "- in_channels = 1\n",
    "- out_channels (int) – Number of channels produced by the convolution = 100\n",
    "Pooling layer formula:\n",
    "- K\n",
    "```\n",
    "\n",
    "```\n",
    "*Filter dimensions*:\n",
    "Conv1 (W_conv, (100, 1, 3, 300))\n",
    "Conv1 (b_conv, (100,))\n",
    "Conv2 (W_conv, (100, 1, 4, 300))\n",
    "Conv2 (b_conv, (100,))\n",
    "Conv3 (W_conv, (100, 1, 5, 300))\n",
    "Conv3 (b_conv, (100,))\n",
    "\n",
    "*Layer input dimensions*:\n",
    "- Input image(64, 300) \n",
    "\n",
    "----------------------------------------------------------------------\n",
    "|  Conv1  (100, 3, 300)   Conv2  (100, 4, 300)   Conv3  (100, 5, 300) |\n",
    "|  MaxPool (100, 62, 1)   MaxPool (100, 61, 1)   MaxPool (100, 60, 1) |\n",
    "-----------------------------Concat ----------------------------------\n",
    "\n",
    "- Concatenated (100, 1, 1) + (100, 1, 1) + (100, 1, 1) => (300, 1, 1) \n",
    "\n",
    "- Fully Connected Layer(Logits (100, 1) -> Logits (2, 1) -> Softmax) -> Labels\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvPoolLayer(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(ConvPoolLayer, self).__init__()\n",
    "\n",
    "        # Layer 1: conv - relu - conv- relu - pool\n",
    "        self.ngram1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=feature_maps, kernel_size=(filter_hs[0], img_w), stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=pool_sizes[0], stride=None))\n",
    "        self.ngram2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=feature_maps, kernel_size=(filter_hs[1], img_w), stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=pool_sizes[1], stride=None))\n",
    "        self.ngram3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=feature_maps, kernel_size=(filter_hs[2], img_w), stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=pool_sizes[2], stride=None))\n",
    "        \n",
    "        # Fully Connected 1 (readout)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(feature_maps * 3, hidden_units[0]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_units[0], num_classes))\n",
    "\n",
    "        # Initialize all parameters using kaiming normalization\n",
    "        self.init_weights_kaiming()\n",
    "    \n",
    "    def init_weights_kaiming(self):\n",
    "        #Use kaiming normalization to initialize the parameters\n",
    "        for layer in [self.ngram1, self.ngram2, self.ngram3, self.fc]:\n",
    "            for m in layer:\n",
    "                if type(m) == nn.Conv2d or type(m) == nn.Linear:\n",
    "                    m.weight = nn.init.kaiming_normal_(m.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        out1 = self.ngram1(x)\n",
    "        out2 = self.ngram2(x)\n",
    "        out3 = self.ngram3(x)\n",
    "        out = torch.cat((out1, out2, out3), 1)\n",
    "        \n",
    "        out = out.view(out.size(0), -1)\n",
    "    \n",
    "        # Linear function (readout)\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvPoolLayer(\n",
      "  (ngram1): Sequential(\n",
      "    (0): Conv2d(1, 100, kernel_size=(3, 300), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=(106, 1), stride=(106, 1), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (ngram2): Sequential(\n",
      "    (0): Conv2d(1, 100, kernel_size=(4, 300), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=(105, 1), stride=(105, 1), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (ngram3): Sequential(\n",
      "    (0): Conv2d(1, 100, kernel_size=(5, 300), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=(104, 1), stride=(104, 1), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=300, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=100, out_features=3, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = ConvPoolLayer(num_classes)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1, 3, 300])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 4, 300])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 5, 300])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 300])\n",
      "torch.Size([100])\n",
      "torch.Size([3, 100])\n",
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "for p in model.parameters():\n",
    "    print(p.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 50. Loss: 0.16025562584400177.\n",
      "Iteration: 100. Loss: 0.028041373938322067.\n",
      "Iteration: 150. Loss: 0.010904279537498951.\n",
      "Iteration: 200. Loss: 0.0031761773861944675.\n",
      "Iteration: 250. Loss: 0.05298465117812157.\n",
      "Iteration: 300. Loss: 0.011562262661755085.\n",
      "Iteration: 350. Loss: 0.003827402601018548.\n"
     ]
    }
   ],
   "source": [
    "avg_losses = list()\n",
    "iter = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        total_loss = list()\n",
    "        \n",
    "        # Load images as Variable\n",
    "        images = Variable(images) # Now we dont need to resize like images.view(xx)\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        # Clear gradients w.r.t parameters\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass to get output/logits\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # Calculate Loss: Softmax --> cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Getting gradients w.r.t paramters\n",
    "        loss.backward()\n",
    "        \n",
    "        # Track loss to plot the result\n",
    "        total_loss.append(loss.item())\n",
    "        \n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        iter += 1\n",
    "        \n",
    "        if iter % 50 == 0:\n",
    "            # Print Loss\n",
    "            print('Iteration: {}. Loss: {}.'.format(iter, loss.item()))\n",
    "            avg_loss = np.divide(np.sum(total_loss), len(total_loss))\n",
    "            avg_losses.append(avg_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the loss vs iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_axis = np.arange(len(avg_losses))\n",
    "plt.plot(x_axis, avg_losses, label='train')\n",
    "plt.xlabel('iterations (x100)')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model with test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 250 test images: 99.06976744186046 %\n"
     ]
    }
   ],
   "source": [
    "n_test = len(test_loader) * batch_size\n",
    "wrong_predictions = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels, revs in test_loader:\n",
    "        images = Variable(images)\n",
    "        labels = Variable(labels)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        # See which are error predictions\n",
    "        result = (predicted == labels)\n",
    "        err_imgs = images[result == 0] # 0 means wrong prediction\n",
    "        err_labels = labels[result == 0]\n",
    "        err_p = outputs[result == 0]\n",
    "        err_outputs = predicted[result == 0]\n",
    "        err_texts = np.array(revs['text'])[np.array((result == 0).numpy(), dtype=np.bool)]\n",
    "        for img, lbl, p, out, text in zip(err_imgs, err_labels, err_p, err_outputs, err_texts):\n",
    "            wrong_predictions.append((img, lbl, p, out, text))\n",
    "     \n",
    "    print('Test Accuracy of the model on the {} test images: {} %'.format(n_test, 100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True label:  0 \t エンタメ系\n",
      "Predition:  2 \t 暮らし系\n",
      "Possibility: tensor([ 0.8326, -8.3825,  2.3618])\n",
      "ガルパ に 登場 する キャラクター たち の 日常 を 描い た ４ コマ 漫画 、 『 もっと ！ ガルパライフ 』 （# ガルパラ ） を 更新 し まし た 第 94 話 「 元気 の 出 ない とき に 」 今 まで の お話 は こちら → # バンドリ # ガ \n",
      "\n",
      "True label:  2 \t 暮らし系\n",
      "Predition:  0 \t エンタメ系\n",
      "Possibility: tensor([-0.2630, -1.8365, -0.5394])\n",
      "見 たい ！ ！ ！ やっぱ 、 ディズニー グッズ を どう 収納 し てる の か 気 に なる (*'▽'*) カチューシャ とか 、 ポップコーン ケース とか 。(*'▽'*) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "label_names = ['エンタメ系', '美容系', '暮らし系']\n",
    "# unpack img, lbl, out, text\n",
    "for img, lbl, p, out, text in wrong_predictions:\n",
    "    print('True label: ', lbl.item(), '\\t', label_names[lbl.item()])\n",
    "    print('Predition: ', out.item(), '\\t', label_names[out.item()])\n",
    "    print('Possibility:', p)\n",
    "    print(text, '\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model with train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 1900 train images: 99.7301672962763 %\n"
     ]
    }
   ],
   "source": [
    "n_train = len(train_loader) * batch_size\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in train_loader:\n",
    "        images = Variable(images)\n",
    "        labels = Variable(labels)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "    print('Test Accuracy of the model on the {} train images: {} %'.format(n_train, 100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict single inputted text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input the text to predict (change the text below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_to_predict = \"お風呂掃除でいつも落ちなかった溝にある黒カビが家事えもんの塩素系漂白剤＋片栗粉でほぼ真っ白になって感動 家事えもんのテクニック凄い～！\"\n",
    "\n",
    "text_to_predict = \"コスメの最安値が見つけられるアプリ💄💋メイク動画とか 美容情報も載ってるし最高😆🙌📲http://goo.gl/K5Fmea 女子にはほんとに助かる〜💗\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data...\n",
      "data loaded!\n",
      "number of sentences: 2068\n",
      "vocab size: 10329\n",
      "max sentence length: 100\n",
      "loading word2vec vectors...\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "from process_data import build_single_data_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_make_idx_data_cv_2vec(revs, U, word_idx_map, max_l=51, k=300, filter_h=5):\n",
    "    \"\"\"\n",
    "    Transforms sentences into a 2-d matrix.\n",
    "    \"\"\"\n",
    "    test_image, test_label = [], []\n",
    "    test_rev = []\n",
    "    for rev in revs:\n",
    "        sent = get_idx_from_sent_2vec(rev[\"text\"], U, word_idx_map, max_l, k, filter_h) # one sentence\n",
    "        test_image.append(sent) \n",
    "        test_label.append(rev[\"y\"])\n",
    "        test_rev.append(rev)\n",
    "\n",
    "    test_image = np.array(test_image)\n",
    "    test_label = np.array(test_label)\n",
    "    test_rev = np.array(test_rev)\n",
    "    return test_image, test_label, test_rev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1行処理済み\n"
     ]
    }
   ],
   "source": [
    "single_revs, _ = build_single_data_cv(text_to_predict)\n",
    "single_data_2vec = single_make_idx_data_cv_2vec(single_revs, U, word_idx_map, max_l, k=300, filter_h=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 1 美容系\n",
      "Text: コスメ の 最 安値 が 見つけ られる アプリメイク 動画 とか 美容 情報 も 載っ てる し 最高 女子 に は ほんとに 助かる 〜\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    images, labels, revs = single_data_2vec\n",
    "    images = Variable(torch.Tensor(images.reshape(1, 1, -1, 300)))\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    print('Prediction:', predicted.item(), label_names[predicted.item()])\n",
    "    print('Text:', revs[0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
