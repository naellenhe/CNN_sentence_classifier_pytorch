{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomly initialized word vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = \"-rand\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import cPickle (python2.7)\n",
    "#http://testpy.hatenablog.com/entry/2017/03/17/000626\n",
    "import _pickle as cPickle\n",
    "\n",
    "import numpy as np\n",
    "from collections import defaultdict, OrderedDict\n",
    "\n",
    "import re\n",
    "import sys\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameters\n",
    "num_epochs = 10\n",
    "num_classes = 3\n",
    "batch_size = 50\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load pickle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the pickle file contains [revs, W, W2, word_idx_map, vocab] # W2 random vectors\n",
    "x = cPickle.load(open(\"tweet.p\",\"rb\"), encoding=\"latin1\") # Add encoding=\"latin1\" because got UnicodeDecodeError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset content\n",
    "Get data from twitter (reference: http://tech.wonderpla.net/entry/2017/10/10/110000)\n",
    "- Label 0\n",
    "    - KEYWORD = \"芸能 OR アニメ OR 漫画 OR ドラマ OR ゲーム\"            #エンタメ系のキーワード\n",
    "    - CLASS_LABEL = \"\\__label__0\"\n",
    "\n",
    "- Label 1\n",
    "    - KEYWORD = \"美容 OR サロン OR エステ OR 化粧 OR 保湿\"            #美容系のキーワード\n",
    "    - CLASS_LABEL = \"\\__label__1\"\n",
    "\n",
    "- Label 2\n",
    "    - KEYWORD = \"日常 OR 料理 OR 家事 OR 収納 OR 家具\"            #暮らし系のキーワード\n",
    "    - CLASS_LABEL = \"\\__label__2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### See data sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_words</th>\n",
       "      <th>split</th>\n",
       "      <th>text</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>じ っ ぷ 。 シゲ 髪形 かわいい ～（*´ ω ｀*） ドラマ 楽しみ ♡</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>某 ゲーム の ロケテ → 夜勤 ループ に 無理 が あり まし た 土日 ちゃんと 寝 ます</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     num_words  split                                              text  y\n",
       "512         13      3           じ っ ぷ 。 シゲ 髪形 かわいい ～（*´ ω ｀*） ドラマ 楽しみ ♡  0\n",
       "75          17      8  某 ゲーム の ロケテ → 夜勤 ループ に 無理 が あり まし た 土日 ちゃんと 寝 ます  0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(x[0])\n",
    "\n",
    "# label 0: Entertainment \n",
    "df[df['y'] == 0].sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_words</th>\n",
       "      <th>split</th>\n",
       "      <th>text</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1192</th>\n",
       "      <td>72</td>\n",
       "      <td>9</td>\n",
       "      <td>下北沢 から 快速 急行 に 乗っ て き た 若者 二 人組 が 「 付き合っ ちゃ いけ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>化粧 し ながら dive みる</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      num_words  split                                               text  y\n",
       "1192         72      9  下北沢 から 快速 急行 に 乗っ て き た 若者 二 人組 が 「 付き合っ ちゃ いけ...  1\n",
       "1296          5      7                                   化粧 し ながら dive みる  1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# label 1 : Beauty\n",
    "df[df['y'] == 1].sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_words</th>\n",
       "      <th>split</th>\n",
       "      <th>text</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1946</th>\n",
       "      <td>31</td>\n",
       "      <td>9</td>\n",
       "      <td>むつみ ちゃん 、 おはよう ありがと ね ️ 睡魔 と の 戦い を 頑張っ て まさかの...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1848</th>\n",
       "      <td>64</td>\n",
       "      <td>9</td>\n",
       "      <td>ジャガイモ が 出 て くる 時点 で 。 明治 期 に 「 強制 的 に 同化 さ せ ら...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      num_words  split                                               text  y\n",
       "1946         31      9  むつみ ちゃん 、 おはよう ありがと ね ️ 睡魔 と の 戦い を 頑張っ て まさかの...  2\n",
       "1848         64      9  ジャガイモ が 出 て くる 時点 で 。 明治 期 に 「 強制 的 に 同化 さ せ ら...  2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# label 2: Life\n",
    "df[df['y'] == 2].sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "revs, W, W2, word_idx_map, vocab = x[0], x[1], x[2], x[3], x[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max sentence length:  100\n"
     ]
    }
   ],
   "source": [
    "# Get the number of the longest sentence\n",
    "max_l = np.max(pd.DataFrame(revs)[\"num_words\"])\n",
    "print(\"max sentence length: \", max_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "revs 2068\n",
      "W 10330\n",
      "W2 10330\n",
      "word_idx_map 10329\n",
      "vocab 10329\n"
     ]
    }
   ],
   "source": [
    "print('revs',len(x[0])) # number of sentence\n",
    "print('W',len(x[1])) # W are pretrained word vectors (unknown words are randomly initialized)\n",
    "print('W2', len(x[2])) # W2 are randomly initialized vectors\n",
    "print('word_idx_map', len(x[3]))\n",
    "print('vocab', len(x[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'y': 0,\n",
       " 'text': 'え 、 サラリーマン し ながら 、 商業 漫画 の 仕事 を し て 、 ツイッター に 定期 的 に 漫画 を あげ て 、 さらに コミケ の 原稿 を 作る ！ ？',\n",
       " 'num_words': 32,\n",
       " 'split': 1}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "revs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using: random vectors\n"
     ]
    }
   ],
   "source": [
    "if word_vectors == \"-rand\":\n",
    "    print(\"using: random vectors\")\n",
    "    U = W2\n",
    "elif word_vectors == \"-word2vec\":\n",
    "    print(\"using: word2vec vectors\")\n",
    "    U = W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10330, 300)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make dataset (check original code)\n",
    "make each sentence an word index map using word_idx_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_idx_from_sent(sent, word_idx_map, max_l=51, k=300, filter_h=5):\n",
    "    \"\"\"\n",
    "    Transforms sentence into a list of indices. Pad with zeroes.\n",
    "    \"\"\"\n",
    "    x = []\n",
    "    pad = filter_h - 1\n",
    "    for i in range(pad):\n",
    "        x.append(0)\n",
    "    words = sent.split()\n",
    "    for word in words:\n",
    "        if word in word_idx_map:\n",
    "            x.append(word_idx_map[word])\n",
    "    while len(x) < max_l + 2*pad:\n",
    "        x.append(0)\n",
    "    return x\n",
    "\n",
    "def make_idx_data_cv(revs, word_idx_map, cv, max_l=51, k=300, filter_h=5):\n",
    "    \"\"\"\n",
    "    Transforms sentences into a 2-d matrix.\n",
    "    \"\"\"\n",
    "    train, test = [], []\n",
    "    for rev in revs:\n",
    "        sent = get_idx_from_sent(rev[\"text\"], word_idx_map, max_l, k, filter_h) # one sentence\n",
    "        sent.append(rev[\"y\"])\n",
    "        if rev[\"split\"]== cv:  # \"split\" is random number of np.random.randint(0,10)\n",
    "            test.append(sent)        \n",
    "        else:  \n",
    "            train.append(sent)   \n",
    "    train = np.array(train, dtype=\"int\")\n",
    "    test = np.array(test, dtype=\"int\")\n",
    "    return [train, test] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "datasets = make_idx_data_cv(revs, word_idx_map, i, max_l, k=300, filter_h=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example of sentence to word index map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'y': 0,\n",
       " 'text': 'え 、 サラリーマン し ながら 、 商業 漫画 の 仕事 を し て 、 ツイッター に 定期 的 に 漫画 を あげ て 、 さらに コミケ の 原稿 を 作る ！ ？',\n",
       " 'num_words': 32,\n",
       " 'split': 1}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "revs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,   32, 4148,   26,   14,   21, 4148,   23,\n",
       "       4138,   25, 4153,   29,   14,    4, 4148,   30,    9,   31,   22,\n",
       "          9, 4138,   29, 4152,    4, 4148,   27,   24,   25,   28,   29,\n",
       "       4150, 4151, 4154,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(datasets[0][0]))\n",
    "datasets[0][1] # sentence => word index map padding with zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data size: (1853, 109)\n",
      "test data size: (215, 109)\n"
     ]
    }
   ],
   "source": [
    "print('train data size:', datasets[0].shape)\n",
    "print('test data size:', datasets[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make dataset (using vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_idx_from_sent_2vec(sent, U, word_idx_map, max_l=51, k=300, filter_h=5):\n",
    "    \"\"\"\n",
    "    Transforms sentence into a list of indices. Pad with zeroes.\n",
    "    \"\"\"\n",
    "    pad = filter_h - 1\n",
    "    x = np.zeros((max_l+2*pad, k))\n",
    "\n",
    "    words = sent.split()\n",
    "    # starting after padding\n",
    "    i = pad\n",
    "    for word in words:\n",
    "        if word in word_idx_map:\n",
    "            x[i] = U[word_idx_map[word]]\n",
    "            i += 1\n",
    "    return x\n",
    "\n",
    "def make_idx_data_cv_2vec(revs, U, word_idx_map, cv, max_l=51, k=300, filter_h=5):\n",
    "    \"\"\"\n",
    "    Transforms sentences into a 2-d matrix.\n",
    "    \"\"\"\n",
    "    train_image, train_label = [], []\n",
    "    test_image, test_label = [], []\n",
    "    test_rev = []\n",
    "    for rev in revs:\n",
    "        sent = get_idx_from_sent_2vec(rev[\"text\"], U, word_idx_map, max_l, k, filter_h) # one sentence\n",
    "        if rev[\"split\"] == cv:  # \"split\" is random number of np.random.randint(0,10)\n",
    "            test_image.append(sent) \n",
    "            test_label.append(rev[\"y\"])\n",
    "            test_rev.append(rev)\n",
    "        else:  \n",
    "            train_image.append(sent)\n",
    "            train_label.append(rev[\"y\"])\n",
    "    train_image = np.array(train_image)\n",
    "    train_label = np.array(train_label)\n",
    "    test_image = np.array(test_image)\n",
    "    test_label = np.array(test_label)\n",
    "    test_rev = np.array(test_rev)\n",
    "    return (train_image, train_label), (test_image, test_label, test_rev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence length(before) 108\n"
     ]
    }
   ],
   "source": [
    "t = \"effective but too tepid biopic\"\n",
    "t_sent_2vec = get_idx_from_sent_2vec(t, U, word_idx_map, max_l, k=300, filter_h=5)\n",
    "print(\"sentence length(before)\", len(t_sent_2vec)) # max_l(51)+2*pad(filter_h-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_sent_2vec[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "datasets_2vec = make_idx_data_cv_2vec(revs, U, word_idx_map, i, max_l, k=300, filter_h=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_image, train_label), (test_image, test_label, test_rev) = datasets_2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example of sentence to vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'y': 0,\n",
       " 'text': 'え 、 サラリーマン し ながら 、 商業 漫画 の 仕事 を し て 、 ツイッター に 定期 的 に 漫画 を あげ て 、 さらに コミケ の 原稿 を 作る ！ ？',\n",
       " 'num_words': 32,\n",
       " 'split': 1}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "revs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(108, 300)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.020504</td>\n",
       "      <td>-0.046327</td>\n",
       "      <td>0.064646</td>\n",
       "      <td>0.075139</td>\n",
       "      <td>0.019245</td>\n",
       "      <td>0.088999</td>\n",
       "      <td>-0.013704</td>\n",
       "      <td>-0.062541</td>\n",
       "      <td>0.093266</td>\n",
       "      <td>-0.026601</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046905</td>\n",
       "      <td>-0.056365</td>\n",
       "      <td>0.054788</td>\n",
       "      <td>-0.048016</td>\n",
       "      <td>-0.088997</td>\n",
       "      <td>-0.077678</td>\n",
       "      <td>0.090646</td>\n",
       "      <td>0.066018</td>\n",
       "      <td>-0.088081</td>\n",
       "      <td>0.025803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.063965</td>\n",
       "      <td>-0.051744</td>\n",
       "      <td>-0.077990</td>\n",
       "      <td>-0.087165</td>\n",
       "      <td>-0.044545</td>\n",
       "      <td>-0.034732</td>\n",
       "      <td>0.006807</td>\n",
       "      <td>0.010893</td>\n",
       "      <td>0.059861</td>\n",
       "      <td>0.011902</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056590</td>\n",
       "      <td>0.028966</td>\n",
       "      <td>-0.076021</td>\n",
       "      <td>-0.073102</td>\n",
       "      <td>0.040097</td>\n",
       "      <td>-0.092823</td>\n",
       "      <td>0.067505</td>\n",
       "      <td>0.075281</td>\n",
       "      <td>0.089812</td>\n",
       "      <td>0.063847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.029120</td>\n",
       "      <td>0.034866</td>\n",
       "      <td>-0.084759</td>\n",
       "      <td>-0.087468</td>\n",
       "      <td>0.054134</td>\n",
       "      <td>0.094201</td>\n",
       "      <td>-0.035864</td>\n",
       "      <td>0.092331</td>\n",
       "      <td>0.079579</td>\n",
       "      <td>-0.039939</td>\n",
       "      <td>...</td>\n",
       "      <td>0.080512</td>\n",
       "      <td>0.019726</td>\n",
       "      <td>0.024677</td>\n",
       "      <td>0.055511</td>\n",
       "      <td>0.010866</td>\n",
       "      <td>-0.076733</td>\n",
       "      <td>-0.022563</td>\n",
       "      <td>0.054954</td>\n",
       "      <td>0.078676</td>\n",
       "      <td>-0.021445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.060643</td>\n",
       "      <td>0.083628</td>\n",
       "      <td>0.075804</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>-0.054350</td>\n",
       "      <td>-0.061242</td>\n",
       "      <td>0.061567</td>\n",
       "      <td>-0.005142</td>\n",
       "      <td>0.032233</td>\n",
       "      <td>-0.074817</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022148</td>\n",
       "      <td>-0.043589</td>\n",
       "      <td>0.027836</td>\n",
       "      <td>-0.047874</td>\n",
       "      <td>0.073111</td>\n",
       "      <td>-0.003108</td>\n",
       "      <td>-0.082038</td>\n",
       "      <td>0.091354</td>\n",
       "      <td>0.055975</td>\n",
       "      <td>0.057465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.081688</td>\n",
       "      <td>-0.011092</td>\n",
       "      <td>-0.052978</td>\n",
       "      <td>0.073950</td>\n",
       "      <td>0.025340</td>\n",
       "      <td>0.007605</td>\n",
       "      <td>0.017981</td>\n",
       "      <td>0.095140</td>\n",
       "      <td>-0.052617</td>\n",
       "      <td>-0.064261</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.055777</td>\n",
       "      <td>-0.088397</td>\n",
       "      <td>-0.004968</td>\n",
       "      <td>-0.071379</td>\n",
       "      <td>0.011787</td>\n",
       "      <td>0.063268</td>\n",
       "      <td>-0.076265</td>\n",
       "      <td>-0.021418</td>\n",
       "      <td>-0.043032</td>\n",
       "      <td>0.052886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.063965</td>\n",
       "      <td>-0.051744</td>\n",
       "      <td>-0.077990</td>\n",
       "      <td>-0.087165</td>\n",
       "      <td>-0.044545</td>\n",
       "      <td>-0.034732</td>\n",
       "      <td>0.006807</td>\n",
       "      <td>0.010893</td>\n",
       "      <td>0.059861</td>\n",
       "      <td>0.011902</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056590</td>\n",
       "      <td>0.028966</td>\n",
       "      <td>-0.076021</td>\n",
       "      <td>-0.073102</td>\n",
       "      <td>0.040097</td>\n",
       "      <td>-0.092823</td>\n",
       "      <td>0.067505</td>\n",
       "      <td>0.075281</td>\n",
       "      <td>0.089812</td>\n",
       "      <td>0.063847</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4 -0.020504 -0.046327  0.064646  0.075139  0.019245  0.088999 -0.013704   \n",
       "5 -0.063965 -0.051744 -0.077990 -0.087165 -0.044545 -0.034732  0.006807   \n",
       "6 -0.029120  0.034866 -0.084759 -0.087468  0.054134  0.094201 -0.035864   \n",
       "7  0.060643  0.083628  0.075804  0.000008 -0.054350 -0.061242  0.061567   \n",
       "8  0.081688 -0.011092 -0.052978  0.073950  0.025340  0.007605  0.017981   \n",
       "9 -0.063965 -0.051744 -0.077990 -0.087165 -0.044545 -0.034732  0.006807   \n",
       "\n",
       "        7         8         9      ...          290       291       292  \\\n",
       "0  0.000000  0.000000  0.000000    ...     0.000000  0.000000  0.000000   \n",
       "1  0.000000  0.000000  0.000000    ...     0.000000  0.000000  0.000000   \n",
       "2  0.000000  0.000000  0.000000    ...     0.000000  0.000000  0.000000   \n",
       "3  0.000000  0.000000  0.000000    ...     0.000000  0.000000  0.000000   \n",
       "4 -0.062541  0.093266 -0.026601    ...    -0.046905 -0.056365  0.054788   \n",
       "5  0.010893  0.059861  0.011902    ...     0.056590  0.028966 -0.076021   \n",
       "6  0.092331  0.079579 -0.039939    ...     0.080512  0.019726  0.024677   \n",
       "7 -0.005142  0.032233 -0.074817    ...    -0.022148 -0.043589  0.027836   \n",
       "8  0.095140 -0.052617 -0.064261    ...    -0.055777 -0.088397 -0.004968   \n",
       "9  0.010893  0.059861  0.011902    ...     0.056590  0.028966 -0.076021   \n",
       "\n",
       "        293       294       295       296       297       298       299  \n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "2  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "4 -0.048016 -0.088997 -0.077678  0.090646  0.066018 -0.088081  0.025803  \n",
       "5 -0.073102  0.040097 -0.092823  0.067505  0.075281  0.089812  0.063847  \n",
       "6  0.055511  0.010866 -0.076733 -0.022563  0.054954  0.078676 -0.021445  \n",
       "7 -0.047874  0.073111 -0.003108 -0.082038  0.091354  0.055975  0.057465  \n",
       "8 -0.071379  0.011787  0.063268 -0.076265 -0.021418 -0.043032  0.052886  \n",
       "9 -0.073102  0.040097 -0.092823  0.067505  0.075281  0.089812  0.063847  \n",
       "\n",
       "[10 rows x 300 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p2 = pd.DataFrame(train_image[1])\n",
    "print(p2.shape)\n",
    "p2.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make dataset iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1853"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_image = torch.FloatTensor(train_image).reshape(-1, 1, max_l + 2 * (5-1), 300)\n",
    "t_label = torch.LongTensor(train_label)\n",
    "train_dataset = list(zip(t_image, t_label))\n",
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images: torch.Size([50, 1, 108, 300]) \n",
      "labels: torch.Size([50])\n",
      "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])\n",
      "tensor(0)\n"
     ]
    }
   ],
   "source": [
    "for images, labels in train_loader:\n",
    "    print('images:', images.shape, '\\nlabels:', labels.shape)\n",
    "    print(images[1][0])\n",
    "    print(labels[1])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "215"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_image = torch.FloatTensor(test_image).reshape(-1, 1, max_l + 2 * (5-1), 300)\n",
    "c_label = torch.LongTensor(test_label)\n",
    "test_dataset = list(zip(c_image, c_label, test_rev))\n",
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loader\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model parameters (original code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_hs=[3, 4, 5]\n",
    "hidden_units=[100, num_classes]\n",
    "batch_size=50\n",
    "img_w=300\n",
    "img_h = len(datasets[0][0])-1  # sentence length (subtracted 1 for y label)\n",
    "\n",
    "filter_w = img_w    \n",
    "feature_maps = hidden_units[0]\n",
    "filter_shapes = []\n",
    "pool_sizes = []\n",
    "for filter_h in filter_hs:\n",
    "    filter_shapes.append((feature_maps, 1, filter_h, filter_w))\n",
    "    pool_sizes.append((img_h-filter_h+1, img_w-filter_w+1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(100, 1, 3, 300), (100, 1, 4, 300), (100, 1, 5, 300)]\n",
      "one batch train (50, 1, 108, 300)\n",
      "[(106, 1), (105, 1), (104, 1)]\n"
     ]
    }
   ],
   "source": [
    "print(filter_shapes)\n",
    "image_shape = (batch_size, 1, img_h, img_w)\n",
    "print('one batch train', image_shape)\n",
    "print(pool_sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding & Stride\n",
    "- Output size\n",
    "\n",
    "    $ O = \\frac {W-K+2P}{S} + 1 $\n",
    "    - O: output h/w\n",
    "    - W: input h/w\n",
    "    - K: filter size(kernel size)\n",
    "    - P: padding\n",
    "        - $  P = \\frac {K-1}{2} $\n",
    "    - S: stride"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network\n",
    "\n",
    "- Theano:\n",
    "    - conv_layer: LeNetConvPoolLayer\n",
    "    - classifier: MLPDropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model:\n",
    "\n",
    "\n",
    "```\n",
    "Network\n",
    "Input ->\n",
    "Conv -> ReLU -> MaxPool |\n",
    "Conv -> ReLU -> MaxPool | -> concat\n",
    "Conv -> ReLU -> MaxPool |\n",
    "Fully Connected Layer(Logits -> Softmax) -> Labels\n",
    "```\n",
    "\n",
    "```\n",
    "Convolutional layer formula:\n",
    "- Filter 1(Kernel) size K = 3 => (3 x 300)\n",
    "- P(same padding) P = (3-1)/2=1\n",
    "- S(stride) S = 1\n",
    "- in_channels = 1\n",
    "- out_channels (int) – Number of channels produced by the convolution = 100\n",
    "Pooling layer formula:\n",
    "- K\n",
    "```\n",
    "\n",
    "```\n",
    "*Filter dimensions*:\n",
    "Conv1 (W_conv, (100, 1, 3, 300))\n",
    "Conv1 (b_conv, (100,))\n",
    "Conv2 (W_conv, (100, 1, 4, 300))\n",
    "Conv2 (b_conv, (100,))\n",
    "Conv3 (W_conv, (100, 1, 5, 300))\n",
    "Conv3 (b_conv, (100,))\n",
    "\n",
    "*Layer input dimensions*:\n",
    "- Input image(64, 300) \n",
    "\n",
    "----------------------------------------------------------------------\n",
    "|  Conv1  (100, 3, 300)   Conv2  (100, 4, 300)   Conv3  (100, 5, 300) |\n",
    "|  MaxPool (100, 62, 1)   MaxPool (100, 61, 1)   MaxPool (100, 60, 1) |\n",
    "-----------------------------Concat ----------------------------------\n",
    "\n",
    "- Concatenated (100, 1, 1) + (100, 1, 1) + (100, 1, 1) => (300, 1, 1) \n",
    "\n",
    "- Fully Connected Layer(Logits (100, 1) -> Logits (2, 1) -> Softmax) -> Labels\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvPoolLayer(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(ConvPoolLayer, self).__init__()\n",
    "\n",
    "        # Layer 1: conv - relu - conv- relu - pool\n",
    "        self.ngram1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=feature_maps, kernel_size=(filter_hs[0], img_w), stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=pool_sizes[0], stride=None))\n",
    "        self.ngram2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=feature_maps, kernel_size=(filter_hs[1], img_w), stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=pool_sizes[1], stride=None))\n",
    "        self.ngram3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=feature_maps, kernel_size=(filter_hs[2], img_w), stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=pool_sizes[2], stride=None))\n",
    "        \n",
    "        # Fully Connected 1 (readout)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(feature_maps * 3, hidden_units[0]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_units[0], num_classes))\n",
    "\n",
    "        # Initialize all parameters using kaiming normalization\n",
    "        self.init_weights_kaiming()\n",
    "    \n",
    "    def init_weights_kaiming(self):\n",
    "        #Use kaiming normalization to initialize the parameters\n",
    "        for layer in [self.ngram1, self.ngram2, self.ngram3, self.fc]:\n",
    "            for m in layer:\n",
    "                if type(m) == nn.Conv2d or type(m) == nn.Linear:\n",
    "                    m.weight = nn.init.kaiming_normal_(m.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        out1 = self.ngram1(x)\n",
    "        out2 = self.ngram2(x)\n",
    "        out3 = self.ngram3(x)\n",
    "        out = torch.cat((out1, out2, out3), 1)\n",
    "        \n",
    "        out = out.view(out.size(0), -1)\n",
    "    \n",
    "        # Linear function (readout)\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvPoolLayer(\n",
      "  (ngram1): Sequential(\n",
      "    (0): Conv2d(1, 100, kernel_size=(3, 300), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=(106, 1), stride=(106, 1), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (ngram2): Sequential(\n",
      "    (0): Conv2d(1, 100, kernel_size=(4, 300), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=(105, 1), stride=(105, 1), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (ngram3): Sequential(\n",
      "    (0): Conv2d(1, 100, kernel_size=(5, 300), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=(104, 1), stride=(104, 1), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=300, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=100, out_features=3, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = ConvPoolLayer(num_classes)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1, 3, 300])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 4, 300])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 5, 300])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 300])\n",
      "torch.Size([100])\n",
      "torch.Size([3, 100])\n",
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "for p in model.parameters():\n",
    "    print(p.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 50. Loss: 0.3596552610397339.\n",
      "Iteration: 100. Loss: 0.0326966866850853.\n",
      "Iteration: 150. Loss: 0.011703996919095516.\n",
      "Iteration: 200. Loss: 0.08660157024860382.\n",
      "Iteration: 250. Loss: 0.004488104488700628.\n",
      "Iteration: 300. Loss: 0.005744218826293945.\n",
      "Iteration: 350. Loss: 0.15957088768482208.\n"
     ]
    }
   ],
   "source": [
    "avg_losses = list()\n",
    "iter = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        total_loss = list()\n",
    "        \n",
    "        # Load images as Variable\n",
    "        images = Variable(images) # Now we dont need to resize like images.view(xx)\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        # Clear gradients w.r.t parameters\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass to get output/logits\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # Calculate Loss: Softmax --> cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Getting gradients w.r.t paramters\n",
    "        loss.backward()\n",
    "        \n",
    "        # Track loss to plot the result\n",
    "        total_loss.append(loss.item())\n",
    "        \n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        iter += 1\n",
    "        \n",
    "        if iter % 50 == 0:\n",
    "            # Print Loss\n",
    "            print('Iteration: {}. Loss: {}.'.format(iter, loss.item()))\n",
    "            avg_loss = np.divide(np.sum(total_loss), len(total_loss))\n",
    "            avg_losses.append(avg_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the loss vs iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_axis = np.arange(len(avg_losses))\n",
    "plt.plot(x_axis, avg_losses, label='train')\n",
    "plt.xlabel('iterations (x100)')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model with test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 250 test images: 99.53488372093024 %\n"
     ]
    }
   ],
   "source": [
    "n_test = len(test_loader) * batch_size\n",
    "wrong_predictions = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels, revs in test_loader:\n",
    "        images = Variable(images)\n",
    "        labels = Variable(labels)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        # See which are error predictions\n",
    "        result = (predicted == labels)\n",
    "        err_imgs = images[result == 0] # 0 means wrong prediction\n",
    "        err_labels = labels[result == 0]\n",
    "        err_p = outputs[result == 0]\n",
    "        err_outputs = predicted[result == 0]\n",
    "        err_texts = np.array(revs['text'])[np.array((result == 0).numpy(), dtype=np.bool)]\n",
    "        for img, lbl, p, out, text in zip(err_imgs, err_labels, err_p, err_outputs, err_texts):\n",
    "            wrong_predictions.append((img, lbl, p, out, text))\n",
    "     \n",
    "    print('Test Accuracy of the model on the {} test images: {} %'.format(n_test, 100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True label:  0 \t エンタメ系\n",
      "Predition:  2 \t 暮らし系\n",
      "Possibility: tensor([ 3.0471, -5.5162,  4.4039])\n",
      "ガルパ に 登場 する キャラクター たち の 日常 を 描い た ４ コマ 漫画 、 『 もっと ！ ガルパライフ 』 （# ガルパラ ） を 更新 し まし た 第 94 話 「 元気 の 出 ない とき に 」 今 まで の お話 は こちら → # バンドリ # ガ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "label_names = ['エンタメ系', '美容系', '暮らし系']\n",
    "# unpack img, lbl, out, text\n",
    "for img, lbl, p, out, text in wrong_predictions:\n",
    "    print('True label: ', lbl.item(), '\\t', label_names[lbl.item()])\n",
    "    print('Predition: ', out.item(), '\\t', label_names[out.item()])\n",
    "    print('Possibility:', p)\n",
    "    print(text, '\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model with train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 1900 train images: 99.7301672962763 %\n"
     ]
    }
   ],
   "source": [
    "n_train = len(train_loader) * batch_size\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in train_loader:\n",
    "        images = Variable(images)\n",
    "        labels = Variable(labels)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "    print('Test Accuracy of the model on the {} train images: {} %'.format(n_train, 100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict single inputted text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input the text to predict (change the text below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_to_predict = \"お風呂掃除でいつも落ちなかった溝にある黒カビが家事えもんの塩素系漂白剤＋片栗粉でほぼ真っ白になって感動 家事えもんのテクニック凄い～！\"\n",
    "\n",
    "text_to_predict = \"コスメの最安値が見つけられるアプリ💄💋メイク動画とか 美容情報も載ってるし最高😆🙌📲http://goo.gl/K5Fmea 女子にはほんとに助かる〜💗\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data...\n",
      "data loaded!\n",
      "number of sentences: 2068\n",
      "vocab size: 10329\n",
      "max sentence length: 100\n",
      "loading word2vec vectors...\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "from process_data import build_single_data_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_make_idx_data_cv_2vec(revs, U, word_idx_map, max_l=51, k=300, filter_h=5):\n",
    "    \"\"\"\n",
    "    Transforms sentences into a 2-d matrix.\n",
    "    \"\"\"\n",
    "    test_image, test_label = [], []\n",
    "    test_rev = []\n",
    "    for rev in revs:\n",
    "        sent = get_idx_from_sent_2vec(rev[\"text\"], U, word_idx_map, max_l, k, filter_h) # one sentence\n",
    "        test_image.append(sent) \n",
    "        test_label.append(rev[\"y\"])\n",
    "        test_rev.append(rev)\n",
    "\n",
    "    test_image = np.array(test_image)\n",
    "    test_label = np.array(test_label)\n",
    "    test_rev = np.array(test_rev)\n",
    "    return test_image, test_label, test_rev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1行処理済み\n"
     ]
    }
   ],
   "source": [
    "single_revs, _ = build_single_data_cv(text_to_predict)\n",
    "single_data_2vec = single_make_idx_data_cv_2vec(single_revs, U, word_idx_map, max_l, k=300, filter_h=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 1 美容系\n",
      "Text: コスメ の 最 安値 が 見つけ られる アプリメイク 動画 とか 美容 情報 も 載っ てる し 最高 女子 に は ほんとに 助かる 〜\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    images, labels, revs = single_data_2vec\n",
    "    images = Variable(torch.Tensor(images.reshape(1, 1, -1, 300)))\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    print('Prediction:', predicted.item(), label_names[predicted.item()])\n",
    "    print('Text:', revs[0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
