{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import cPickle (python2.7)\n",
    "#http://testpy.hatenablog.com/entry/2017/03/17/000626\n",
    "import _pickle as cPickle\n",
    "\n",
    "import numpy as np\n",
    "from collections import defaultdict, OrderedDict\n",
    "\n",
    "import re\n",
    "import warnings\n",
    "import sys\n",
    "import time\n",
    "warnings.filterwarnings(\"ignore\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameters\n",
    "num_epochs = 50\n",
    "num_classes = 2\n",
    "batch_size = 50\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load pickle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the pickle file contains [revs, W, W2, word_idx_map, vocab]\n",
    "x = cPickle.load(open(\"mr.p\",\"rb\"), encoding=\"latin1\") # Add encoding=\"latin1\" because got UnicodeDecodeError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "revs, W, W2, word_idx_map, vocab = x[0], x[1], x[2], x[3], x[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max sentence length:  56\n"
     ]
    }
   ],
   "source": [
    "max_l = np.max(pd.DataFrame(revs)[\"num_words\"])\n",
    "print(\"max sentence length: \", max_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "revs 10662\n",
      "W 18766\n",
      "W2 18766\n",
      "word_idx_map 18765\n",
      "vocab 18765\n"
     ]
    }
   ],
   "source": [
    "print('revs',len(x[0])) # number of sentence\n",
    "print('W', len(x[1]))\n",
    "print('W2', len(x[2])) # W2 are randomly initialized vectors\n",
    "print('word_idx_map', len(x[3]))\n",
    "print('vocab', len(x[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'y': 1, 'text': 'effective but too tepid biopic', 'split': 7, 'num_words': 5}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "revs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12002"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_idx_map['good'] # word and its index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "393.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab['good'] # word and its count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model architecture: CNN-non-static\n",
      "using: word2vec vectors\n"
     ]
    }
   ],
   "source": [
    "# mode= sys.argv[1]\n",
    "# word_vectors = sys.argv[2]\n",
    "\n",
    "mode = \"-nonstatic\"\n",
    "word_vectors = \"-word2vec\"\n",
    "\n",
    "if mode==\"-nonstatic\":\n",
    "    print(\"model architecture: CNN-non-static\")\n",
    "    non_static=True\n",
    "elif mode==\"-static\":\n",
    "    print(\"model architecture: CNN-static\")\n",
    "    non_static=False\n",
    "\n",
    "#execfile(\"conv_net_classes.py\")  \n",
    "\n",
    "if word_vectors==\"-rand\":\n",
    "    print(\"using: random vectors\")\n",
    "    U = W2\n",
    "elif word_vectors==\"-word2vec\":\n",
    "    print(\"using: word2vec vectors\")\n",
    "    U = W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18766, 300)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make dataset (check original code)\n",
    "make each sentence an word index map using word_idx_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_idx_from_sent(sent, word_idx_map, max_l=51, k=300, filter_h=5):\n",
    "    \"\"\"\n",
    "    Transforms sentence into a list of indices. Pad with zeroes.\n",
    "    \"\"\"\n",
    "    x = []\n",
    "    pad = filter_h - 1\n",
    "    for i in range(pad):\n",
    "        x.append(0)\n",
    "    words = sent.split()\n",
    "    for word in words:\n",
    "        if word in word_idx_map:\n",
    "            x.append(word_idx_map[word])\n",
    "    while len(x) < max_l+2*pad:\n",
    "        x.append(0)\n",
    "    return x\n",
    "\n",
    "def make_idx_data_cv(revs, word_idx_map, cv, max_l=51, k=300, filter_h=5):\n",
    "    \"\"\"\n",
    "    Transforms sentences into a 2-d matrix.\n",
    "    \"\"\"\n",
    "    train, test = [], []\n",
    "    for rev in revs:\n",
    "        sent = get_idx_from_sent(rev[\"text\"], word_idx_map, max_l, k, filter_h) # one sentence\n",
    "        sent.append(rev[\"y\"])\n",
    "        if rev[\"split\"]==cv:  # \"split\" is random number of np.random.randint(0,10)\n",
    "            test.append(sent)        \n",
    "        else:  \n",
    "            train.append(sent)   \n",
    "    train = np.array(train, dtype=\"int\")\n",
    "    test = np.array(test, dtype=\"int\")\n",
    "    return [train, test] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence length(before) 64\n",
      "sentence length(after added y label) 65\n"
     ]
    }
   ],
   "source": [
    "t = \"effective but too tepid biopic\"\n",
    "t_sent = get_idx_from_sent(t, word_idx_map, max_l, k=300, filter_h=5)\n",
    "print(\"sentence length(before)\", len(t_sent)) # max_l(51)+2*pad(filter_h-1)\n",
    "t_sent.append(1) #sent.append(rev[\"y\"])\n",
    "print(\"sentence length(after added y label)\", len(t_sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "datasets = make_idx_data_cv(revs, word_idx_map, i, max_l=56, k=300, filter_h=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example of sentence to word index map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'y': 1, 'text': 'effective but too tepid biopic', 'split': 7, 'num_words': 5}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "revs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([    0,     0,     0,     0,   271, 13936, 14497, 17972,  5678,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     1])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(datasets[0][0]))\n",
    "datasets[0][2] # sentence => word index map padding with zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data size: (9572, 65)\n",
      "test data size: (1090, 65)\n"
     ]
    }
   ],
   "source": [
    "print('train data size:', datasets[0].shape)\n",
    "print('test data size:', datasets[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make dataset (using vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_idx_from_sent_2vec(sent, U, word_idx_map, max_l=51, k=300, filter_h=5):\n",
    "    \"\"\"\n",
    "    Transforms sentence into a list of indices. Pad with zeroes.\n",
    "    \"\"\"\n",
    "    pad = filter_h - 1\n",
    "    x = np.zeros((max_l+2*pad, k))\n",
    "\n",
    "    words = sent.split()\n",
    "    # starting after padding\n",
    "    i = pad\n",
    "    for word in words:\n",
    "        if word in word_idx_map:\n",
    "            x[i] = U[word_idx_map[word]]\n",
    "            i += 1\n",
    "    return x\n",
    "\n",
    "def make_idx_data_cv_2vec(revs, U, word_idx_map, cv, max_l=51, k=300, filter_h=5):\n",
    "    \"\"\"\n",
    "    Transforms sentences into a 2-d matrix.\n",
    "    \"\"\"\n",
    "    train_image, train_label = [], []\n",
    "    test_image, test_label = [], []\n",
    "    for rev in revs:\n",
    "        sent = get_idx_from_sent_2vec(rev[\"text\"], U, word_idx_map, max_l, k, filter_h) # one sentence\n",
    "        if rev[\"split\"]==cv:  # \"split\" is random number of np.random.randint(0,10)\n",
    "            test_image.append(sent) \n",
    "            test_label.append(rev[\"y\"])\n",
    "        else:  \n",
    "            train_image.append(sent)\n",
    "            train_label.append(rev[\"y\"])\n",
    "    train_image = np.array(train_image)\n",
    "    train_label = np.array(train_label)\n",
    "    test_image = np.array(test_image)\n",
    "    test_label = np.array(test_label)\n",
    "    return (train_image, train_label), (test_image, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence length(before) 64\n"
     ]
    }
   ],
   "source": [
    "t = \"effective but too tepid biopic\"\n",
    "t_sent_2vec = get_idx_from_sent_2vec(t, W, word_idx_map, max_l, k=300, filter_h=5)\n",
    "print(\"sentence length(before)\", len(t_sent_2vec)) # max_l(51)+2*pad(filter_h-1)\n",
    "# t_sent_2vec.append(1) #sent.append(rev[\"y\"])\n",
    "# print(\"sentence length(after added y label)\", len(t_sent_2vec ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_sent_2vec[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "datasets_2vec = make_idx_data_cv_2vec(revs, W, word_idx_map, i, max_l=56, k=300, filter_h=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_image, train_label), (test_image, test_label) = datasets_2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example of sentence to vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'y': 1, 'text': 'effective but too tepid biopic', 'split': 7, 'num_words': 5}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "revs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 300)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.028931</td>\n",
       "      <td>-0.034912</td>\n",
       "      <td>-0.125977</td>\n",
       "      <td>0.078613</td>\n",
       "      <td>-0.182617</td>\n",
       "      <td>0.080078</td>\n",
       "      <td>0.143555</td>\n",
       "      <td>-0.005280</td>\n",
       "      <td>0.308594</td>\n",
       "      <td>0.070801</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.177734</td>\n",
       "      <td>-0.082520</td>\n",
       "      <td>0.108398</td>\n",
       "      <td>0.208008</td>\n",
       "      <td>-0.145508</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>-0.070801</td>\n",
       "      <td>-0.003143</td>\n",
       "      <td>-0.104980</td>\n",
       "      <td>0.339844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.047607</td>\n",
       "      <td>0.081543</td>\n",
       "      <td>0.045654</td>\n",
       "      <td>0.091797</td>\n",
       "      <td>-0.014709</td>\n",
       "      <td>0.111328</td>\n",
       "      <td>0.065430</td>\n",
       "      <td>-0.096680</td>\n",
       "      <td>0.138672</td>\n",
       "      <td>0.143555</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.114746</td>\n",
       "      <td>0.041504</td>\n",
       "      <td>-0.041992</td>\n",
       "      <td>0.092285</td>\n",
       "      <td>-0.000713</td>\n",
       "      <td>0.075195</td>\n",
       "      <td>0.049316</td>\n",
       "      <td>-0.055664</td>\n",
       "      <td>0.104980</td>\n",
       "      <td>-0.108398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.129883</td>\n",
       "      <td>0.131836</td>\n",
       "      <td>-0.032959</td>\n",
       "      <td>0.148438</td>\n",
       "      <td>-0.138672</td>\n",
       "      <td>0.141602</td>\n",
       "      <td>0.192383</td>\n",
       "      <td>-0.053955</td>\n",
       "      <td>0.110352</td>\n",
       "      <td>0.068848</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006165</td>\n",
       "      <td>0.079102</td>\n",
       "      <td>-0.070312</td>\n",
       "      <td>0.025757</td>\n",
       "      <td>-0.137695</td>\n",
       "      <td>-0.045166</td>\n",
       "      <td>0.070801</td>\n",
       "      <td>-0.065918</td>\n",
       "      <td>0.032959</td>\n",
       "      <td>0.208984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.248047</td>\n",
       "      <td>0.236328</td>\n",
       "      <td>0.107422</td>\n",
       "      <td>0.217773</td>\n",
       "      <td>-0.257812</td>\n",
       "      <td>-0.014771</td>\n",
       "      <td>-0.118164</td>\n",
       "      <td>-0.064941</td>\n",
       "      <td>0.076172</td>\n",
       "      <td>0.291016</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057861</td>\n",
       "      <td>-0.306641</td>\n",
       "      <td>-0.055176</td>\n",
       "      <td>0.128906</td>\n",
       "      <td>0.067383</td>\n",
       "      <td>-0.069336</td>\n",
       "      <td>-0.001877</td>\n",
       "      <td>0.133789</td>\n",
       "      <td>0.057617</td>\n",
       "      <td>0.175781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.285156</td>\n",
       "      <td>-0.195312</td>\n",
       "      <td>0.109863</td>\n",
       "      <td>0.237305</td>\n",
       "      <td>0.322266</td>\n",
       "      <td>0.363281</td>\n",
       "      <td>0.015869</td>\n",
       "      <td>-0.137695</td>\n",
       "      <td>0.017334</td>\n",
       "      <td>-0.427734</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.076660</td>\n",
       "      <td>0.111328</td>\n",
       "      <td>-0.365234</td>\n",
       "      <td>0.025757</td>\n",
       "      <td>0.011292</td>\n",
       "      <td>0.024780</td>\n",
       "      <td>0.001472</td>\n",
       "      <td>0.109863</td>\n",
       "      <td>-0.053467</td>\n",
       "      <td>0.296875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4 -0.028931 -0.034912 -0.125977  0.078613 -0.182617  0.080078  0.143555   \n",
       "5 -0.047607  0.081543  0.045654  0.091797 -0.014709  0.111328  0.065430   \n",
       "6  0.129883  0.131836 -0.032959  0.148438 -0.138672  0.141602  0.192383   \n",
       "7  0.248047  0.236328  0.107422  0.217773 -0.257812 -0.014771 -0.118164   \n",
       "8  0.285156 -0.195312  0.109863  0.237305  0.322266  0.363281  0.015869   \n",
       "9  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "        7         8         9      ...          290       291       292  \\\n",
       "0  0.000000  0.000000  0.000000    ...     0.000000  0.000000  0.000000   \n",
       "1  0.000000  0.000000  0.000000    ...     0.000000  0.000000  0.000000   \n",
       "2  0.000000  0.000000  0.000000    ...     0.000000  0.000000  0.000000   \n",
       "3  0.000000  0.000000  0.000000    ...     0.000000  0.000000  0.000000   \n",
       "4 -0.005280  0.308594  0.070801    ...    -0.177734 -0.082520  0.108398   \n",
       "5 -0.096680  0.138672  0.143555    ...    -0.114746  0.041504 -0.041992   \n",
       "6 -0.053955  0.110352  0.068848    ...     0.006165  0.079102 -0.070312   \n",
       "7 -0.064941  0.076172  0.291016    ...    -0.057861 -0.306641 -0.055176   \n",
       "8 -0.137695  0.017334 -0.427734    ...    -0.076660  0.111328 -0.365234   \n",
       "9  0.000000  0.000000  0.000000    ...     0.000000  0.000000  0.000000   \n",
       "\n",
       "        293       294       295       296       297       298       299  \n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "2  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "4  0.208008 -0.145508  0.375000 -0.070801 -0.003143 -0.104980  0.339844  \n",
       "5  0.092285 -0.000713  0.075195  0.049316 -0.055664  0.104980 -0.108398  \n",
       "6  0.025757 -0.137695 -0.045166  0.070801 -0.065918  0.032959  0.208984  \n",
       "7  0.128906  0.067383 -0.069336 -0.001877  0.133789  0.057617  0.175781  \n",
       "8  0.025757  0.011292  0.024780  0.001472  0.109863 -0.053467  0.296875  \n",
       "9  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "\n",
       "[10 rows x 300 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p2 = pd.DataFrame(train_image[2])\n",
    "print(p2.shape)\n",
    "p2.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make dataset iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9572"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_image = torch.FloatTensor(train_image).reshape(-1, 1, 64, 300)\n",
    "t_label = torch.LongTensor(train_label)\n",
    "train_dataset = list(zip(t_image, t_label))\n",
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images: torch.Size([50, 1, 64, 300]) \n",
      "labels: torch.Size([50])\n",
      "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])\n",
      "tensor(0)\n"
     ]
    }
   ],
   "source": [
    "for images, labels in train_loader:\n",
    "    print('images:', images.shape, '\\nlabels:', labels.shape)\n",
    "    print(images[1][0])\n",
    "    print(labels[1])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1090"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_image = torch.FloatTensor(test_image).reshape(-1, 1, 64, 300)\n",
    "c_label = torch.LongTensor(test_label)\n",
    "test_dataset = list(zip(c_image, c_label))\n",
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loader\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images: torch.Size([50, 1, 64, 300]) \n",
      "labels: torch.Size([50])\n",
      "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])\n",
      "tensor(1)\n"
     ]
    }
   ],
   "source": [
    "for images, labels in test_loader:\n",
    "    print('images:', images.shape, '\\nlabels:', labels.shape)\n",
    "    print(images[1][0])\n",
    "    print(labels[1])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model parameters (original code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('image shape', 64, 300), ('filter shape', [(100, 1, 3, 300), (100, 1, 4, 300), (100, 1, 5, 300)]), ('hidden_units', [100, 2]), ('dropout', [0.5]), ('batch_size', 50), ('non_static', True), ('learn_decay', 0.95), ('conv_non_linear', 'relu'), ('non_static', True), ('sqr_norm_lim', 9), ('shuffle_batch', True)]\n"
     ]
    }
   ],
   "source": [
    "lr_decay=0.95\n",
    "filter_hs=[3,4,5]\n",
    "conv_non_linear=\"relu\"\n",
    "hidden_units=[100,2]\n",
    "shuffle_batch=True\n",
    "n_epochs=25\n",
    "sqr_norm_lim=9\n",
    "non_static=non_static\n",
    "batch_size=50\n",
    "dropout_rate=[0.5]\n",
    "\n",
    "img_w=300\n",
    "shuffle_batch=True\n",
    "# activations=[Iden]\n",
    "\n",
    "\"\"\"\n",
    "Train a simple conv net\n",
    "img_h = sentence length (padded where necessary)\n",
    "img_w = word vector length (300 for word2vec)\n",
    "filter_hs = filter window sizes    \n",
    "hidden_units = [x,y] x is the number of feature maps (per filter window), and y is the penultimate layer\n",
    "sqr_norm_lim = s^2 in the paper\n",
    "lr_decay = adadelta decay parameter\n",
    "\"\"\"    \n",
    "rng = np.random.RandomState(3435)\n",
    "img_h = len(datasets[0][0])-1  # sentence length (subtracted 1 for y label)\n",
    "filter_w = img_w    \n",
    "feature_maps = hidden_units[0]\n",
    "filter_shapes = []\n",
    "pool_sizes = []\n",
    "for filter_h in filter_hs:\n",
    "    filter_shapes.append((feature_maps, 1, filter_h, filter_w))\n",
    "    pool_sizes.append((img_h-filter_h+1, img_w-filter_w+1))\n",
    "\n",
    "# filter_shapes [(100, 1, 3, 300), (100, 1, 4, 300), (100, 1, 5, 300)]\n",
    "# pool_sizes [(62, 1), (61, 1), (60, 1)]\n",
    "\n",
    "parameters = [(\"image shape\",img_h,img_w),(\"filter shape\",filter_shapes), (\"hidden_units\",hidden_units),\n",
    "              (\"dropout\", dropout_rate), (\"batch_size\",batch_size),(\"non_static\", non_static),\n",
    "                (\"learn_decay\",lr_decay), (\"conv_non_linear\", conv_non_linear), (\"non_static\", non_static)\n",
    "                ,(\"sqr_norm_lim\",sqr_norm_lim),(\"shuffle_batch\",shuffle_batch)]\n",
    "print(parameters)   \n",
    "\n",
    "# [('image shape', 64, 300), ('filter shape', [(100, 1, 3, 300), (100, 1, 4, 300), (100, 1, 5, 300)]), \n",
    "# ('hidden_units', [100, 2]), ('dropout', [0.5]), ('batch_size', 50), \n",
    "# ('non_static', True), ('learn_decay', 0.95), ('conv_non_linear', 'relu'), \n",
    "# ('non_static', True), ('sqr_norm_lim', 9), ('shuffle_batch', True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(100, 1, 3, 300), (100, 1, 4, 300), (100, 1, 5, 300)]\n",
      "one batch train (50, 1, 64, 300)\n",
      "[(62, 1), (61, 1), (60, 1)]\n"
     ]
    }
   ],
   "source": [
    "print(filter_shapes)\n",
    "image_shape=(batch_size, 1, img_h, img_w)\n",
    "print('one batch train', image_shape)\n",
    "print(pool_sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding & Stride\n",
    "- Output size\n",
    "\n",
    "    $ O = \\frac {W-K+2P}{S} + 1 $\n",
    "    - O: output h/w\n",
    "    - W: input h/w\n",
    "    - K: filter size(kernel size)\n",
    "    - P: padding\n",
    "        - $  P = \\frac {K-1}{2} $\n",
    "    - S: stride"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network\n",
    "\n",
    "- Theano:\n",
    "    - conv_layer: LeNetConvPoolLayer\n",
    "    - classifier: MLPDropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model:\n",
    "\n",
    "\n",
    "```\n",
    "Network\n",
    "Input ->\n",
    "Conv -> ReLU -> MaxPool |\n",
    "Conv -> ReLU -> MaxPool | -> concat\n",
    "Conv -> ReLU -> MaxPool |\n",
    "Fully Connected Layer(Logits -> Softmax) -> Labels\n",
    "```\n",
    "\n",
    "```\n",
    "Convolutional layer formula:\n",
    "- Filter 1(Kernel) size K = 3 => (3 x 300)\n",
    "- P(same padding) P = (3-1)/2=1\n",
    "- S(stride) S = 1\n",
    "- in_channels = 1\n",
    "- out_channels (int) – Number of channels produced by the convolution = 100\n",
    "Pooling layer formula:\n",
    "- K\n",
    "```\n",
    "\n",
    "```\n",
    "*Filter dimensions*:\n",
    "Conv1 (W_conv, (100, 1, 3, 300))\n",
    "Conv1 (b_conv, (100,))\n",
    "Conv2 (W_conv, (100, 1, 4, 300))\n",
    "Conv2 (b_conv, (100,))\n",
    "Conv3 (W_conv, (100, 1, 5, 300))\n",
    "Conv3 (b_conv, (100,))\n",
    "\n",
    "*Layer input dimensions*:\n",
    "- Input image(64, 300) \n",
    "\n",
    "----------------------------------------------------------------------\n",
    "|  Conv1  (100, 3, 300)   Conv2  (100, 4, 300)   Conv3  (100, 5, 300) |\n",
    "|  MaxPool (100, 62, 1)   MaxPool (100, 61, 1)   MaxPool (100, 60, 1) |\n",
    "-----------------------------Concat ----------------------------------\n",
    "\n",
    "- Concatenated (100, 1, 1) + (100, 1, 1) + (100, 1, 1) => (300, 1, 1) \n",
    "\n",
    "- Fully Connected Layer(Logits (100, 1) -> Logits (2, 1) -> Softmax) -> Labels\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvPoolLayer(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(ConvPoolLayer, self).__init__()\n",
    "\n",
    "        # Layer 1: conv - relu - conv- relu - pool\n",
    "        self.ngram1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=100, kernel_size=(3, 300), stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(62, 1), stride=None))\n",
    "        self.ngram2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=100, kernel_size=(4, 300), stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(61, 1), stride=None))\n",
    "        self.ngram3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=100, kernel_size=(5, 300), stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(60, 1), stride=None))\n",
    "        \n",
    "        # Fully Connected 1 (readout)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(300, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(100, num_classes))\n",
    "\n",
    "        # Initialize all parameters using kaiming normalization\n",
    "        self.init_weights_kaiming()\n",
    "    \n",
    "    def init_weights_kaiming(self):\n",
    "        #Use kaiming normalization to initialize the parameters\n",
    "        for layer in [self.ngram1, self.ngram2, self.ngram3, self.fc]:\n",
    "            for m in layer:\n",
    "                if type(m) == nn.Conv2d or type(m) == nn.Linear:\n",
    "                    m.weight = nn.init.kaiming_normal_(m.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        out1 = self.ngram1(x)\n",
    "        out2 = self.ngram2(x)\n",
    "        out3 = self.ngram3(x)\n",
    "        out = torch.cat((out1, out2, out3), 1)\n",
    "        \n",
    "        out = out.view(out.size(0), -1)\n",
    "    \n",
    "        # Linear function (readout)\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvPoolLayer(\n",
      "  (ngram1): Sequential(\n",
      "    (0): Conv2d(1, 100, kernel_size=(3, 300), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=(62, 1), stride=(62, 1), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (ngram2): Sequential(\n",
      "    (0): Conv2d(1, 100, kernel_size=(4, 300), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=(61, 1), stride=(61, 1), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (ngram3): Sequential(\n",
      "    (0): Conv2d(1, 100, kernel_size=(5, 300), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=(60, 1), stride=(60, 1), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=300, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.5)\n",
      "    (3): Linear(in_features=100, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = ConvPoolLayer(num_classes).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1, 3, 300])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 4, 300])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 5, 300])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 300])\n",
      "torch.Size([100])\n",
      "torch.Size([2, 100])\n",
      "torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "for p in model.parameters():\n",
    "    print(p.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1000. Loss: 0.017180060967803.\n",
      "Iteration: 2000. Loss: 0.1374388337135315.\n",
      "Iteration: 3000. Loss: 0.018514199182391167.\n",
      "Iteration: 4000. Loss: 0.0013086104299873114.\n",
      "Iteration: 5000. Loss: 4.0898321458371356e-05.\n",
      "Iteration: 6000. Loss: 6.0286522057140246e-05.\n",
      "Iteration: 7000. Loss: 0.03126201778650284.\n",
      "Iteration: 8000. Loss: 0.0002952528011519462.\n",
      "Iteration: 9000. Loss: 0.0028464950155466795.\n",
      "Test Accuracy of the model on the 1100 test images: 81.28440366972477 %\n",
      "Iteration: 1000. Loss: 0.023725857958197594.\n",
      "Iteration: 2000. Loss: 0.0021967124193906784.\n",
      "Iteration: 3000. Loss: 0.0026143407449126244.\n",
      "Iteration: 4000. Loss: 0.005998624954372644.\n",
      "Iteration: 5000. Loss: 0.02010442316532135.\n",
      "Iteration: 6000. Loss: 6.330013275146484e-05.\n",
      "Iteration: 7000. Loss: 0.0027032112702727318.\n",
      "Iteration: 8000. Loss: 4.4126511056674644e-05.\n",
      "Iteration: 9000. Loss: 2.8774738893844187e-05.\n",
      "Test Accuracy of the model on the 1100 test images: 81.10091743119266 %\n",
      "Iteration: 1000. Loss: 0.014694278128445148.\n",
      "Iteration: 2000. Loss: 0.015467614866793156.\n",
      "Iteration: 3000. Loss: 0.002240073634311557.\n",
      "Iteration: 4000. Loss: 0.0006312418263405561.\n",
      "Iteration: 5000. Loss: 9.91725901258178e-05.\n",
      "Iteration: 6000. Loss: 3.7670135952794226e-06.\n",
      "Iteration: 7000. Loss: 6.9046018325025216e-06.\n",
      "Iteration: 8000. Loss: 3.681182761283708e-06.\n",
      "Iteration: 9000. Loss: 0.00266297091729939.\n",
      "Test Accuracy of the model on the 1100 test images: 77.33944954128441 %\n",
      "Iteration: 1000. Loss: 0.037836890667676926.\n",
      "Iteration: 2000. Loss: 0.0113527225330472.\n",
      "Iteration: 3000. Loss: 0.0017901635728776455.\n",
      "Iteration: 4000. Loss: 0.0018794131465256214.\n",
      "Iteration: 5000. Loss: 0.0008962416904978454.\n",
      "Iteration: 6000. Loss: 0.0036186242941766977.\n",
      "Iteration: 7000. Loss: 0.04000085964798927.\n",
      "Iteration: 8000. Loss: 0.02817942574620247.\n",
      "Iteration: 9000. Loss: 0.017192654311656952.\n",
      "Test Accuracy of the model on the 1100 test images: 78.89908256880734 %\n",
      "Iteration: 1000. Loss: 0.04638590291142464.\n",
      "Iteration: 2000. Loss: 0.027685200795531273.\n",
      "Iteration: 3000. Loss: 0.0016696834936738014.\n",
      "Iteration: 4000. Loss: 0.006628125905990601.\n",
      "Iteration: 5000. Loss: 0.0005330753047019243.\n",
      "Iteration: 6000. Loss: 0.00022845268540550023.\n",
      "Iteration: 7000. Loss: 0.000386655330657959.\n",
      "Iteration: 8000. Loss: 0.0022405218333005905.\n",
      "Iteration: 9000. Loss: 0.00010658740939106792.\n",
      "Test Accuracy of the model on the 1100 test images: 81.0091743119266 %\n",
      "Iteration: 1000. Loss: 0.04483379051089287.\n",
      "Iteration: 2000. Loss: 0.0036911105271428823.\n",
      "Iteration: 3000. Loss: 0.009895285591483116.\n",
      "Iteration: 4000. Loss: 0.07141177356243134.\n",
      "Iteration: 5000. Loss: 0.0011301779886707664.\n",
      "Iteration: 6000. Loss: 0.0003364777658134699.\n",
      "Iteration: 7000. Loss: 0.0006580710178241134.\n",
      "Iteration: 8000. Loss: 4.26673905167263e-05.\n",
      "Iteration: 9000. Loss: 0.01115214079618454.\n",
      "Test Accuracy of the model on the 1100 test images: 78.9908256880734 %\n",
      "Iteration: 1000. Loss: 0.032275039702653885.\n",
      "Iteration: 2000. Loss: 0.004471493884921074.\n",
      "Iteration: 3000. Loss: 0.002925856038928032.\n",
      "Iteration: 4000. Loss: 0.00023085117572918534.\n",
      "Iteration: 5000. Loss: 0.00011345863458700478.\n",
      "Iteration: 6000. Loss: 0.0018780017271637917.\n",
      "Iteration: 7000. Loss: 0.033855121582746506.\n",
      "Iteration: 8000. Loss: 0.0006646251422353089.\n",
      "Iteration: 9000. Loss: 0.0007313298992812634.\n",
      "Test Accuracy of the model on the 1100 test images: 79.54128440366972 %\n",
      "Iteration: 1000. Loss: 0.018222860991954803.\n",
      "Iteration: 2000. Loss: 0.010378828272223473.\n",
      "Iteration: 3000. Loss: 0.014944079332053661.\n",
      "Iteration: 4000. Loss: 0.004929780960083008.\n",
      "Iteration: 5000. Loss: 0.0013220167020335793.\n",
      "Iteration: 6000. Loss: 0.003210776951164007.\n",
      "Iteration: 7000. Loss: 0.000491342565510422.\n",
      "Iteration: 8000. Loss: 0.08785044401884079.\n",
      "Iteration: 9000. Loss: 0.0006677747005596757.\n",
      "Test Accuracy of the model on the 1100 test images: 81.46788990825688 %\n",
      "Iteration: 1000. Loss: 0.05723224952816963.\n",
      "Iteration: 2000. Loss: 0.014893877319991589.\n",
      "Iteration: 3000. Loss: 0.006881040520966053.\n",
      "Iteration: 4000. Loss: 0.004619321785867214.\n",
      "Iteration: 5000. Loss: 0.017919069156050682.\n",
      "Iteration: 6000. Loss: 0.0002131223736796528.\n",
      "Iteration: 7000. Loss: 0.0010540246730670333.\n",
      "Iteration: 8000. Loss: 0.00012318610970396549.\n",
      "Iteration: 9000. Loss: 1.586914004292339e-05.\n",
      "Test Accuracy of the model on the 1100 test images: 80.55045871559633 %\n",
      "Iteration: 1000. Loss: 0.03968435153365135.\n",
      "Iteration: 2000. Loss: 0.09541500359773636.\n",
      "Iteration: 3000. Loss: 0.025059277191758156.\n",
      "Iteration: 4000. Loss: 0.0066725690849125385.\n",
      "Iteration: 5000. Loss: 0.006849540397524834.\n",
      "Iteration: 6000. Loss: 0.004288953263312578.\n",
      "Iteration: 7000. Loss: 0.0002463865384925157.\n",
      "Iteration: 8000. Loss: 9.083271288545802e-05.\n",
      "Iteration: 9000. Loss: 6.771087441848067e-07.\n",
      "Test Accuracy of the model on the 1100 test images: 79.90825688073394 %\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for i in range(0,10):\n",
    "    avg_losses = list()\n",
    "    iter = 0\n",
    "    \n",
    "    model = ConvPoolLayer(num_classes).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            total_loss = list()\n",
    "\n",
    "            # Load images as Variable\n",
    "            images = Variable(images).to(device)\n",
    "            labels = Variable(labels).to(device)\n",
    "\n",
    "            # Clear gradients w.r.t parameters\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass to get output/logits\n",
    "            outputs = model(images)\n",
    "\n",
    "            # Calculate Loss: Softmax --> cross entropy loss\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Getting gradients w.r.t paramters\n",
    "            loss.backward()\n",
    "\n",
    "            # Track loss to plot the result\n",
    "            total_loss.append(loss.item())\n",
    "\n",
    "            # Updating parameters\n",
    "            optimizer.step()\n",
    "\n",
    "            iter += 1\n",
    "\n",
    "            if iter % 1000 == 0:\n",
    "                # Print Loss\n",
    "                print('Iteration: {}. Loss: {}.'.format(iter, loss.item()))\n",
    "                avg_loss = np.divide(np.sum(total_loss), len(total_loss))\n",
    "                avg_losses.append(avg_loss)\n",
    "\n",
    "    n_test = len(test_loader) * batch_size\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in test_loader:\n",
    "            images = Variable(images).to(device)\n",
    "            labels = Variable(labels).to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "\n",
    "        print('Test Accuracy of the model on the {} test images: {} %'.format(n_test, 100 * correct / total))\n",
    "        \n",
    "        results.append(100 * correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[81.28440366972477, 81.10091743119266, 77.33944954128441, 78.89908256880734, 81.0091743119266, 78.9908256880734, 79.54128440366972, 81.46788990825688, 80.55045871559633, 79.90825688073394]\n",
      "80.00917431192661\n"
     ]
    }
   ],
   "source": [
    "print(results)\n",
    "print(np.mean(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the loss vs iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_axis = np.arange(len(avg_losses))\n",
    "plt.plot(x_axis, avg_losses, label='train')\n",
    "plt.xlabel('iterations (100)')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 1100 test images: 79.90825688073394 %\n"
     ]
    }
   ],
   "source": [
    "n_test = len(test_loader) * batch_size\n",
    "wrong_predictions = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = Variable(images).to(device)\n",
    "        labels = Variable(labels).to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        # See which are error predictions\n",
    "        result = (predicted == labels)\n",
    "        err_imgs = images[result == 0] # 0 means wrong prediction\n",
    "        err_labels = labels[result == 0]\n",
    "        err_outputs = predicted[result == 0]\n",
    "        for img, lbl, out in zip(err_imgs, err_labels, err_outputs):\n",
    "            wrong_predictions.append((img, lbl, out))\n",
    "     \n",
    "    print('Test Accuracy of the model on the {} test images: {} %'.format(n_test, 100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 9600 train images: 99.81195152528207 %\n"
     ]
    }
   ],
   "source": [
    "n_train = len(train_loader) * batch_size\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in train_loader:\n",
    "        images = Variable(images).to(device)\n",
    "        labels = Variable(labels).to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "     \n",
    "    print('Test Accuracy of the model on the {} train images: {} %'.format(n_train, 100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test memo:\n",
    "\n",
    "#### Model 1\n",
    "|mode/vec|dataset size(train/test)|#epoch|      model  |  optimizer | parameters |lr| accuracy  |\n",
    "|-----|-----------------------|-------|--------------|------------|------------|--|------------|\n",
    "|-nonstatic -rand|9572/1100|25|(conv- relu - pool), (linear)x2 |torch.optim.Adam|-|0.01| 77.15%|\n",
    "|-nonstatic -rand|9572/1100|25|(conv- relu - pool), (linear-relu)x2 |torch.optim.Adam|Kaiming He|0.01| 77.52%|\n",
    "|-nonstatic -rand|9572/1100|25|(conv- relu - pool), (linear-relu)x2 |torch.optim.Adam|Kaiming He|0.001| 80.27%|\n",
    "|-nonstatic -word2vec|9572/1100|25|(conv- relu - pool), (linear-relu)x2 |torch.optim.Adam|Kaiming He|0.001| 80.90%|\n",
    "|-nonstatic -word2vec|9572/1100|50|(conv- relu - pool), (linear-relu)x2 |torch.optim.Adam|Kaiming He|0.001| 80.83%|\n",
    "|-nonstatic -word2vec|9572/1100|50|(conv- relu - pool), (linear-relu-dropout)x2 |torch.optim.Adam|Kaiming He|0.001| 80.00%|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
